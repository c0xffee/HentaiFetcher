#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HentaiFetcher Download Processor
================================
ä¸‹è¼‰è™•ç†å™¨ï¼šè² è²¬åŸ·è¡Œ gallery-dlã€è½‰æ› PDF ä¸¦ç”Ÿæˆ metadata
"""

import re
import sys
import json
import time
import shutil
import subprocess
import threading
from pathlib import Path
from typing import Optional, Dict, Any, List
from urllib.parse import quote

from core.config import (
    VERSION, IS_DOCKER, BASE_DIR, DOWNLOAD_DIR, TEMP_DIR, 
    logger, PDF_WEB_BASE_URL
)
from utils.helpers import sanitize_filename, find_images
from services.metadata_service import parse_gallery_dl_info, create_eagle_metadata, find_info_json
from services.nhentai_api import fetch_nhentai_extra_info


class DownloadProcessor:
    """
    ä¸‹è¼‰è™•ç†å™¨ï¼šè² è²¬åŸ·è¡Œ gallery-dlã€è½‰æ› PDF ä¸¦ç”Ÿæˆ metadata
    """
    
    def __init__(self, url: str, total_pages: int = 0, message_callback=None, cancel_event: threading.Event = None):
        """
        åˆå§‹åŒ–ä¸‹è¼‰è™•ç†å™¨
        
        Args:
            url: è¦ä¸‹è¼‰çš„ç¶²å€
            total_pages: é æœŸç¸½é æ•¸ï¼ˆç”¨æ–¼é€²åº¦è¨ˆç®—ï¼‰
            message_callback: ç‹€æ…‹æ›´æ–°å›èª¿å‡½å¼
            cancel_event: å–æ¶ˆäº‹ä»¶ï¼ˆè¢« set æ™‚æ‡‰ä¸­æ­¢ä¸‹è¼‰ï¼‰
        """
        self.url = url
        self.total_pages = total_pages
        self.message_callback = message_callback
        self.cancel_event = cancel_event
        self.temp_path: Optional[Path] = None
        self.output_path: Optional[Path] = None
        self.last_error: str = ""
        self.download_complete = False  # ä¸‹è¼‰æ˜¯å¦å®Œæˆ
        self.pdf_progress = 0  # PDF è½‰æ›é€²åº¦ (0-100)
        self.pdf_converting = False  # æ˜¯å¦æ­£åœ¨è½‰æ› PDF
    
    def is_cancelled(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ"""
        return self.cancel_event and self.cancel_event.is_set()
        
    def get_downloaded_count(self) -> int:
        """ç²å–å·²ä¸‹è¼‰çš„åœ–ç‰‡æ•¸é‡"""
        if not self.temp_path or not self.temp_path.exists():
            return 0
        return len(find_images(self.temp_path))
    
    def get_first_image_path(self) -> Path:
        """ç²å–ç¬¬ä¸€å¼µå·²ä¸‹è¼‰åœ–ç‰‡çš„è·¯å¾‘"""
        if not self.temp_path or not self.temp_path.exists():
            return None
        images = find_images(self.temp_path)
        if images:
            # æŒ‰æª”åæ’åºå–ç¬¬ä¸€å¼µ
            images.sort(key=lambda x: x.name)
            return images[0]
        return None
        
    async def send_status(self, message: str):
        """ç™¼é€ç‹€æ…‹è¨Šæ¯"""
        logger.info(message)
        if self.message_callback:
            try:
                await self.message_callback(message)
            except Exception as e:
                logger.warning(f"ç„¡æ³•ç™¼é€ç‹€æ…‹è¨Šæ¯: {e}")
    
    def download_with_gallery_dl(self) -> bool:
        """
        ä½¿ç”¨ gallery-dl ä¸‹è¼‰åœ–ç‰‡å’Œ metadata
        
        Returns:
            æˆåŠŸè¿”å› Trueï¼Œå¤±æ•—è¿”å› False
        """
        try:
            # å»ºç«‹å”¯ä¸€çš„æš«å­˜ç›®éŒ„ï¼ˆçµ±ä¸€ä½¿ç”¨ TEMP_DIRï¼‰
            self.temp_path = TEMP_DIR / f"dl_{int(time.time() * 1000)}"
            self.temp_path.mkdir(parents=True, exist_ok=True)
            
            print(f"[GALLERY-DL] ä¸‹è¼‰ç›®éŒ„: {self.temp_path}", flush=True)
            
            # æ ¹æ“šç’°å¢ƒé¸æ“‡ gallery-dl åŸ·è¡Œæ–¹å¼èˆ‡åƒæ•¸
            if IS_DOCKER:
                # Docker ç’°å¢ƒï¼šå…©éšæ®µä¸‹è¼‰
                # éšæ®µ 1: ä½¿ç”¨ gallery-dl --dump-json ç²å– metadata
                print(f"[GALLERY-DL] éšæ®µ1: ç²å– metadata...", flush=True)
                metadata_cmd = [
                    'gallery-dl',
                    '--dump-json',
                    '--user-agent', 'Mozilla/5.0',
                    self.url
                ]
                
                metadata_result = subprocess.run(
                    metadata_cmd,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                # è§£æä¸¦å„²å­˜ metadata
                if metadata_result.returncode == 0 and metadata_result.stdout.strip():
                    try:
                        # gallery-dl --dump-json è¼¸å‡ºçš„æ˜¯ JSON é™£åˆ—
                        metadata_list = json.loads(metadata_result.stdout)
                        if metadata_list and len(metadata_list) > 0:
                            # å–ç¬¬ä¸€å€‹å…ƒç´ çš„ metadataï¼ˆé€šå¸¸åŒ…å« gallery infoï¼‰
                            first_item = metadata_list[0]
                            if isinstance(first_item, list) and len(first_item) >= 2:
                                gallery_metadata = first_item[1]  # [url, metadata] æ ¼å¼
                            else:
                                gallery_metadata = first_item
                            
                            # å„²å­˜ metadata åˆ°æš«å­˜ç›®éŒ„
                            metadata_file = self.temp_path / "gallery_metadata.json"
                            with open(metadata_file, 'w', encoding='utf-8') as f:
                                json.dump(gallery_metadata, f, ensure_ascii=False, indent=2)
                            print(f"[GALLERY-DL] Metadata å·²å„²å­˜: {metadata_file}", flush=True)
                    except json.JSONDecodeError as e:
                        print(f"[GALLERY-DL] Metadata è§£æå¤±æ•—: {e}", flush=True)
                
                # éšæ®µ 2: ä½¿ç”¨ gallery-dl -g + aria2c å¤šç·šç¨‹ä¸‹è¼‰åœ–ç‰‡
                print(f"[GALLERY-DL] éšæ®µ2: å¤šç·šç¨‹ä¸‹è¼‰åœ–ç‰‡...", flush=True)
                cmd = (
                    f'gallery-dl --user-agent "Mozilla/5.0" -g "{self.url}" | '
                    f'aria2c -i - -x 8 -s 8 --user-agent="Mozilla/5.0" -d "{self.temp_path}"'
                )
                
                logger.info(f"åŸ·è¡ŒæŒ‡ä»¤: {cmd}")
                print(f"[GALLERY-DL+ARIA2] å‘½ä»¤: {cmd}", flush=True)
                
                # ä½¿ç”¨ shell=True åŸ·è¡Œç®¡é“å‘½ä»¤
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=900
                )
            else:
                # Windows ç’°å¢ƒï¼šå…©éšæ®µä¸‹è¼‰
                # éšæ®µ 1: ä½¿ç”¨ gallery-dl --dump-json ç²å– metadata
                print(f"[GALLERY-DL] éšæ®µ1: ç²å– metadata...", flush=True)
                metadata_cmd = [
                    sys.executable,
                    '-m', 'gallery_dl',
                    '--dump-json',
                    self.url
                ]
                
                metadata_result = subprocess.run(
                    metadata_cmd,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                # è§£æä¸¦å„²å­˜ metadata
                if metadata_result.returncode == 0 and metadata_result.stdout.strip():
                    try:
                        metadata_list = json.loads(metadata_result.stdout)
                        if metadata_list and len(metadata_list) > 0:
                            first_item = metadata_list[0]
                            if isinstance(first_item, list) and len(first_item) >= 2:
                                gallery_metadata = first_item[1]
                            else:
                                gallery_metadata = first_item
                            
                            metadata_file = self.temp_path / "gallery_metadata.json"
                            with open(metadata_file, 'w', encoding='utf-8') as f:
                                json.dump(gallery_metadata, f, ensure_ascii=False, indent=2)
                            print(f"[GALLERY-DL] Metadata å·²å„²å­˜: {metadata_file}", flush=True)
                    except json.JSONDecodeError as e:
                        print(f"[GALLERY-DL] Metadata è§£æå¤±æ•—: {e}", flush=True)
                
                # éšæ®µ 2: ä¸‹è¼‰åœ–ç‰‡
                print(f"[GALLERY-DL] éšæ®µ2: ä¸‹è¼‰åœ–ç‰‡...", flush=True)
                
                # è¨­å®šæª”è·¯å¾‘
                config_path = BASE_DIR / "config" / "gallery-dl.conf"
                
                cmd = [
                    sys.executable,
                    '-m', 'gallery_dl',
                    '--config', str(config_path),
                    '--dest', str(self.temp_path),
                    '--write-metadata',
                    self.url
                ]
                
                logger.info(f"åŸ·è¡ŒæŒ‡ä»¤: {' '.join(cmd)}")
                print(f"[GALLERY-DL] å‘½ä»¤: {cmd}", flush=True)
                
                # åŸ·è¡Œ gallery-dl å‘½ä»¤
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=900
                )
            print(f"[GALLERY-DL] åŸ·è¡Œå®Œæˆ", flush=True)
            
            # å¼·åˆ¶è¼¸å‡ºæ‰€æœ‰ gallery-dl æ—¥èªŒï¼ˆç”¨æ–¼é™¤éŒ¯ï¼‰
            print(f"[GALLERY-DL] URL: {self.url}", flush=True)
            print(f"[GALLERY-DL] è¿”å›ç¢¼: {result.returncode}", flush=True)
            print(f"[GALLERY-DL] STDOUT: {result.stdout[:2000] if result.stdout else '(ç©º)'}", flush=True)
            print(f"[GALLERY-DL] STDERR: {result.stderr[:2000] if result.stderr else '(ç©º)'}", flush=True)
            
            if result.returncode != 0:
                logger.error(f"gallery-dl è¿”å›ç¢¼: {result.returncode}")
                logger.error(f"gallery-dl STDERR: {result.stderr}")
                logger.error(f"gallery-dl STDOUT: {result.stdout}")
                
                # å„²å­˜è©³ç´°éŒ¯èª¤è¨Šæ¯ä¾› Discord å›å ±
                # cmd åœ¨ Docker ç’°å¢ƒæ˜¯å­—ä¸²ï¼ŒWindows ç’°å¢ƒæ˜¯åˆ—è¡¨
                cmd_str = cmd if isinstance(cmd, str) else ' '.join(cmd)
                error_lines = [
                    f"âš ï¸ **Debug è³‡è¨Š**",
                    f"ğŸ“¦ ç‰ˆæœ¬: {VERSION}",
                    f"ğŸ’» ç’°å¢ƒ: {'Docker' if IS_DOCKER else 'Windows'}",
                    f"ğŸ“‚ ä¸‹è¼‰ç›®éŒ„: `{self.temp_path}`",
                    f"ğŸ”§ åŸ·è¡Œå‘½ä»¤: `{cmd_str}`",
                    f"ğŸ”´ è¿”å›ç¢¼: {result.returncode}",
                ]
                
                if result.stderr:
                    error_lines.append(f"\n**STDERR:**\n```\n{result.stderr[:800]}\n```")
                if result.stdout:
                    error_lines.append(f"\n**STDOUT:**\n```\n{result.stdout[:800]}\n```")
                
                self.last_error = "\n".join(error_lines)
                return False
            
            logger.info(f"gallery-dl è¼¸å‡º: {result.stdout}")
            return True
            
        except subprocess.TimeoutExpired:
            logger.error("gallery-dl åŸ·è¡Œè¶…æ™‚")
            return False
        except Exception as e:
            logger.error(f"gallery-dl åŸ·è¡ŒéŒ¯èª¤: {e}")
            return False
    
    def convert_to_pdf(self, images: List[Path], output_pdf: Path) -> bool:
        """
        ä½¿ç”¨ Pillow å°‡åœ–ç‰‡è½‰æ›ç‚ºç­‰å¯¬ PDFï¼ˆæ”¯æ´é€²åº¦å›å ± + ç·šæ€§åŒ–ï¼‰
        
        æ‰€æœ‰åœ–ç‰‡æœƒè¢«èª¿æ•´ç‚ºçµ±ä¸€å¯¬åº¦ï¼ˆä½¿ç”¨æœ€å¤§å¯¬åº¦ï¼‰ï¼Œé«˜åº¦æŒ‰æ¯”ä¾‹ç¸®æ”¾ï¼Œ
        ç¢ºä¿ PDF æ¯ä¸€é éƒ½æ˜¯ 100% å¯¬åº¦å°é½Šã€‚
        æœ€å¾Œä½¿ç”¨ pikepdf ç·šæ€§åŒ–ï¼ŒåŠ é€Ÿç¶²é å­˜å– (Fast Web View)ã€‚
        
        Args:
            images: åœ–ç‰‡æª”æ¡ˆåˆ—è¡¨
            output_pdf: è¼¸å‡º PDF è·¯å¾‘
        
        Returns:
            æˆåŠŸè¿”å› Trueï¼Œå¤±æ•—è¿”å› False
        """
        if not images:
            logger.error("æ²’æœ‰åœ–ç‰‡å¯ä¾›è½‰æ›")
            return False
        
        try:
            from PIL import Image
            from io import BytesIO
            import pikepdf
            
            self.pdf_converting = True
            self.pdf_progress = 0
            
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
            output_pdf.parent.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"è½‰æ› {len(images)} å¼µåœ–ç‰‡ç‚ºç­‰å¯¬ PDF (å«ç·šæ€§åŒ–)")
            
            total = len(images)
            
            # éšæ®µ 1: è®€å–æ‰€æœ‰åœ–ç‰‡ä¸¦æ‰¾å‡ºæœ€å¤§å¯¬åº¦ (0-20%)
            logger.info("éšæ®µ 1/4: åˆ†æåœ–ç‰‡å°ºå¯¸...")
            pil_images = []
            max_width = 0
            
            for i, img_path in enumerate(images):
                img = Image.open(img_path)
                # è½‰æ›ç‚º RGBï¼ˆPDF ä¸æ”¯æ´ RGBA é€æ˜é€šé“ï¼‰
                if img.mode in ('RGBA', 'P', 'LA'):
                    # å»ºç«‹ç™½è‰²èƒŒæ™¯
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    if img.mode in ('RGBA', 'LA'):
                        background.paste(img, mask=img.split()[-1])  # ä½¿ç”¨ alpha é€šé“ä½œç‚ºé®ç½©
                        img = background
                    else:
                        img = img.convert('RGB')
                elif img.mode != 'RGB':
                    img = img.convert('RGB')
                
                pil_images.append(img)
                if img.width > max_width:
                    max_width = img.width
                
                self.pdf_progress = int((i + 1) / total * 20)
                if (i + 1) % 10 == 0:
                    time.sleep(0.05)
            
            logger.info(f"çµ±ä¸€å¯¬åº¦: {max_width}px")
            
            # éšæ®µ 2: èª¿æ•´æ‰€æœ‰åœ–ç‰‡ç‚ºç­‰å¯¬ (20-60%)
            logger.info("éšæ®µ 2/4: èª¿æ•´åœ–ç‰‡ç‚ºç­‰å¯¬...")
            resized_images = []
            
            for i, img in enumerate(pil_images):
                if img.width != max_width:
                    # æŒ‰æ¯”ä¾‹ç¸®æ”¾åˆ°ç›®æ¨™å¯¬åº¦
                    ratio = max_width / img.width
                    new_height = int(img.height * ratio)
                    # ä½¿ç”¨é«˜å“è³ªç¸®æ”¾
                    resized_img = img.resize((max_width, new_height), Image.Resampling.LANCZOS)
                    resized_images.append(resized_img)
                else:
                    resized_images.append(img)
                
                self.pdf_progress = 20 + int((i + 1) / total * 40)
                if (i + 1) % 10 == 0:
                    time.sleep(0.05)
            
            # éšæ®µ 3: ç”Ÿæˆ PDF åˆ°è¨˜æ†¶é«” (60-80%)
            logger.info("éšæ®µ 3/4: ç”Ÿæˆ PDF åˆ°è¨˜æ†¶é«”...")
            self.pdf_progress = 65
            
            # ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºåŸºåº•ï¼Œå…¶é¤˜ append
            first_image = resized_images[0]
            rest_images = resized_images[1:] if len(resized_images) > 1 else []
            
            # å…ˆå­˜åˆ° BytesIO
            pdf_buffer = BytesIO()
            try:
                first_image.save(
                    pdf_buffer,
                    "PDF",
                    save_all=True,
                    append_images=rest_images,
                    resolution=100.0
                )
                pdf_buffer.seek(0)
                logger.info(f"PDF è¨˜æ†¶é«”å¤§å°: {len(pdf_buffer.getvalue()) / (1024*1024):.2f} MB")
            except Exception as save_error:
                logger.error(f"PDF save å¤±æ•—: {save_error}")
                import traceback
                logger.error(traceback.format_exc())
                self.pdf_converting = False
                return False
            
            self.pdf_progress = 80
            
            # éšæ®µ 4: ä½¿ç”¨ pikepdf ç·šæ€§åŒ– (80-100%)
            logger.info("éšæ®µ 4/4: PDF ç·šæ€§åŒ– (Fast Web View)...")
            try:
                with pikepdf.open(pdf_buffer) as pdf:
                    pdf.save(output_pdf, linearize=True)
                logger.info("PDF ç·šæ€§åŒ–å®Œæˆ")
            except Exception as linearize_error:
                logger.warning(f"ç·šæ€§åŒ–å¤±æ•—ï¼Œæ”¹ç”¨éç·šæ€§åŒ–å­˜æª”: {linearize_error}")
                # å¤±æ•—æ™‚ç›´æ¥å­˜æª”ï¼ˆä¸ç·šæ€§åŒ–ï¼‰
                pdf_buffer.seek(0)
                with open(output_pdf, 'wb') as f:
                    f.write(pdf_buffer.getvalue())
            
            # æ¸…ç†è¨˜æ†¶é«” - ä½¿ç”¨ set è¿½è¹¤å·²é—œé–‰çš„åœ–ç‰‡ idï¼Œé¿å…æ¯”è¼ƒæ“ä½œ
            closed_ids = set()
            for img in pil_images:
                if id(img) not in closed_ids:
                    try:
                        img.close()
                    except Exception:
                        pass
                    closed_ids.add(id(img))
            for img in resized_images:
                if id(img) not in closed_ids:
                    try:
                        img.close()
                    except Exception:
                        pass
                    closed_ids.add(id(img))
            
            self.pdf_progress = 100
            self.pdf_converting = False
            
            # ç¢ºèª PDF å·²ç”Ÿæˆ
            if output_pdf.exists() and output_pdf.stat().st_size > 0:
                logger.info(f"PDF ç”ŸæˆæˆåŠŸ: {output_pdf}")
                return True
            else:
                logger.error("PDF æª”æ¡ˆæœªç”Ÿæˆæˆ–ç‚ºç©º")
                return False
                
        except Exception as e:
            logger.error(f"PDF è½‰æ›éŒ¯èª¤: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.pdf_converting = False
            return False
    
    def process(self) -> tuple:
        """
        åŸ·è¡Œå®Œæ•´çš„ä¸‹è¼‰è™•ç†æµç¨‹
        
        Returns:
            (æˆåŠŸç‹€æ…‹, çµæœè¨Šæ¯)
        """
        start_time = time.time()  # é–‹å§‹è¨ˆæ™‚
        
        try:
            # æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self.is_cancelled():
                return False, "ğŸš« ä¸‹è¼‰å·²å–æ¶ˆ"
            
            # æ­¥é©Ÿ 1: ä¸‹è¼‰
            logger.info(f"é–‹å§‹ä¸‹è¼‰: {self.url}")
            print(f"[PROCESS] é–‹å§‹ä¸‹è¼‰: {self.url}", flush=True)
            if not self.download_with_gallery_dl():
                # å†æ¬¡æª¢æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                if self.is_cancelled():
                    return False, "ğŸš« ä¸‹è¼‰å·²å–æ¶ˆ"
                error_detail = self.last_error if self.last_error else "æœªçŸ¥åŸå› "
                elapsed = time.time() - start_time
                return False, f"âŒ ä¸‹è¼‰å¤±æ•—\nğŸ”— {self.url}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s\n\n{error_detail}"
            
            # æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self.is_cancelled():
                return False, "ğŸš« ä¸‹è¼‰å·²å–æ¶ˆ"
            
            # å°‹æ‰¾ä¸‹è¼‰çš„å…§å®¹
            # gallery-dl å¯èƒ½æœƒå»ºç«‹å­ç›®éŒ„
            print(f"[PROCESS] æœå°‹åœ–ç‰‡ç›®éŒ„: {self.temp_path}", flush=True)
            images = find_images(self.temp_path)
            print(f"[PROCESS] æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡", flush=True)
            
            if not images:
                # åˆ—å‡ºç›®éŒ„å…§å®¹ä»¥ä¾¿é™¤éŒ¯
                try:
                    all_files = list(self.temp_path.rglob('*'))
                    print(f"[DEBUG] ç›®éŒ„å…§æ‰€æœ‰æª”æ¡ˆ: {[str(f) for f in all_files[:20]]}", flush=True)
                except Exception as e:
                    print(f"[DEBUG] ç„¡æ³•åˆ—å‡ºç›®éŒ„: {e}", flush=True)
                elapsed = time.time() - start_time
                return False, f"âŒ æ‰¾ä¸åˆ°ä¸‹è¼‰çš„åœ–ç‰‡\nğŸ”— {self.url}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s"
            
            logger.info(f"æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡")
            
            # æ­¥é©Ÿ 2: è§£æ metadata
            info_json = find_info_json(self.temp_path)
            
            if info_json:
                metadata = parse_gallery_dl_info(info_json)
            else:
                logger.warning("æ‰¾ä¸åˆ° info.jsonï¼Œä½¿ç”¨é è¨­ metadata")
                metadata = None
            
            # è¨­å®šæ¨™é¡Œ - å„ªå…ˆä½¿ç”¨æ—¥æ–‡æ¨™é¡Œ
            if metadata:
                # å„ªå…ˆé †åº: æ—¥æ–‡æ¨™é¡Œ > è‹±æ–‡æ¨™é¡Œ > URL ID
                if metadata.get('title_japanese'):
                    title = metadata['title_japanese']
                    logger.info(f"ä½¿ç”¨æ—¥æ–‡æ¨™é¡Œ: {title}")
                elif metadata.get('title'):
                    title = metadata['title']
                    logger.info(f"ä½¿ç”¨è‹±æ–‡æ¨™é¡Œ: {title}")
                else:
                    title = None
            else:
                title = None
            
            # æå– gallery_id ç”¨æ–¼ç›®éŒ„å’Œæª”åï¼ˆé¿å…è·¯å¾‘éé•·ï¼‰
            gallery_id_for_path = metadata.get('gallery_id', '') if metadata else ''
            if not gallery_id_for_path:
                # å˜—è©¦å¾ URL æå–
                match = re.search(r'/g/(\d+)', self.url)
                if match:
                    gallery_id_for_path = match.group(1)
                else:
                    gallery_id_for_path = str(int(time.time()))
            
            if not title:
                title = f"Gallery_{gallery_id_for_path}"
            
            safe_title = sanitize_filename(title)
            logger.info(f"ä½¿ç”¨æ¨™é¡Œ: {safe_title}")
            logger.info(f"ä½¿ç”¨ Gallery ID ä½œç‚ºç›®éŒ„å: {gallery_id_for_path}")
            
            # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾ - ä½¿ç”¨ gallery_id é¿å…è·¯å¾‘éé•·
            self.output_path = DOWNLOAD_DIR / gallery_id_for_path
            
            # å¦‚æœè³‡æ–™å¤¾å·²å­˜åœ¨ï¼Œä½¿ç”¨æ™‚é–“æˆ³å‘½åé¿å…è¦†è“‹
            if self.output_path.exists():
                self.output_path = DOWNLOAD_DIR / f"{gallery_id_for_path}_{int(time.time())}"
                logger.info(f"è³‡æ–™å¤¾å·²å­˜åœ¨ï¼Œä½¿ç”¨æ–°è³‡æ–™å¤¾ {self.output_path}")
            
            self.output_path.mkdir(parents=True, exist_ok=True)
            
            # æ­¥é©Ÿ 3: è½‰æ›ç‚º PDF - ä½¿ç”¨ gallery_id ä½œç‚ºæª”å
            pdf_path = self.output_path / f"{gallery_id_for_path}.pdf"
            if not self.convert_to_pdf(images, pdf_path):
                return False, "âŒ PDF è½‰æ›å¤±æ•—"
            
            # æ­¥é©Ÿ 3.5: è¤‡è£½ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢
            if images:
                try:
                    first_image = images[0]
                    # ç²å–å‰¯æª”å
                    ext = first_image.suffix  # ä¾‹å¦‚ .jpg, .png
                    cover_path = self.output_path / f"cover{ext}"
                    # è¤‡è£½ç¬¬ä¸€å¼µåœ–ç‰‡
                    shutil.copy2(first_image, cover_path)
                    logger.info(f"å°é¢å·²ä¿å­˜: {cover_path.name}")
                except Exception as e:
                    logger.warning(f"ä¿å­˜å°é¢å¤±æ•—: {e}")
            
            # æ­¥é©Ÿ 4: ç²å–é¡å¤–è³‡è¨Šï¼ˆæ”¶è—æ•¸ã€è©•è«–ï¼‰
            gallery_id = metadata.get('gallery_id', '') if metadata else ''
            if not gallery_id:
                # å˜—è©¦å¾ URL æå–
                match = re.search(r'/g/(\d+)', self.url)
                if match:
                    gallery_id = match.group(1)
            
            nhentai_extra = {}
            if gallery_id:
                logger.info(f"ç²å– nhentai é¡å¤–è³‡è¨Š (ID: {gallery_id})...")
                nhentai_extra = fetch_nhentai_extra_info(gallery_id)
            
            # æ­¥é©Ÿ 5: ç”Ÿæˆ Eagle metadataï¼ˆåŒ…å«æ“´å±•è³‡è¨Šï¼‰
            extra_info = None
            if metadata:
                extra_info = {
                    'title_japanese': metadata.get('title_japanese', ''),
                    'title_english': metadata.get('title', ''),  # è‹±æ–‡æ¨™é¡Œæ”¾ annotation
                    'title_pretty': metadata.get('title_pretty', ''),
                    'gallery_id': metadata.get('gallery_id', ''),
                    'pages': metadata.get('pages', 0),
                    'favorites': nhentai_extra.get('favorites', 0),  # å¾ API ç²å–
                    'category': metadata.get('category', ''),
                    'type': metadata.get('type', ''),
                    'artist': metadata.get('artist', []),
                    'group': metadata.get('group', []),
                    'parody': metadata.get('parody', []),
                    'character': metadata.get('character', []),
                    'language': metadata.get('language', ''),
                    'comments': nhentai_extra.get('comments', []),  # è©•è«–
                }
            
            eagle_metadata = create_eagle_metadata(
                title=title,  # å·²ç¶“æ˜¯æ—¥æ–‡æ¨™é¡Œå„ªå…ˆ
                url=metadata.get('url', self.url) if metadata else self.url,
                tags=metadata.get('tags', []) if metadata else [],
                annotation="",
                extra_info=extra_info
            )
            
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨ï¼ˆé˜²æ­¢ UNC è·¯å¾‘å•é¡Œï¼‰
            self.output_path.mkdir(parents=True, exist_ok=True)
            
            metadata_path = self.output_path / "metadata.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(eagle_metadata, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Eagle metadata å·²ç”Ÿæˆ: {metadata_path}")
            
            # æ­¥é©Ÿ 5: æ¸…ç†æš«å­˜æª”æ¡ˆ
            if self.temp_path and self.temp_path.exists():
                shutil.rmtree(self.temp_path)
                logger.info(f"å·²æ¸…ç†æš«å­˜ç›®éŒ„: {self.temp_path}")
            
            # è¨ˆç®—è€—æ™‚
            elapsed = time.time() - start_time
            if elapsed >= 60:
                elapsed_str = f"{int(elapsed // 60)}åˆ†{int(elapsed % 60)}ç§’"
            else:
                elapsed_str = f"{elapsed:.1f}ç§’"
            
            # ç²å–é æ•¸
            page_count = metadata.get('pages', len(images)) if metadata else len(images)
            
            # è½‰æ›è·¯å¾‘ç‚ºå­—ä¸²ï¼Œç¢ºä¿ UNC è·¯å¾‘æ­£ç¢ºé¡¯ç¤º
            output_path_str = str(self.output_path)
            if output_path_str.startswith('\\\\'):
                output_path_str = output_path_str  # å·²ç¶“æ˜¯æ­£ç¢ºçš„ UNC è·¯å¾‘
            elif output_path_str.startswith('\\') and not output_path_str.startswith('\\\\'):
                output_path_str = '\\' + output_path_str  # è£œä¸Šç¼ºå°‘çš„æ–œç·š
            
            # ç”Ÿæˆ PDF Web é€£çµ - ä½¿ç”¨å¯¦éš›è³‡æ–™å¤¾åç¨±ï¼ˆå¯èƒ½æœ‰æ™‚é–“æˆ³å¾Œç¶´ï¼‰
            folder_name = self.output_path.name  # ä½¿ç”¨å¯¦éš›è³‡æ–™å¤¾åç¨±
            pdf_filename = f"{gallery_id_for_path}.pdf"
            pdf_web_url = f"{PDF_WEB_BASE_URL}/{quote(folder_name)}/{quote(pdf_filename)}"
            
            # ä½¿ç”¨ç´” URL é¡¯ç¤ºï¼ˆé¿å… markdown é€£çµè¢«ç·¨ç¢¼çš„æ‹¬è™Ÿç ´å£ï¼‰
            return True, f"âœ… å®Œæˆ: **{safe_title}**\nğŸ“„ {page_count}é  â±ï¸ {elapsed_str}\nğŸ“¥ {pdf_web_url}\nğŸ“ {output_path_str}"
            
        except Exception as e:
            logger.exception(f"è™•ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            
            # è¨ˆç®—è€—æ™‚
            elapsed = time.time() - start_time
            
            # æ¸…ç†æš«å­˜æª”æ¡ˆ
            if self.temp_path and self.temp_path.exists():
                try:
                    shutil.rmtree(self.temp_path)
                except Exception:
                    pass
            
            return False, f"âŒ éŒ¯èª¤: {str(e)}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s"
