#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HentaiFetcher - Discord Bot è‡ªå‹•åŒ–æ¼«ç•«ä¸‹è¼‰å™¨
==============================================
ç‰ˆæœ¬: 3.0.0 - æ–œç·šæŒ‡ä»¤ç‰ˆæœ¬
åŠŸèƒ½ï¼š
1. Discord Bot ä½¿ç”¨æ–œç·šæŒ‡ä»¤ (/dl, /search, /read ç­‰)
2. ä½¿ç”¨ gallery-dl ä¸‹è¼‰åœ–ç‰‡èˆ‡ metadata
3. ä½¿ç”¨ Pillow è½‰æ›ç‚ºç­‰å¯¬ PDF
4. ç”Ÿæˆ Eagle ç›¸å®¹çš„ metadata.json
5. è‡ªå‹•æ¸…ç†åŸå§‹åœ–ç‰‡æª”æ¡ˆ
6. æ•´åˆ Eagle Library æŸ¥è©¢
"""

# ç‰ˆæœ¬è™Ÿ - ç”¨ä¾†ç¢ºèªå®¹å™¨æ˜¯å¦æ›´æ–°
VERSION = "3.0.0"

print(f"[STARTUP] HentaiFetcher ç‰ˆæœ¬ {VERSION} æ­£åœ¨è¼‰å…¥...", flush=True)

import os
import sys
import json
import time
import shutil
import asyncio
import logging
import subprocess
import threading
import re
import requests
from queue import Queue, Empty
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, List

import discord
from discord.ext import commands
from discord import app_commands

# è¼‰å…¥ .env æª”æ¡ˆï¼ˆæœ¬åœ°æ¸¬è©¦ç”¨ï¼‰
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("[STARTUP] å·²è¼‰å…¥ .env æª”æ¡ˆ", flush=True)
except ImportError:
    pass  # Docker ç’°å¢ƒä¸éœ€è¦ dotenv

print(f"[STARTUP] æ¨¡çµ„è¼‰å…¥å®Œæˆ", flush=True)

# ==================== è¨­å®šå€å¡Š ====================

# åˆ¤æ–·é‹è¡Œç’°å¢ƒï¼ˆDocker æˆ–æœ¬åœ°ï¼‰
import platform
IS_DOCKER = platform.system() == 'Linux' and os.path.exists('/app')

if IS_DOCKER:
    # Docker ç’°å¢ƒ - ä½¿ç”¨å®¹å™¨å…§è·¯å¾‘
    BASE_DIR = Path('/app')
    print("[STARTUP] é‹è¡Œç’°å¢ƒ: Docker", flush=True)
else:
    # æœ¬åœ°æ¸¬è©¦ç’°å¢ƒ - ä½¿ç”¨å°ˆæ¡ˆè³‡æ–™å¤¾
    BASE_DIR = Path(__file__).parent.resolve()
    print(f"[STARTUP] é‹è¡Œç’°å¢ƒ: æœ¬åœ° ({BASE_DIR})", flush=True)

# çµ±ä¸€ä½¿ç”¨ç›¸åŒçš„å­è³‡æ–™å¤¾
CONFIG_DIR = BASE_DIR / 'config'
DOWNLOAD_DIR = BASE_DIR / 'downloads'
TEMP_DIR = BASE_DIR / 'temp'

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
CONFIG_DIR.mkdir(parents=True, exist_ok=True)
DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)
TEMP_DIR.mkdir(parents=True, exist_ok=True)

# æ—¥èªŒè¨­å®š
log_file = CONFIG_DIR / 'bot.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(str(log_file), encoding='utf-8')
    ]
)
logger = logging.getLogger('HentaiFetcher')

# ä¸‹è¼‰ä½‡åˆ— - çµæ§‹: (url, channel_id, status_message_id)
download_queue: Queue = Queue()

# é€²åº¦æ¢è¨­å®š
PROGRESS_UPDATE_INTERVAL = 3  # æ¯ 3 ç§’æ›´æ–°ä¸€æ¬¡é€²åº¦
SECONDS_PER_PAGE = 3.6  # é ä¼°æ¯é ä¸‹è¼‰æ™‚é–“ï¼ˆå¯¦æ¸¬å¹³å‡å€¼ï¼‰
PROGRESS_BAR_WIDTH = 15  # é€²åº¦æ¢å¯¬åº¦ï¼ˆæ ¼æ•¸ï¼‰

# PDF Web å­˜å–è¨­å®š
PDF_WEB_BASE_URL = "http://192.168.0.32:8888"  # Web Station åŸºç¤ URL


def create_progress_bar(current: int, total: int, width: int = PROGRESS_BAR_WIDTH) -> str:
    """
    å‰µå»º emoji é€²åº¦æ¢
    
    Args:
        current: ç›®å‰å®Œæˆæ•¸é‡
        total: ç¸½æ•¸é‡
        width: é€²åº¦æ¢å¯¬åº¦ï¼ˆæ ¼æ•¸ï¼‰
    
    Returns:
        é€²åº¦æ¢å­—ä¸²ï¼Œä¾‹å¦‚ï¼šğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œâ¬œâ¬œ 50%
    """
    if total <= 0:
        return "â¬œ" * width + " 0%"
    
    percentage = min(current / total, 1.0)
    filled = int(percentage * width)
    empty = width - filled
    
    bar = "ğŸŸ©" * filled + "â¬œ" * empty
    percent_text = f"{int(percentage * 100)}%"
    
    return f"{bar} {percent_text}"


# è¨Šæ¯å»é‡ï¼ˆé¿å…é‡è¤‡è™•ç†åŒä¸€è¨Šæ¯ï¼‰
processed_messages: set = set()

# å°ˆç”¨é »é“è¨­å®š - åœ¨é€™äº›é »é“ä¸­ä¸éœ€è¦ !dl å‰ç¶´
# å¯è¨­å®šé »é“åç¨±æˆ–é »é“ IDï¼ˆè¨­å®šåç¨±æ›´æ–¹ä¾¿ï¼‰
DEDICATED_CHANNEL_NAMES = ['hentaifetcher', 'hentai-fetcher', 'nhentai']  # é »é“åç¨±
DEDICATED_CHANNEL_IDS = []  # æˆ–ç›´æ¥è¨­å®šé »é“ ID
MAX_PROCESSED_MESSAGES = 1000  # æœ€å¤šä¿ç•™ 1000 ç­†è¨˜éŒ„

def is_message_processed(message_id: int) -> bool:
    """æª¢æŸ¥è¨Šæ¯æ˜¯å¦å·²è™•ç†é"""
    global processed_messages
    if message_id in processed_messages:
        return True
    
    # æ¸…ç†éèˆŠçš„è¨˜éŒ„
    if len(processed_messages) >= MAX_PROCESSED_MESSAGES:
        # æ¸…é™¤ä¸€åŠçš„è¨˜éŒ„
        processed_messages = set(list(processed_messages)[MAX_PROCESSED_MESSAGES // 2:])
    
    processed_messages.add(message_id)
    return False

# ==================== å·¥å…·å‡½å¼ ====================

def parse_input_to_urls(input_text: str) -> List[str]:
    """
    è§£æä½¿ç”¨è€…è¼¸å…¥ï¼Œæ”¯æ´å¤šç¨®æ ¼å¼ï¼š
    - å®Œæ•´ç¶²å€: https://nhentai.net/g/123456/
    - ç´”æ•¸å­—: 123456
    - å¤šå€‹è¼¸å…¥ï¼ˆç©ºç™½ã€é€—è™Ÿã€æ›è¡Œåˆ†éš”ï¼‰
    - æ··åˆè¼¸å…¥: 421633 https://nhentai.net/g/607769/ 613358
    
    Args:
        input_text: ä½¿ç”¨è€…è¼¸å…¥çš„æ–‡å­—
    
    Returns:
        è§£æå¾Œçš„å®Œæ•´ URL åˆ—è¡¨
    """
    urls = []
    
    # æ¨™æº–åŒ–æ›è¡Œç¬¦è™Ÿï¼ˆè™•ç† Windows/Mac/Linux ä¸åŒçš„æ›è¡Œï¼‰
    normalized_text = input_text.replace('\r\n', '\n').replace('\r', '\n')
    
    # Debug æ—¥èªŒ
    logger.debug(f"åŸå§‹è¼¸å…¥: {repr(input_text)}")
    logger.debug(f"æ¨™æº–åŒ–å¾Œ: {repr(normalized_text)}")
    
    # æŒ‰è¡Œåˆ†å‰²è™•ç†
    lines = normalized_text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # æ¯è¡Œå¯èƒ½æœ‰å¤šå€‹é …ç›®ï¼ˆç©ºç™½æˆ–é€—è™Ÿåˆ†éš”ï¼‰
        parts = re.split(r'[\s,;]+', line)
        
        for part in parts:
            part = part.strip()
            if not part:
                continue
            
            # å¦‚æœæ˜¯å®Œæ•´ URL
            if part.startswith(('http://', 'https://')):
                # æ¸…ç† URL çµå°¾å¯èƒ½çš„æ¨™é»ç¬¦è™Ÿ
                url = part.rstrip('.,;')
                urls.append(url)
            # å¦‚æœæ˜¯ç´”æ•¸å­—
            elif part.isdigit():
                urls.append(f"https://nhentai.net/g/{part}/")
            # å˜—è©¦æå–æ•¸å­—ï¼ˆä¾‹å¦‚: g/123456 æˆ– #123456ï¼‰
            else:
                match = re.search(r'(\d{4,7})', part)
                if match:
                    urls.append(f"https://nhentai.net/g/{match.group(1)}/")
    
    # å»é™¤é‡è¤‡ä¸¦ä¿æŒé †åº
    seen = set()
    unique_urls = []
    for url in urls:
        if url not in seen:
            seen.add(url)
            unique_urls.append(url)
    
    logger.info(f"è§£æåˆ° {len(unique_urls)} å€‹ URL")
    return unique_urls


def sanitize_filename(name: str, max_length: int = 200) -> str:
    """
    æ¸…ç†æª”æ¡ˆåç¨±ï¼Œç§»é™¤ä¸åˆæ³•å­—å…ƒ
    
    Args:
        name: åŸå§‹åç¨±
        max_length: æœ€å¤§é•·åº¦é™åˆ¶ï¼ˆé è¨­ 200ï¼Œä¿ç•™å®Œæ•´æ¨™é¡Œï¼‰
    
    Returns:
        æ¸…ç†å¾Œçš„å®‰å…¨æª”æ¡ˆåç¨±
    """
    # ç§»é™¤æˆ–æ›¿æ›ä¸åˆæ³•çš„æª”æ¡ˆåç¨±å­—å…ƒ
    invalid_chars = r'[<>:"/\\|?*\x00-\x1f]'
    sanitized = re.sub(invalid_chars, '_', name)
    
    # ç§»é™¤å‰å¾Œç©ºç™½å’Œé»
    sanitized = sanitized.strip(' .')
    
    # åªåœ¨è¶…éç³»çµ±é™åˆ¶æ™‚æ‰æˆªæ–·ï¼ˆLinux æª”åä¸Šé™ 255ï¼‰
    if max_length and len(sanitized) > max_length:
        sanitized = sanitized[:max_length].strip(' .')
    
    # å¦‚æœçµæœç‚ºç©ºï¼Œä½¿ç”¨é è¨­åç¨±
    if not sanitized:
        sanitized = f"download_{int(time.time())}"
    
    return sanitized


def generate_eagle_id() -> str:
    """
    ç”Ÿæˆ Eagle ç›¸å®¹çš„å”¯ä¸€ ID (åŸºæ–¼æ™‚é–“æˆ³)
    
    Returns:
        å”¯ä¸€è­˜åˆ¥ç¢¼å­—ä¸²
    """
    return f"L{int(datetime.now().timestamp() * 1000)}"


def check_already_downloaded(gallery_id: str) -> tuple[bool, Optional[dict]]:
    """
    æª¢æŸ¥ gallery æ˜¯å¦å·²ç¶“ä¸‹è¼‰é (å­˜åœ¨æ–¼ Eagle Library)
    
    Args:
        gallery_id: nhentai Gallery ID
    
    Returns:
        (å·²å­˜åœ¨, çµæœè³‡è¨Š) - å¦‚æœå·²å­˜åœ¨ï¼ŒçµæœåŒ…å« web_url, title ç­‰
    """
    try:
        from eagle_library import EagleLibrary
        eagle = EagleLibrary()
        result = eagle.find_by_nhentai_id(gallery_id)
        if result:
            return True, result
        return False, None
    except Exception as e:
        logger.warning(f"æª¢æŸ¥é‡è¤‡ä¸‹è¼‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False, None


def verify_nhentai_url(gallery_id: str) -> tuple[bool, str]:
    """
    é©—è­‰ nhentai gallery æ˜¯å¦å­˜åœ¨ä¸”å¯è¨ªå•
    
    Args:
        gallery_id: Gallery ID
    
    Returns:
        (æ˜¯å¦æœ‰æ•ˆ, æ¨™é¡Œæˆ–éŒ¯èª¤è¨Šæ¯)
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            title = data.get('title', {}).get('english', '') or data.get('title', {}).get('japanese', '')
            return True, title[:50] + '...' if len(title) > 50 else title
        elif response.status_code == 404:
            return False, "Gallery ä¸å­˜åœ¨"
        else:
            return False, f"HTTP {response.status_code}"
    except requests.Timeout:
        return False, "é€£ç·šé€¾æ™‚"
    except Exception as e:
        return False, str(e)


def get_nhentai_page_count(gallery_id: str) -> tuple[int, str, str]:
    """
    å¾ nhentai API ç²å–é æ•¸ã€æ¨™é¡Œå’Œ media_id
    
    Args:
        gallery_id: Gallery ID
    
    Returns:
        (é æ•¸, æ¨™é¡Œ, media_id) - å¤±æ•—æ™‚é æ•¸ç‚º 0
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            pages = data.get('num_pages', 0)
            title = data.get('title', {}).get('japanese', '') or data.get('title', {}).get('english', '')
            media_id = str(data.get('media_id', ''))
            return pages, title[:40] + '...' if len(title) > 40 else title, media_id
    except:
        pass
    
    return 0, "", ""


def fetch_nhentai_extra_info(gallery_id: str) -> Dict[str, Any]:
    """
    å¾ nhentai API ç²å–é¡å¤–è³‡è¨Šï¼ˆæ”¶è—æ•¸ã€è©•è«–ç­‰ï¼‰
    
    Args:
        gallery_id: Gallery ID
    
    Returns:
        åŒ…å« favorites å’Œ comments çš„å­—å…¸
    """
    result = {
        'favorites': 0,
        'comments': []
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    # ç²å–æ”¶è—æ•¸
    try:
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=30)
        if response.status_code == 200:
            data = response.json()
            result['favorites'] = data.get('num_favorites', 0)
            logger.info(f"ç²å–æ”¶è—æ•¸: {result['favorites']}")
    except Exception as e:
        logger.warning(f"ç²å–æ”¶è—æ•¸å¤±æ•—: {e}")
    
    # ç²å–è©•è«–
    try:
        comments_url = f"https://nhentai.net/api/gallery/{gallery_id}/comments"
        response = requests.get(comments_url, headers=headers, timeout=30)
        if response.status_code == 200:
            result['comments'] = response.json()
            logger.info(f"ç²å–è©•è«–æ•¸: {len(result['comments'])}")
    except Exception as e:
        logger.warning(f"ç²å–è©•è«–å¤±æ•—: {e}")
    
    return result


def download_nhentai_cover(gallery_id: str, save_path: Path) -> bool:
    """
    å¾ nhentai ä¸‹è¼‰å°é¢åœ–ç‰‡
    
    Args:
        gallery_id: Gallery ID
        save_path: ä¿å­˜è·¯å¾‘ï¼ˆè³‡æ–™å¤¾ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        # ç²å– gallery è³‡è¨Š
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=30)
        if response.status_code != 200:
            logger.warning(f"ç„¡æ³•ç²å– gallery è³‡è¨Š: {gallery_id}")
            return False
        
        data = response.json()
        media_id = data.get('media_id', '')
        if not media_id:
            logger.warning(f"æ‰¾ä¸åˆ° media_id: {gallery_id}")
            return False
        
        # ç²å–å°é¢æ ¼å¼
        images = data.get('images', {})
        cover = images.get('cover', {})
        cover_type = cover.get('t', 'j')  # j=jpg, p=png, g=gif
        
        ext_map = {'j': 'jpg', 'p': 'png', 'g': 'gif'}
        ext = ext_map.get(cover_type, 'jpg')
        
        # å˜—è©¦å¤šå€‹ URL æ ¼å¼ä¸‹è¼‰å°é¢
        cover_urls = [
            f"https://t.nhentai.net/galleries/{media_id}/cover.{ext}",
            f"https://t3.nhentai.net/galleries/{media_id}/cover.{ext}",
            f"https://i.nhentai.net/galleries/{media_id}/cover.{ext}",
            f"https://i5.nhentai.net/galleries/{media_id}/cover.{ext}",
        ]
        
        for cover_url in cover_urls:
            try:
                logger.info(f"å˜—è©¦ä¸‹è¼‰å°é¢: {cover_url}")
                response = requests.get(cover_url, headers=headers, timeout=30)
                if response.status_code == 200:
                    cover_path = save_path / f"cover.{ext}"
                    with open(cover_path, 'wb') as f:
                        f.write(response.content)
                    logger.info(f"å°é¢å·²ä¿å­˜: {cover_path}")
                    return True
            except Exception as e:
                logger.debug(f"å˜—è©¦ {cover_url} å¤±æ•—: {e}")
                continue
        
        logger.warning(f"æ‰€æœ‰å°é¢ URL éƒ½å¤±æ•—")
        return False
            
    except Exception as e:
        logger.error(f"ä¸‹è¼‰å°é¢éŒ¯èª¤: {e}")
        return False


def download_nhentai_first_page(gallery_id: str, save_path: Path) -> bool:
    """
    å¾ nhentai ä¸‹è¼‰ç¬¬ä¸€é åœ–ç‰‡ä½œç‚ºå°é¢ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
    
    Args:
        gallery_id: Gallery ID
        save_path: ä¿å­˜è·¯å¾‘ï¼ˆè³‡æ–™å¤¾ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        # ç²å– gallery è³‡è¨Š
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=30)
        if response.status_code != 200:
            logger.warning(f"ç„¡æ³•ç²å– gallery è³‡è¨Š: {gallery_id}")
            return False
        
        data = response.json()
        media_id = data.get('media_id', '')
        if not media_id:
            logger.warning(f"æ‰¾ä¸åˆ° media_id: {gallery_id}")
            return False
        
        # ç²å–ç¬¬ä¸€é æ ¼å¼
        images = data.get('images', {})
        pages = images.get('pages', [])
        if not pages:
            logger.warning(f"æ‰¾ä¸åˆ°é é¢è³‡è¨Š: {gallery_id}")
            return False
        
        first_page = pages[0]
        page_type = first_page.get('t', 'j')  # j=jpg, p=png, g=gif, w=webp
        
        ext_map = {'j': 'jpg', 'p': 'png', 'g': 'gif', 'w': 'webp'}
        ext = ext_map.get(page_type, 'jpg')
        
        # å˜—è©¦å¤šå€‹ URL æ ¼å¼ä¸‹è¼‰ç¬¬ä¸€é 
        first_page_urls = [
            f"https://i.nhentai.net/galleries/{media_id}/1.{ext}",
            f"https://i2.nhentai.net/galleries/{media_id}/1.{ext}",
            f"https://i5.nhentai.net/galleries/{media_id}/1.{ext}",
            f"https://i7.nhentai.net/galleries/{media_id}/1.{ext}",
        ]
        
        for page_url in first_page_urls:
            try:
                logger.info(f"å˜—è©¦ä¸‹è¼‰ç¬¬ä¸€é ä½œç‚ºå°é¢: {page_url}")
                response = requests.get(page_url, headers=headers, timeout=30)
                if response.status_code == 200:
                    cover_path = save_path / f"cover.{ext}"
                    with open(cover_path, 'wb') as f:
                        f.write(response.content)
                    logger.info(f"ç¬¬ä¸€é å·²ä¿å­˜ç‚ºå°é¢: {cover_path}")
                    return True
            except Exception as e:
                logger.debug(f"å˜—è©¦ {page_url} å¤±æ•—: {e}")
                continue
        
        logger.warning(f"æ‰€æœ‰ç¬¬ä¸€é  URL éƒ½å¤±æ•—")
        return False
            
    except Exception as e:
        logger.error(f"ä¸‹è¼‰ç¬¬ä¸€é éŒ¯èª¤: {e}")
        return False


def get_first_image_as_cover(folder_path: Path) -> bool:
    """
    ä½¿ç”¨è³‡æ–™å¤¾å…§çš„ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢
    
    Args:
        folder_path: è³‡æ–™å¤¾è·¯å¾‘
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp'}
        
        # æ‰¾åˆ°æ‰€æœ‰åœ–ç‰‡ï¼ˆæ’é™¤å·²æœ‰çš„ cover é–‹é ­æª”æ¡ˆï¼‰
        images = []
        for file in folder_path.iterdir():
            if file.is_file() and file.suffix.lower() in image_extensions:
                # æ’é™¤å°é¢æª”æ¡ˆ
                if not file.stem.lower().startswith('cover'):
                    images.append(file)
        
        if not images:
            logger.warning(f"è³‡æ–™å¤¾å…§æ²’æœ‰å¯ç”¨çš„åœ–ç‰‡: {folder_path}")
            return False
        
        # æŒ‰æª”åè‡ªç„¶æ’åºï¼Œå–ç¬¬ä¸€å¼µ
        images.sort(key=lambda x: natural_sort_key(x.name))
        first_image = images[0]
        
        # è¤‡è£½ç‚ºå°é¢
        cover_ext = first_image.suffix.lower()
        cover_path = folder_path / f"cover{cover_ext}"
        
        import shutil
        shutil.copy2(first_image, cover_path)
        logger.info(f"å·²ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢: {first_image.name} -> cover{cover_ext}")
        return True
        
    except Exception as e:
        logger.error(f"ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢å¤±æ•—: {e}")
        return False


def format_comment_time(timestamp: int) -> str:
    """æ ¼å¼åŒ–è©•è«–æ™‚é–“ç‚ºç›¸å°æ™‚é–“"""
    dt = datetime.fromtimestamp(timestamp)
    now = datetime.now()
    diff = now - dt
    
    if diff.days > 30:
        months = diff.days // 30
        weeks = (diff.days % 30) // 7
        if weeks > 0:
            return f"{months} å€‹æœˆ, {weeks} é€±å‰"
        return f"{months} å€‹æœˆå‰"
    elif diff.days > 7:
        weeks = diff.days // 7
        return f"{weeks} é€±å‰"
    elif diff.days > 0:
        return f"{diff.days} å¤©å‰"
    elif diff.seconds > 3600:
        return f"{diff.seconds // 3600} å°æ™‚å‰"
    else:
        return f"{diff.seconds // 60} åˆ†é˜å‰"


def format_comments_for_annotation(comments: list, max_comments: int = 5) -> str:
    """
    æ ¼å¼åŒ–è©•è«–ç”¨æ–¼ annotation
    
    Args:
        comments: è©•è«–åˆ—è¡¨
        max_comments: æœ€å¤§é¡¯ç¤ºè©•è«–æ•¸
    
    Returns:
        æ ¼å¼åŒ–çš„è©•è«–å­—ä¸²
    """
    if not comments:
        return ""
    
    lines = ["\nğŸ’¬ ç”¨æˆ¶è©•è«–:"]
    
    for i, comment in enumerate(comments[:max_comments]):
        username = comment.get('poster', {}).get('username', 'åŒ¿å')
        body = comment.get('body', '')
        post_date = comment.get('post_date', 0)
        time_str = format_comment_time(post_date) if post_date else ''
        
        lines.append(f"  [{username}] ({time_str})")
        lines.append(f"  {body}")
        if i < len(comments[:max_comments]) - 1:
            lines.append("")
    
    if len(comments) > max_comments:
        lines.append(f"  ... é‚„æœ‰ {len(comments) - max_comments} å‰‡è©•è«–")
    
    return "\n".join(lines)


def parse_gallery_dl_info(info_path: Path) -> Optional[Dict[str, Any]]:
    """
    è§£æ gallery-dl ç”Ÿæˆçš„ info.json æˆ– gallery_metadata.json
    
    gallery-dl --dump-json è¼¸å‡ºæ ¼å¼:
    {
        "title": "...",
        "title_en": "...",
        "title_ja": "...",
        "gallery_id": 123456,
        "count": 34,
        "type": "doujinshi",
        "artist": ["name"],
        "group": ["name"],
        "parody": ["name"],
        "characters": [],
        "language": "Chinese",
        "tags": ["tag1", "tag2", ...]
    }
    
    Args:
        info_path: info.json æª”æ¡ˆè·¯å¾‘
    
    Returns:
        è§£æå¾Œçš„ metadata å­—å…¸ï¼Œå¤±æ•—å‰‡è¿”å› None
    """
    try:
        with open(info_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # åˆå§‹åŒ–çµæœçµæ§‹ï¼ˆæ“´å±•ç‰ˆï¼‰
        result = {
            'title': '',
            'title_japanese': '',  # æ—¥æ–‡å‰¯æ¨™é¡Œ
            'title_pretty': '',    # ç°¡çŸ­æ¨™é¡Œ
            'tags': [],
            'url': '',
            'gallery_id': '',
            'pages': 0,
            'favorites': 0,
            'category': '',
            'type': '',
            'artist': [],
            'group': [],
            'parody': [],
            'character': [],
            'language': '',
        }
        
        # è™•ç† gallery-dl è¼¸å‡ºæ ¼å¼
        if isinstance(data, dict):
            # ===== æ¨™é¡Œè™•ç† =====
            # gallery-dl æ ¼å¼: title, title_en, title_ja éƒ½æ˜¯å­—ä¸²
            if 'title' in data:
                if isinstance(data['title'], dict):
                    # èˆŠç‰ˆ nhentai API æ ¼å¼: {"english": "...", "japanese": "...", "pretty": "..."}
                    result['title'] = (
                        data['title'].get('english') or 
                        data['title'].get('pretty') or 
                        data['title'].get('japanese') or 
                        ''
                    )
                    result['title_japanese'] = data['title'].get('japanese', '')
                    result['title_pretty'] = data['title'].get('pretty', '')
                else:
                    result['title'] = str(data['title'])
            
            # gallery-dl ä½¿ç”¨ title_en å’Œ title_ja
            if 'title_en' in data:
                if not result['title']:
                    result['title'] = data['title_en']
            
            if 'title_ja' in data:
                result['title_japanese'] = data['title_ja']
            
            # ===== Gallery ID =====
            if 'gallery_id' in data:
                result['gallery_id'] = str(data['gallery_id'])
            elif 'id' in data:
                result['gallery_id'] = str(data['id'])
            
            # ===== é æ•¸ =====
            # gallery-dl ä½¿ç”¨ countï¼Œnhentai API ä½¿ç”¨ num_pages
            if 'count' in data:
                result['pages'] = int(data['count'])
            elif 'num_pages' in data:
                result['pages'] = int(data['num_pages'])
            
            # ===== æ”¶è—æ•¸ =====
            if 'num_favorites' in data:
                result['favorites'] = int(data['num_favorites'])
            
            # ===== é¡å‹ (doujinshi, manga, etc.) =====
            if 'type' in data:
                result['type'] = data['type']
                result['category'] = data['type']  # å…¼å®¹èˆŠæ ¼å¼
            
            # ===== ä½œè€…åˆ—è¡¨ =====
            if 'artist' in data:
                if isinstance(data['artist'], list):
                    result['artist'] = data['artist']
                    for artist in data['artist']:
                        result['tags'].append(f"artist:{artist}")
                elif isinstance(data['artist'], str):
                    result['artist'] = [data['artist']]
                    result['tags'].append(f"artist:{data['artist']}")
            
            # ===== ç¤¾åœ˜åˆ—è¡¨ =====
            if 'group' in data:
                if isinstance(data['group'], list):
                    result['group'] = data['group']
                    for group in data['group']:
                        result['tags'].append(f"group:{group}")
                elif isinstance(data['group'], str):
                    result['group'] = [data['group']]
                    result['tags'].append(f"group:{data['group']}")
            
            # ===== åŸä½œåˆ—è¡¨ =====
            if 'parody' in data:
                if isinstance(data['parody'], list):
                    result['parody'] = data['parody']
                    for parody in data['parody']:
                        result['tags'].append(f"parody:{parody}")
                elif isinstance(data['parody'], str):
                    result['parody'] = [data['parody']]
                    result['tags'].append(f"parody:{data['parody']}")
            
            # ===== è§’è‰²åˆ—è¡¨ =====
            # gallery-dl ä½¿ç”¨ characters (è¤‡æ•¸)
            if 'characters' in data:
                if isinstance(data['characters'], list):
                    result['character'] = data['characters']
                    for char in data['characters']:
                        result['tags'].append(f"character:{char}")
            elif 'character' in data:
                if isinstance(data['character'], list):
                    result['character'] = data['character']
                    for char in data['character']:
                        result['tags'].append(f"character:{char}")
            
            # ===== èªè¨€ =====
            if 'language' in data:
                result['language'] = data['language']
                result['tags'].append(f"language:{data['language']}")
            
            # ===== æ¨™ç±¤è™•ç† =====
            if 'tags' in data:
                tags = data['tags']
                if isinstance(tags, list):
                    for tag in tags:
                        if isinstance(tag, dict):
                            # èˆŠç‰ˆ nhentai API æ ¼å¼: {type, name}
                            tag_name = tag.get('name', '')
                            tag_type = tag.get('type', '')
                            if tag_name:
                                if tag_type == 'category':
                                    result['category'] = tag_name
                                    result['tags'].append(f"category:{tag_name}")
                                elif tag_type == 'artist':
                                    if tag_name not in result['artist']:
                                        result['artist'].append(tag_name)
                                        result['tags'].append(f"artist:{tag_name}")
                                elif tag_type == 'group':
                                    if tag_name not in result['group']:
                                        result['group'].append(tag_name)
                                        result['tags'].append(f"group:{tag_name}")
                                elif tag_type == 'parody':
                                    if tag_name not in result['parody']:
                                        result['parody'].append(tag_name)
                                        result['tags'].append(f"parody:{tag_name}")
                                elif tag_type == 'character':
                                    if tag_name not in result['character']:
                                        result['character'].append(tag_name)
                                        result['tags'].append(f"character:{tag_name}")
                                elif tag_type == 'language':
                                    result['language'] = tag_name
                                    result['tags'].append(f"language:{tag_name}")
                                elif tag_type in ['tag', '']:
                                    result['tags'].append(tag_name)
                                else:
                                    result['tags'].append(f"{tag_type}:{tag_name}")
                        elif isinstance(tag, str):
                            # gallery-dl æ ¼å¼: ç›´æ¥å­—ä¸²é™£åˆ—
                            result['tags'].append(tag)
                elif isinstance(tags, str):
                    result['tags'] = [t.strip() for t in tags.split(',') if t.strip()]
            
            # ===== é¡å‹æ¨™ç±¤ =====
            if result['type']:
                result['tags'].append(f"type:{result['type']}")
            
            # ===== URL è™•ç† =====
            if 'gallery_url' in data:
                result['url'] = data['gallery_url']
            elif 'url' in data:
                result['url'] = data['url']
            
            # å˜—è©¦å¾ gallery_id æ§‹å»º URL
            if not result['url'] and result['gallery_id']:
                result['url'] = f"https://nhentai.net/g/{result['gallery_id']}/"
        
        # å»é™¤é‡è¤‡æ¨™ç±¤
        result['tags'] = list(dict.fromkeys(result['tags']))
        
        logger.info(f"è§£æåˆ°æ¨™é¡Œ: {result['title']}")
        logger.info(f"  æ—¥æ–‡æ¨™é¡Œ: {result['title_japanese']}")
        logger.info(f"  Gallery ID: {result['gallery_id']}, é æ•¸: {result['pages']}")
        logger.info(f"  ä½œè€…: {result['artist']}, ç¤¾åœ˜: {result['group']}")
        logger.info(f"  é¡å‹: {result['type']}, èªè¨€: {result['language']}")
        logger.info(f"  æ¨™ç±¤æ•¸: {len(result['tags'])}")
        return result
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON è§£æéŒ¯èª¤: {e}")
        return None
    except Exception as e:
        logger.error(f"è§£æ info.json æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def create_eagle_metadata(
    title: str,
    url: str,
    tags: List[str],
    annotation: str = "",
    extra_info: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    å»ºç«‹ Eagle ç›¸å®¹çš„ metadata.json å…§å®¹
    
    Eagle æ¨™æº–æ¬„ä½ï¼š
    - id: å”¯ä¸€è­˜åˆ¥ç¢¼
    - name: åç¨±
    - tags: æ¨™ç±¤åˆ—è¡¨ (Array)
    - url / website: ä¾†æºç¶²å€
    - annotation: è¨»é‡‹/å‚™è¨» (å†—é•·è³‡è¨Šæ”¾é€™è£¡)
    
    Args:
        title: æ¼«ç•«æ¨™é¡Œ
        url: ä¾†æºç¶²å€
        tags: æ¨™ç±¤åˆ—è¡¨
        annotation: åŸºæœ¬å‚™è¨»
        extra_info: é¡å¤–è³‡è¨Šï¼ˆå‰¯æ¨™é¡Œã€é æ•¸ã€æ”¶è—æ•¸ç­‰ï¼‰
    
    Returns:
        Eagle metadata å­—å…¸
    """
    # å»ºç«‹å®Œæ•´çš„ tags åˆ—è¡¨
    all_tags = list(tags)  # è¤‡è£½åŸæœ‰æ¨™ç±¤
    
    # å»ºç«‹ annotation å…§å®¹
    annotation_lines = []
    
    if extra_info:
        # ===== åŠ å…¥é¡å¤–æ¨™ç±¤ =====
        # é¡å‹æ¨™ç±¤
        if extra_info.get('type'):
            type_tag = f"type:{extra_info['type']}"
            if type_tag not in all_tags:
                all_tags.append(type_tag)
        
        # èªè¨€æ¨™ç±¤
        if extra_info.get('language'):
            lang_tag = f"language:{extra_info['language']}"
            if lang_tag not in all_tags:
                all_tags.append(lang_tag)
        
        # ä½œè€…æ¨™ç±¤
        if extra_info.get('artist'):
            for artist in extra_info['artist']:
                artist_tag = f"artist:{artist}"
                if artist_tag not in all_tags:
                    all_tags.append(artist_tag)
        
        # ç¤¾åœ˜æ¨™ç±¤
        if extra_info.get('group'):
            for group in extra_info['group']:
                group_tag = f"group:{group}"
                if group_tag not in all_tags:
                    all_tags.append(group_tag)
        
        # åŸä½œæ¨™ç±¤
        if extra_info.get('parody'):
            for parody in extra_info['parody']:
                parody_tag = f"parody:{parody}"
                if parody_tag not in all_tags:
                    all_tags.append(parody_tag)
        
        # è§’è‰²æ¨™ç±¤
        if extra_info.get('character'):
            for char in extra_info['character']:
                char_tag = f"character:{char}"
                if char_tag not in all_tags:
                    all_tags.append(char_tag)
        
        # ===== å»ºç«‹ annotation å…§å®¹ =====
        # è‹±æ–‡æ¨™é¡Œï¼ˆå¦‚æœä¸»æ¨™é¡Œæ˜¯æ—¥æ–‡ï¼Œé¡¯ç¤ºè‹±æ–‡æ¨™é¡Œä½œç‚ºåƒè€ƒï¼‰
        if extra_info.get('title_english'):
            annotation_lines.append(f"ğŸ“– è‹±æ–‡æ¨™é¡Œ: {extra_info['title_english']}")
        
        # é æ•¸
        if extra_info.get('pages'):
            annotation_lines.append(f"ğŸ“„ é æ•¸: {extra_info['pages']}")
        
        # æ”¶è—æ•¸
        if extra_info.get('favorites') and extra_info['favorites'] > 0:
            annotation_lines.append(f"â¤ï¸ æ”¶è—æ•¸: {extra_info['favorites']}")
        
        # é¡å‹
        if extra_info.get('type'):
            annotation_lines.append(f"ğŸ“ é¡å‹: {extra_info['type']}")
        
        # èªè¨€
        if extra_info.get('language'):
            annotation_lines.append(f"ğŸŒ èªè¨€: {extra_info['language']}")
        
        # ä½œè€…
        if extra_info.get('artist'):
            annotation_lines.append(f"ğŸ¨ ä½œè€…: {', '.join(extra_info['artist'])}")
        
        # ç¤¾åœ˜
        if extra_info.get('group'):
            annotation_lines.append(f"ğŸ‘¥ ç¤¾åœ˜: {', '.join(extra_info['group'])}")
        
        # åŸä½œ
        if extra_info.get('parody'):
            annotation_lines.append(f"ğŸ¬ åŸä½œ: {', '.join(extra_info['parody'])}")
        
        # è§’è‰²
        if extra_info.get('character') and len(extra_info['character']) > 0:
            annotation_lines.append(f"ğŸ‘¤ è§’è‰²: {', '.join(extra_info['character'])}")
        
        # ID (æ”¾åœ¨è¼ƒä¸‹é¢)
        if extra_info.get('gallery_id'):
            annotation_lines.append(f"ğŸ“” ID: {extra_info['gallery_id']}")
        
        # ç”¨æˆ¶è©•è«–
        if extra_info.get('comments'):
            comments_text = format_comments_for_annotation(extra_info['comments'])
            if comments_text:
                annotation_lines.append(comments_text)
    
    # åŠ å…¥ä¸‹è¼‰æ™‚é–“
    annotation_lines.append(f"\nâ° ä¸‹è¼‰æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    annotation_lines.append("ğŸ“¥ Downloaded via HentaiFetcher Bot")
    
    # å¦‚æœæœ‰é¡å¤–çš„åŸºæœ¬å‚™è¨»ï¼ŒåŠ åœ¨æœ€å¾Œ
    if annotation and annotation != "Downloaded via HentaiFetcher Bot":
        annotation_lines.append(f"\n{annotation}")
    
    # å»é™¤é‡è¤‡æ¨™ç±¤
    all_tags = list(dict.fromkeys(all_tags))
    
    # å»ºç«‹æœ€çµ‚ metadata
    metadata = {
        "id": generate_eagle_id(),
        "name": title,
        "url": url,
        "tags": all_tags,
        "annotation": "\n".join(annotation_lines)
    }
    
    return metadata


def find_info_json(directory: Path) -> Optional[Path]:
    """
    éè¿´æœå°‹ info.json æª”æ¡ˆ
    
    Args:
        directory: æœå°‹èµ·å§‹ç›®éŒ„
    
    Returns:
        æ‰¾åˆ°çš„ info.json è·¯å¾‘ï¼Œæœªæ‰¾åˆ°å‰‡è¿”å› None
    """
    # å„ªå…ˆæœå°‹æˆ‘å€‘è‡ªå·±ç”Ÿæˆçš„ metadata æª”æ¡ˆ
    our_metadata = directory / "gallery_metadata.json"
    if our_metadata.exists():
        return our_metadata
    
    # ç›´æ¥åœ¨ç›®éŒ„ä¸‹æœå°‹
    for json_file in directory.rglob('*.json'):
        if json_file.name == 'info.json' or 'info' in json_file.name.lower():
            return json_file
    
    # ä¹Ÿå˜—è©¦æœå°‹å…¶ä»–å¯èƒ½çš„ metadata æª”æ¡ˆ
    for json_file in directory.rglob('*.json'):
        return json_file  # è¿”å›ç¬¬ä¸€å€‹æ‰¾åˆ°çš„ JSON
    
    return None


def find_images(directory: Path) -> List[Path]:
    """
    æœå°‹ç›®éŒ„ä¸‹çš„æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ
    
    Args:
        directory: æœå°‹ç›®éŒ„
    
    Returns:
        åœ–ç‰‡æª”æ¡ˆè·¯å¾‘åˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
    """
    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp'}
    images = []
    
    for file in directory.rglob('*'):
        # æ’é™¤ .part æª”æ¡ˆï¼ˆæœªå®Œæˆçš„ä¸‹è¼‰ï¼‰
        if file.suffix.lower() in image_extensions and not file.name.endswith('.part'):
            images.append(file)
    
    # æŒ‰æª”åè‡ªç„¶æ’åº
    def natural_sort_key(path: Path):
        # æå–æ•¸å­—é€²è¡Œè‡ªç„¶æ’åº
        numbers = re.findall(r'\d+', path.stem)
        return [int(n) for n in numbers] if numbers else [path.stem]
    
    images.sort(key=natural_sort_key)
    return images


# ==================== ä¸‹è¼‰è™•ç†é¡åˆ¥ ====================

class DownloadProcessor:
    """
    ä¸‹è¼‰è™•ç†å™¨ï¼šè² è²¬åŸ·è¡Œ gallery-dlã€è½‰æ› PDF ä¸¦ç”Ÿæˆ metadata
    """
    
    def __init__(self, url: str, total_pages: int = 0, message_callback=None):
        """
        åˆå§‹åŒ–ä¸‹è¼‰è™•ç†å™¨
        
        Args:
            url: è¦ä¸‹è¼‰çš„ç¶²å€
            total_pages: é æœŸç¸½é æ•¸ï¼ˆç”¨æ–¼é€²åº¦è¨ˆç®—ï¼‰
            message_callback: ç‹€æ…‹æ›´æ–°å›èª¿å‡½å¼
        """
        self.url = url
        self.total_pages = total_pages
        self.message_callback = message_callback
        self.temp_path: Optional[Path] = None
        self.output_path: Optional[Path] = None
        self.last_error: str = ""
        self.download_complete = False  # ä¸‹è¼‰æ˜¯å¦å®Œæˆ
        self.pdf_progress = 0  # PDF è½‰æ›é€²åº¦ (0-100)
        self.pdf_converting = False  # æ˜¯å¦æ­£åœ¨è½‰æ› PDF
        
    def get_downloaded_count(self) -> int:
        """ç²å–å·²ä¸‹è¼‰çš„åœ–ç‰‡æ•¸é‡"""
        if not self.temp_path or not self.temp_path.exists():
            return 0
        return len(find_images(self.temp_path))
    
    def get_first_image_path(self) -> Path:
        """ç²å–ç¬¬ä¸€å¼µå·²ä¸‹è¼‰åœ–ç‰‡çš„è·¯å¾‘"""
        if not self.temp_path or not self.temp_path.exists():
            return None
        images = find_images(self.temp_path)
        if images:
            # æŒ‰æª”åæ’åºå–ç¬¬ä¸€å¼µ
            images.sort(key=lambda x: x.name)
            return images[0]
        return None
        
    async def send_status(self, message: str):
        """ç™¼é€ç‹€æ…‹è¨Šæ¯"""
        logger.info(message)
        if self.message_callback:
            try:
                await self.message_callback(message)
            except Exception as e:
                logger.warning(f"ç„¡æ³•ç™¼é€ç‹€æ…‹è¨Šæ¯: {e}")
    
    def download_with_gallery_dl(self) -> bool:
        """
        ä½¿ç”¨ gallery-dl ä¸‹è¼‰åœ–ç‰‡å’Œ metadata
        
        Returns:
            æˆåŠŸè¿”å› Trueï¼Œå¤±æ•—è¿”å› False
        """
        try:
            # å»ºç«‹å”¯ä¸€çš„æš«å­˜ç›®éŒ„ï¼ˆçµ±ä¸€ä½¿ç”¨ TEMP_DIRï¼‰
            self.temp_path = TEMP_DIR / f"dl_{int(time.time() * 1000)}"
            self.temp_path.mkdir(parents=True, exist_ok=True)
            
            print(f"[GALLERY-DL] ä¸‹è¼‰ç›®éŒ„: {self.temp_path}", flush=True)
            
            # æ ¹æ“šç’°å¢ƒé¸æ“‡ gallery-dl åŸ·è¡Œæ–¹å¼èˆ‡åƒæ•¸
            if IS_DOCKER:
                # Docker ç’°å¢ƒï¼šå…©éšæ®µä¸‹è¼‰
                # éšæ®µ 1: ä½¿ç”¨ gallery-dl --dump-json ç²å– metadata
                print(f"[GALLERY-DL] éšæ®µ1: ç²å– metadata...", flush=True)
                metadata_cmd = [
                    'gallery-dl',
                    '--dump-json',
                    '--user-agent', 'Mozilla/5.0',
                    self.url
                ]
                
                metadata_result = subprocess.run(
                    metadata_cmd,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                # è§£æä¸¦å„²å­˜ metadata
                if metadata_result.returncode == 0 and metadata_result.stdout.strip():
                    try:
                        # gallery-dl --dump-json è¼¸å‡ºçš„æ˜¯ JSON é™£åˆ—
                        metadata_list = json.loads(metadata_result.stdout)
                        if metadata_list and len(metadata_list) > 0:
                            # å–ç¬¬ä¸€å€‹å…ƒç´ çš„ metadataï¼ˆé€šå¸¸åŒ…å« gallery infoï¼‰
                            first_item = metadata_list[0]
                            if isinstance(first_item, list) and len(first_item) >= 2:
                                gallery_metadata = first_item[1]  # [url, metadata] æ ¼å¼
                            else:
                                gallery_metadata = first_item
                            
                            # å„²å­˜ metadata åˆ°æš«å­˜ç›®éŒ„
                            metadata_file = self.temp_path / "gallery_metadata.json"
                            with open(metadata_file, 'w', encoding='utf-8') as f:
                                json.dump(gallery_metadata, f, ensure_ascii=False, indent=2)
                            print(f"[GALLERY-DL] Metadata å·²å„²å­˜: {metadata_file}", flush=True)
                    except json.JSONDecodeError as e:
                        print(f"[GALLERY-DL] Metadata è§£æå¤±æ•—: {e}", flush=True)
                
                # éšæ®µ 2: ä½¿ç”¨ gallery-dl -g + aria2c å¤šç·šç¨‹ä¸‹è¼‰åœ–ç‰‡
                print(f"[GALLERY-DL] éšæ®µ2: å¤šç·šç¨‹ä¸‹è¼‰åœ–ç‰‡...", flush=True)
                cmd = (
                    f'gallery-dl --user-agent "Mozilla/5.0" -g "{self.url}" | '
                    f'aria2c -i - -x 8 -s 8 --user-agent="Mozilla/5.0" -d "{self.temp_path}"'
                )
                
                logger.info(f"åŸ·è¡ŒæŒ‡ä»¤: {cmd}")
                print(f"[GALLERY-DL+ARIA2] å‘½ä»¤: {cmd}", flush=True)
                
                # ä½¿ç”¨ shell=True åŸ·è¡Œç®¡é“å‘½ä»¤
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=900
                )
            else:
                # Windows ç’°å¢ƒï¼šå…©éšæ®µä¸‹è¼‰
                # éšæ®µ 1: ä½¿ç”¨ gallery-dl --dump-json ç²å– metadata
                print(f"[GALLERY-DL] éšæ®µ1: ç²å– metadata...", flush=True)
                metadata_cmd = [
                    sys.executable,
                    '-m', 'gallery_dl',
                    '--dump-json',
                    self.url
                ]
                
                metadata_result = subprocess.run(
                    metadata_cmd,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                # è§£æä¸¦å„²å­˜ metadata
                if metadata_result.returncode == 0 and metadata_result.stdout.strip():
                    try:
                        metadata_list = json.loads(metadata_result.stdout)
                        if metadata_list and len(metadata_list) > 0:
                            first_item = metadata_list[0]
                            if isinstance(first_item, list) and len(first_item) >= 2:
                                gallery_metadata = first_item[1]
                            else:
                                gallery_metadata = first_item
                            
                            metadata_file = self.temp_path / "gallery_metadata.json"
                            with open(metadata_file, 'w', encoding='utf-8') as f:
                                json.dump(gallery_metadata, f, ensure_ascii=False, indent=2)
                            print(f"[GALLERY-DL] Metadata å·²å„²å­˜: {metadata_file}", flush=True)
                    except json.JSONDecodeError as e:
                        print(f"[GALLERY-DL] Metadata è§£æå¤±æ•—: {e}", flush=True)
                
                # éšæ®µ 2: ä¸‹è¼‰åœ–ç‰‡
                print(f"[GALLERY-DL] éšæ®µ2: ä¸‹è¼‰åœ–ç‰‡...", flush=True)
                
                # è¨­å®šæª”è·¯å¾‘
                config_path = BASE_DIR / "config" / "gallery-dl.conf"
                
                cmd = [
                    sys.executable,
                    '-m', 'gallery_dl',
                    '--config', str(config_path),
                    '--dest', str(self.temp_path),
                    '--write-metadata',
                    self.url
                ]
                
                logger.info(f"åŸ·è¡ŒæŒ‡ä»¤: {' '.join(cmd)}")
                print(f"[GALLERY-DL] å‘½ä»¤: {cmd}", flush=True)
                
                # åŸ·è¡Œ gallery-dl å‘½ä»¤
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=900
                )
            print(f"[GALLERY-DL] åŸ·è¡Œå®Œæˆ", flush=True)
            
            # å¼·åˆ¶è¼¸å‡ºæ‰€æœ‰ gallery-dl æ—¥èªŒï¼ˆç”¨æ–¼é™¤éŒ¯ï¼‰
            print(f"[GALLERY-DL] URL: {self.url}", flush=True)
            print(f"[GALLERY-DL] è¿”å›ç¢¼: {result.returncode}", flush=True)
            print(f"[GALLERY-DL] STDOUT: {result.stdout[:2000] if result.stdout else '(ç©º)'}", flush=True)
            print(f"[GALLERY-DL] STDERR: {result.stderr[:2000] if result.stderr else '(ç©º)'}", flush=True)
            
            if result.returncode != 0:
                logger.error(f"gallery-dl è¿”å›ç¢¼: {result.returncode}")
                logger.error(f"gallery-dl STDERR: {result.stderr}")
                logger.error(f"gallery-dl STDOUT: {result.stdout}")
                
                # å„²å­˜è©³ç´°éŒ¯èª¤è¨Šæ¯ä¾› Discord å›å ±
                # cmd åœ¨ Docker ç’°å¢ƒæ˜¯å­—ä¸²ï¼ŒWindows ç’°å¢ƒæ˜¯åˆ—è¡¨
                cmd_str = cmd if isinstance(cmd, str) else ' '.join(cmd)
                error_lines = [
                    f"\u26a0\ufe0f **Debug è³‡è¨Š**",
                    f"\ud83d\udce6 ç‰ˆæœ¬: {VERSION}",
                    f"\ud83d\udcbb ç’°å¢ƒ: {'Docker' if IS_DOCKER else 'Windows'}",
                    f"\ud83d\udcc2 ä¸‹è¼‰ç›®éŒ„: `{self.temp_path}`",
                    f"\ud83d\udd27 åŸ·è¡Œå‘½ä»¤: `{cmd_str}`",
                    f"\ud83d\udd34 è¿”å›ç¢¼: {result.returncode}",
                ]
                
                if result.stderr:
                    error_lines.append(f"\n**STDERR:**\n```\n{result.stderr[:800]}\n```")
                if result.stdout:
                    error_lines.append(f"\n**STDOUT:**\n```\n{result.stdout[:800]}\n```")
                
                self.last_error = "\n".join(error_lines)
                return False
            
            logger.info(f"gallery-dl è¼¸å‡º: {result.stdout}")
            return True
            
        except subprocess.TimeoutExpired:
            logger.error("gallery-dl åŸ·è¡Œè¶…æ™‚")
            return False
        except Exception as e:
            logger.error(f"gallery-dl åŸ·è¡ŒéŒ¯èª¤: {e}")
            return False
    
    def convert_to_pdf(self, images: List[Path], output_pdf: Path) -> bool:
        """
        ä½¿ç”¨ Pillow å°‡åœ–ç‰‡è½‰æ›ç‚ºç­‰å¯¬ PDFï¼ˆæ”¯æ´é€²åº¦å›å ±ï¼‰
        
        æ‰€æœ‰åœ–ç‰‡æœƒè¢«èª¿æ•´ç‚ºçµ±ä¸€å¯¬åº¦ï¼ˆä½¿ç”¨æœ€å¤§å¯¬åº¦ï¼‰ï¼Œé«˜åº¦æŒ‰æ¯”ä¾‹ç¸®æ”¾ï¼Œ
        ç¢ºä¿ PDF æ¯ä¸€é éƒ½æ˜¯ 100% å¯¬åº¦å°é½Šã€‚
        
        Args:
            images: åœ–ç‰‡æª”æ¡ˆåˆ—è¡¨
            output_pdf: è¼¸å‡º PDF è·¯å¾‘
        
        Returns:
            æˆåŠŸè¿”å› Trueï¼Œå¤±æ•—è¿”å› False
        """
        if not images:
            logger.error("æ²’æœ‰åœ–ç‰‡å¯ä¾›è½‰æ›")
            return False
        
        try:
            from PIL import Image
            
            self.pdf_converting = True
            self.pdf_progress = 0
            
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
            output_pdf.parent.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"è½‰æ› {len(images)} å¼µåœ–ç‰‡ç‚ºç­‰å¯¬ PDF")
            
            total = len(images)
            
            # éšæ®µ 1: è®€å–æ‰€æœ‰åœ–ç‰‡ä¸¦æ‰¾å‡ºæœ€å¤§å¯¬åº¦ (0-20%)
            logger.info("éšæ®µ 1/3: åˆ†æåœ–ç‰‡å°ºå¯¸...")
            pil_images = []
            max_width = 0
            
            for i, img_path in enumerate(images):
                img = Image.open(img_path)
                # è½‰æ›ç‚º RGBï¼ˆPDF ä¸æ”¯æ´ RGBA é€æ˜é€šé“ï¼‰
                if img.mode in ('RGBA', 'P', 'LA'):
                    # å»ºç«‹ç™½è‰²èƒŒæ™¯
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    if img.mode in ('RGBA', 'LA'):
                        background.paste(img, mask=img.split()[-1])  # ä½¿ç”¨ alpha é€šé“ä½œç‚ºé®ç½©
                        img = background
                    else:
                        img = img.convert('RGB')
                elif img.mode != 'RGB':
                    img = img.convert('RGB')
                
                pil_images.append(img)
                if img.width > max_width:
                    max_width = img.width
                
                self.pdf_progress = int((i + 1) / total * 20)
                if (i + 1) % 10 == 0:
                    time.sleep(0.05)
            
            logger.info(f"çµ±ä¸€å¯¬åº¦: {max_width}px")
            
            # éšæ®µ 2: èª¿æ•´æ‰€æœ‰åœ–ç‰‡ç‚ºç­‰å¯¬ (20-70%)
            logger.info("éšæ®µ 2/3: èª¿æ•´åœ–ç‰‡ç‚ºç­‰å¯¬...")
            resized_images = []
            
            for i, img in enumerate(pil_images):
                if img.width != max_width:
                    # æŒ‰æ¯”ä¾‹ç¸®æ”¾åˆ°ç›®æ¨™å¯¬åº¦
                    ratio = max_width / img.width
                    new_height = int(img.height * ratio)
                    # ä½¿ç”¨é«˜å“è³ªç¸®æ”¾
                    resized_img = img.resize((max_width, new_height), Image.Resampling.LANCZOS)
                    resized_images.append(resized_img)
                else:
                    resized_images.append(img)
                
                self.pdf_progress = 20 + int((i + 1) / total * 50)
                if (i + 1) % 10 == 0:
                    time.sleep(0.05)
            
            # éšæ®µ 3: å„²å­˜ç‚º PDF (70-100%)
            logger.info("éšæ®µ 3/3: ç”Ÿæˆ PDF...")
            logger.info(f"PDF è¼¸å‡ºè·¯å¾‘: {output_pdf}")
            logger.info(f"è·¯å¾‘é•·åº¦: {len(str(output_pdf))} å­—å…ƒ")
            self.pdf_progress = 75
            
            # ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºåŸºåº•ï¼Œå…¶é¤˜ append
            first_image = resized_images[0]
            rest_images = resized_images[1:] if len(resized_images) > 1 else []
            
            try:
                first_image.save(
                    output_pdf,
                    "PDF",
                    save_all=True,
                    append_images=rest_images,
                    resolution=100.0
                )
                logger.info("PDF save å‘¼å«å®Œæˆ")
            except Exception as save_error:
                logger.error(f"PDF save å¤±æ•—: {save_error}")
                import traceback
                logger.error(traceback.format_exc())
                self.pdf_converting = False
                return False
            
            # æ¸…ç†è¨˜æ†¶é«” - ä½¿ç”¨ set è¿½è¹¤å·²é—œé–‰çš„åœ–ç‰‡ idï¼Œé¿å…æ¯”è¼ƒæ“ä½œ
            closed_ids = set()
            for img in pil_images:
                if id(img) not in closed_ids:
                    try:
                        img.close()
                    except Exception:
                        pass
                    closed_ids.add(id(img))
            for img in resized_images:
                if id(img) not in closed_ids:
                    try:
                        img.close()
                    except Exception:
                        pass
                    closed_ids.add(id(img))
            
            self.pdf_progress = 100
            self.pdf_converting = False
            
            # ç¢ºèª PDF å·²ç”Ÿæˆ
            if output_pdf.exists() and output_pdf.stat().st_size > 0:
                logger.info(f"PDF ç”ŸæˆæˆåŠŸ: {output_pdf}")
                return True
            else:
                logger.error("PDF æª”æ¡ˆæœªç”Ÿæˆæˆ–ç‚ºç©º")
                return False
                
        except Exception as e:
            logger.error(f"PDF è½‰æ›éŒ¯èª¤: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.pdf_converting = False
            return False
    
    def process(self) -> tuple[bool, str]:
        """
        åŸ·è¡Œå®Œæ•´çš„ä¸‹è¼‰è™•ç†æµç¨‹
        
        Returns:
            (æˆåŠŸç‹€æ…‹, çµæœè¨Šæ¯)
        """
        start_time = time.time()  # é–‹å§‹è¨ˆæ™‚
        
        try:
            # æ­¥é©Ÿ 1: ä¸‹è¼‰
            logger.info(f"é–‹å§‹ä¸‹è¼‰: {self.url}")
            print(f"[PROCESS] é–‹å§‹ä¸‹è¼‰: {self.url}", flush=True)
            if not self.download_with_gallery_dl():
                error_detail = self.last_error if self.last_error else "æœªçŸ¥åŸå› "
                elapsed = time.time() - start_time
                return False, f"âŒ ä¸‹è¼‰å¤±æ•—\nğŸ”— {self.url}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s\n\n{error_detail}"
            
            # å°‹æ‰¾ä¸‹è¼‰çš„å…§å®¹
            # gallery-dl å¯èƒ½æœƒå»ºç«‹å­ç›®éŒ„
            print(f"[PROCESS] æœå°‹åœ–ç‰‡ç›®éŒ„: {self.temp_path}", flush=True)
            images = find_images(self.temp_path)
            print(f"[PROCESS] æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡", flush=True)
            
            if not images:
                # åˆ—å‡ºç›®éŒ„å…§å®¹ä»¥ä¾¿é™¤éŒ¯
                try:
                    all_files = list(self.temp_path.rglob('*'))
                    print(f"[DEBUG] ç›®éŒ„å…§æ‰€æœ‰æª”æ¡ˆ: {[str(f) for f in all_files[:20]]}", flush=True)
                except Exception as e:
                    print(f"[DEBUG] ç„¡æ³•åˆ—å‡ºç›®éŒ„: {e}", flush=True)
                elapsed = time.time() - start_time
                return False, f"âŒ æ‰¾ä¸åˆ°ä¸‹è¼‰çš„åœ–ç‰‡\nğŸ”— {self.url}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s"
            
            logger.info(f"æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡")
            
            # æ­¥é©Ÿ 2: è§£æ metadata
            info_json = find_info_json(self.temp_path)
            
            if info_json:
                metadata = parse_gallery_dl_info(info_json)
            else:
                logger.warning("æ‰¾ä¸åˆ° info.jsonï¼Œä½¿ç”¨é è¨­ metadata")
                metadata = None
            
            # è¨­å®šæ¨™é¡Œ - å„ªå…ˆä½¿ç”¨æ—¥æ–‡æ¨™é¡Œ
            if metadata:
                # å„ªå…ˆé †åº: æ—¥æ–‡æ¨™é¡Œ > è‹±æ–‡æ¨™é¡Œ > URL ID
                if metadata.get('title_japanese'):
                    title = metadata['title_japanese']
                    logger.info(f"ä½¿ç”¨æ—¥æ–‡æ¨™é¡Œ: {title}")
                elif metadata.get('title'):
                    title = metadata['title']
                    logger.info(f"ä½¿ç”¨è‹±æ–‡æ¨™é¡Œ: {title}")
                else:
                    title = None
            else:
                title = None
            
            # æå– gallery_id ç”¨æ–¼ç›®éŒ„å’Œæª”åï¼ˆé¿å…è·¯å¾‘éé•·ï¼‰
            gallery_id_for_path = metadata.get('gallery_id', '') if metadata else ''
            if not gallery_id_for_path:
                # å˜—è©¦å¾ URL æå–
                match = re.search(r'/g/(\d+)', self.url)
                if match:
                    gallery_id_for_path = match.group(1)
                else:
                    gallery_id_for_path = str(int(time.time()))
            
            if not title:
                title = f"Gallery_{gallery_id_for_path}"
            
            safe_title = sanitize_filename(title)
            logger.info(f"ä½¿ç”¨æ¨™é¡Œ: {safe_title}")
            logger.info(f"ä½¿ç”¨ Gallery ID ä½œç‚ºç›®éŒ„å: {gallery_id_for_path}")
            
            # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾ - ä½¿ç”¨ gallery_id é¿å…è·¯å¾‘éé•·
            self.output_path = DOWNLOAD_DIR / gallery_id_for_path
            
            # å¦‚æœè³‡æ–™å¤¾å·²å­˜åœ¨ï¼Œä½¿ç”¨æ™‚é–“æˆ³å‘½åé¿å…è¦†è“‹
            if self.output_path.exists():
                self.output_path = DOWNLOAD_DIR / f"{gallery_id_for_path}_{int(time.time())}"
                logger.info(f"è³‡æ–™å¤¾å·²å­˜åœ¨ï¼Œä½¿ç”¨æ–°è³‡æ–™å¤¾ {self.output_path}")
            
            self.output_path.mkdir(parents=True, exist_ok=True)
            
            # æ­¥é©Ÿ 3: è½‰æ›ç‚º PDF - ä½¿ç”¨ gallery_id ä½œç‚ºæª”å
            pdf_path = self.output_path / f"{gallery_id_for_path}.pdf"
            if not self.convert_to_pdf(images, pdf_path):
                return False, "âŒ PDF è½‰æ›å¤±æ•—"
            
            # æ­¥é©Ÿ 3.5: è¤‡è£½ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢
            if images:
                try:
                    first_image = images[0]
                    # ç²å–å‰¯æª”å
                    ext = first_image.suffix  # ä¾‹å¦‚ .jpg, .png
                    cover_path = self.output_path / f"cover{ext}"
                    # è¤‡è£½ç¬¬ä¸€å¼µåœ–ç‰‡
                    shutil.copy2(first_image, cover_path)
                    logger.info(f"å°é¢å·²ä¿å­˜: {cover_path.name}")
                except Exception as e:
                    logger.warning(f"ä¿å­˜å°é¢å¤±æ•—: {e}")
            
            # æ­¥é©Ÿ 4: ç²å–é¡å¤–è³‡è¨Šï¼ˆæ”¶è—æ•¸ã€è©•è«–ï¼‰
            gallery_id = metadata.get('gallery_id', '') if metadata else ''
            if not gallery_id:
                # å˜—è©¦å¾ URL æå–
                match = re.search(r'/g/(\d+)', self.url)
                if match:
                    gallery_id = match.group(1)
            
            nhentai_extra = {}
            if gallery_id:
                logger.info(f"ç²å– nhentai é¡å¤–è³‡è¨Š (ID: {gallery_id})...")
                nhentai_extra = fetch_nhentai_extra_info(gallery_id)
            
            # æ­¥é©Ÿ 5: ç”Ÿæˆ Eagle metadataï¼ˆåŒ…å«æ“´å±•è³‡è¨Šï¼‰
            extra_info = None
            if metadata:
                extra_info = {
                    'title_japanese': metadata.get('title_japanese', ''),
                    'title_english': metadata.get('title', ''),  # è‹±æ–‡æ¨™é¡Œæ”¾ annotation
                    'title_pretty': metadata.get('title_pretty', ''),
                    'gallery_id': metadata.get('gallery_id', ''),
                    'pages': metadata.get('pages', 0),
                    'favorites': nhentai_extra.get('favorites', 0),  # å¾ API ç²å–
                    'category': metadata.get('category', ''),
                    'type': metadata.get('type', ''),
                    'artist': metadata.get('artist', []),
                    'group': metadata.get('group', []),
                    'parody': metadata.get('parody', []),
                    'character': metadata.get('character', []),
                    'language': metadata.get('language', ''),
                    'comments': nhentai_extra.get('comments', []),  # è©•è«–
                }
            
            eagle_metadata = create_eagle_metadata(
                title=title,  # å·²ç¶“æ˜¯æ—¥æ–‡æ¨™é¡Œå„ªå…ˆ
                url=metadata.get('url', self.url) if metadata else self.url,
                tags=metadata.get('tags', []) if metadata else [],
                annotation="",
                extra_info=extra_info
            )
            
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨ï¼ˆé˜²æ­¢ UNC è·¯å¾‘å•é¡Œï¼‰
            self.output_path.mkdir(parents=True, exist_ok=True)
            
            metadata_path = self.output_path / "metadata.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(eagle_metadata, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Eagle metadata å·²ç”Ÿæˆ: {metadata_path}")
            
            # æ­¥é©Ÿ 5: æ¸…ç†æš«å­˜æª”æ¡ˆ
            if self.temp_path and self.temp_path.exists():
                shutil.rmtree(self.temp_path)
                logger.info(f"å·²æ¸…ç†æš«å­˜ç›®éŒ„: {self.temp_path}")
            
            # è¨ˆç®—è€—æ™‚
            elapsed = time.time() - start_time
            if elapsed >= 60:
                elapsed_str = f"{int(elapsed // 60)}åˆ†{int(elapsed % 60)}ç§’"
            else:
                elapsed_str = f"{elapsed:.1f}ç§’"
            
            # ç²å–é æ•¸
            page_count = metadata.get('pages', len(images)) if metadata else len(images)
            
            # è½‰æ›è·¯å¾‘ç‚ºå­—ä¸²ï¼Œç¢ºä¿ UNC è·¯å¾‘æ­£ç¢ºé¡¯ç¤º
            output_path_str = str(self.output_path)
            if output_path_str.startswith('\\\\'):
                output_path_str = output_path_str  # å·²ç¶“æ˜¯æ­£ç¢ºçš„ UNC è·¯å¾‘
            elif output_path_str.startswith('\\') and not output_path_str.startswith('\\\\'):
                output_path_str = '\\' + output_path_str  # è£œä¸Šç¼ºå°‘çš„æ–œç·š
            
            # ç”Ÿæˆ PDF Web é€£çµ - ä½¿ç”¨å¯¦éš›è³‡æ–™å¤¾åç¨±ï¼ˆå¯èƒ½æœ‰æ™‚é–“æˆ³å¾Œç¶´ï¼‰
            from urllib.parse import quote
            folder_name = self.output_path.name  # ä½¿ç”¨å¯¦éš›è³‡æ–™å¤¾åç¨±
            pdf_filename = f"{gallery_id_for_path}.pdf"
            pdf_web_url = f"{PDF_WEB_BASE_URL}/{quote(folder_name)}/{quote(pdf_filename)}"
            
            # ä½¿ç”¨ç´” URL é¡¯ç¤ºï¼ˆé¿å… markdown é€£çµè¢«ç·¨ç¢¼çš„æ‹¬è™Ÿç ´å£ï¼‰
            return True, f"âœ… å®Œæˆ: **{safe_title}**\nğŸ“„ {page_count}é  â±ï¸ {elapsed_str}\nğŸ“¥ {pdf_web_url}\nğŸ“ {output_path_str}"
            
        except Exception as e:
            logger.exception(f"è™•ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            
            # è¨ˆç®—è€—æ™‚
            elapsed = time.time() - start_time
            
            # æ¸…ç†æš«å­˜æª”æ¡ˆ
            if self.temp_path and self.temp_path.exists():
                try:
                    shutil.rmtree(self.temp_path)
                except Exception:
                    pass
            
            return False, f"âŒ éŒ¯èª¤: {str(e)}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s"


# ==================== Worker Thread ====================

class DownloadWorker(threading.Thread):
    """
    ä¸‹è¼‰å·¥ä½œåŸ·è¡Œç·’ï¼šå¾ä½‡åˆ—ä¸­å–å‡ºä»»å‹™ä¸¦åŸ·è¡Œ
    """
    
    def __init__(self, bot):
        super().__init__(daemon=True)
        self.bot = bot
        self.running = True
        self.current_task: Optional[str] = None  # æ­£åœ¨è™•ç†çš„ URL
    
    def run(self):
        """å·¥ä½œåŸ·è¡Œç·’ä¸»è¿´åœˆ"""
        logger.info("ä¸‹è¼‰å·¥ä½œåŸ·è¡Œç·’å·²å•Ÿå‹•")
        
        while self.running:
            try:
                # å¾ä½‡åˆ—å–å¾—ä»»å‹™ï¼ˆé˜»å¡å¼ç­‰å¾…ï¼Œ1ç§’è¶…æ™‚ï¼‰
                task = download_queue.get(timeout=1)
                
                if task is None:
                    continue
                
                # æ”¯æ´æ ¼å¼: (url, channel_id), (url, channel_id, status_msg_id), æˆ– (url, channel_id, status_msg_id, test_mode)
                if len(task) == 4:
                    url, channel_id, status_msg_id, test_mode = task
                elif len(task) == 3:
                    url, channel_id, status_msg_id = task
                    test_mode = False
                else:
                    url, channel_id = task
                    status_msg_id = None
                    test_mode = False
                
                self.current_task = url
                logger.info(f"è™•ç†ä¸‹è¼‰ä»»å‹™: {url}")
                
                # æå– gallery ID ä¸¦ç²å–é æ•¸ï¼Œç™¼é€é–‹å§‹è¨Šæ¯
                start_msg_id = None
                pages = 0
                title = ""
                media_id = ""
                match = re.search(r'/g/(\d+)', url)
                if match:
                    gallery_id = match.group(1)
                    pages, title, media_id = get_nhentai_page_count(gallery_id)
                    if pages > 0:
                        # ç™¼é€é–‹å§‹ä¸‹è¼‰è¨Šæ¯ï¼ˆåŒ…å«é æ•¸å’Œé ä¼°æ™‚é–“ï¼‰ï¼Œä¸¦è¿”å›è¨Šæ¯ ID
                        future = asyncio.run_coroutine_threadsafe(
                            self.send_start_message(channel_id, gallery_id, pages, title, media_id),
                            self.bot.loop
                        )
                        start_msg_id = future.result(timeout=10)
                
                # å‰µå»ºä¸‹è¼‰è™•ç†å™¨
                processor = DownloadProcessor(url, total_pages=pages)
                
                # å•Ÿå‹•é€²åº¦ç›£æ§åŸ·è¡Œç·’
                progress_stop_event = threading.Event()
                if start_msg_id and pages > 0:
                    progress_thread = threading.Thread(
                        target=self._monitor_progress,
                        args=(processor, channel_id, start_msg_id, pages, title, gallery_id, media_id, progress_stop_event),
                        daemon=True
                    )
                    progress_thread.start()
                
                # åŸ·è¡Œä¸‹è¼‰è™•ç†
                success, message = processor.process()
                
                # åœæ­¢é€²åº¦ç›£æ§
                progress_stop_event.set()
                
                # æ›´æ–°é–‹å§‹ä¸‹è¼‰è¨Šæ¯ï¼ˆé¡¯ç¤ºæœ€çµ‚ç‹€æ…‹ï¼‰
                if start_msg_id:
                    asyncio.run_coroutine_threadsafe(
                        self.update_final_progress(channel_id, start_msg_id, success, pages, title, media_id),
                        self.bot.loop
                    )
                
                # ç™¼é€çµæœåˆ° Discord
                asyncio.run_coroutine_threadsafe(
                    self.send_result(channel_id, message),
                    self.bot.loop
                )
                
                self.current_task = None
                download_queue.task_done()
            
            except Empty:
                # ä½‡åˆ—ç‚ºç©ºï¼Œé€™æ˜¯æ­£å¸¸çš„ï¼Œç¹¼çºŒç­‰å¾…
                continue
                
            except Exception as e:
                self.current_task = None
                logger.exception(f"å·¥ä½œåŸ·è¡Œç·’éŒ¯èª¤: {e}")
    
    def _monitor_progress(self, processor: DownloadProcessor, channel_id: int, 
                          message_id: int, total_pages: int, title: str, 
                          gallery_id: str, media_id: str, stop_event: threading.Event):
        """
        ç›£æ§ä¸‹è¼‰é€²åº¦ä¸¦æ›´æ–° Discord è¨Šæ¯
        
        åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­å®šæœŸæª¢æŸ¥å·²ä¸‹è¼‰çš„åœ–ç‰‡æ•¸é‡ï¼Œä¸¦ç·¨è¼¯è¨Šæ¯é¡¯ç¤ºé€²åº¦æ¢
        """
        last_count = 0
        last_pdf_progress = -1
        start_time = time.time()
        pdf_start_time = None  # PDF è½‰æ›é–‹å§‹æ™‚é–“
        first_image_sent = False  # è¿½è¹¤æ˜¯å¦å·²ç™¼é€ç¬¬ä¸€å¼µåœ–ç‰‡
        pdf_mode = False  # æ˜¯å¦é€²å…¥ PDF æ¨¡å¼
        
        while not stop_event.is_set():
            try:
                # æ ¹æ“šæ¨¡å¼èª¿æ•´æª¢æŸ¥é–“éš”
                check_interval = 1 if pdf_mode else PROGRESS_UPDATE_INTERVAL
                
                # ç­‰å¾…ä¸€æ®µæ™‚é–“
                if stop_event.wait(timeout=check_interval):
                    break  # æ”¶åˆ°åœæ­¢ä¿¡è™Ÿ
                
                # æª¢æŸ¥æ˜¯å¦åœ¨ PDF è½‰æ›éšæ®µ
                if processor.pdf_converting:
                    pdf_mode = True
                    pdf_progress = processor.pdf_progress
                    
                    # è¨˜éŒ„ PDF é–‹å§‹æ™‚é–“
                    if pdf_start_time is None:
                        pdf_start_time = time.time()
                    
                    if pdf_progress != last_pdf_progress:
                        last_pdf_progress = pdf_progress
                        
                        # è¨ˆç®— PDF é ä¼°å‰©é¤˜æ™‚é–“
                        pdf_eta_str = "è¨ˆç®—ä¸­..."
                        if pdf_progress > 0:
                            pdf_elapsed = time.time() - pdf_start_time
                            pdf_eta_seconds = (pdf_elapsed / pdf_progress) * (100 - pdf_progress)
                            if pdf_eta_seconds >= 60:
                                pdf_eta_str = f"{int(pdf_eta_seconds // 60)}åˆ†{int(pdf_eta_seconds % 60)}ç§’"
                            else:
                                pdf_eta_str = f"{int(pdf_eta_seconds)}ç§’"
                        
                        # é¡¯ç¤º PDF è½‰æ›é€²åº¦
                        pdf_bar = create_progress_bar(pdf_progress, 100)
                        # ä¸‹è¼‰é€²åº¦æ¢ä¿æŒ 100%
                        download_bar = create_progress_bar(total_pages, total_pages)
                        
                        asyncio.run_coroutine_threadsafe(
                            self.update_pdf_progress_message(
                                channel_id, message_id, 
                                pdf_progress, pdf_bar, download_bar, total_pages, title, pdf_eta_str
                            ),
                            self.bot.loop
                        )
                    continue
                
                # ç²å–å·²ä¸‹è¼‰æ•¸é‡
                current_count = processor.get_downloaded_count()
                
                # ç­‰ç¬¬ 3 å¼µåœ–ç‰‡ä¸‹è¼‰å®Œæˆå¾Œï¼Œç™¼é€ç¬¬ä¸€å¼µåœ–ç‰‡ï¼ˆç¢ºä¿ç¬¬ä¸€å¼µå·²å®Œæ•´ä¸‹è¼‰ï¼‰
                if current_count >= 3 and not first_image_sent:
                    first_image_sent = True
                    # ç­‰å¾… 1 ç§’ç¢ºä¿ NAS å¯«å…¥å®Œæˆ
                    time.sleep(1)
                    first_image = processor.get_first_image_path()
                    # ç¢ºèªæª”æ¡ˆå¤§å°å¤§æ–¼ 0
                    if first_image and first_image.exists() and first_image.stat().st_size > 0:
                        asyncio.run_coroutine_threadsafe(
                            self.send_cover_image(channel_id, first_image),
                            self.bot.loop
                        )
                
                # ä¸‹è¼‰å®Œæˆæ™‚ï¼Œåˆ‡æ›åˆ°æ›´é »ç¹çš„æª¢æŸ¥æ¨¡å¼ä»¥åµæ¸¬ PDF è½‰æ›
                if current_count >= total_pages:
                    pdf_mode = True
                
                # åªæœ‰é€²åº¦æœ‰è®ŠåŒ–æ™‚æ‰æ›´æ–°
                if current_count != last_count and current_count > 0:
                    last_count = current_count
                    
                    # è¨ˆç®—é€²åº¦å’Œé ä¼°å‰©é¤˜æ™‚é–“
                    progress_bar = create_progress_bar(current_count, total_pages)
                    elapsed = time.time() - start_time
                    
                    if current_count > 0:
                        avg_time_per_page = elapsed / current_count
                        remaining_pages = total_pages - current_count
                        eta_seconds = remaining_pages * avg_time_per_page
                        
                        if eta_seconds >= 60:
                            eta_str = f"{int(eta_seconds // 60)}åˆ†{int(eta_seconds % 60)}ç§’"
                        else:
                            eta_str = f"{int(eta_seconds)}ç§’"
                    else:
                        eta_str = "è¨ˆç®—ä¸­..."
                    
                    # æ›´æ–°è¨Šæ¯
                    asyncio.run_coroutine_threadsafe(
                        self.update_progress_message(
                            channel_id, message_id, 
                            current_count, total_pages, 
                            progress_bar, eta_str, title
                        ),
                        self.bot.loop
                    )
                    
            except Exception as e:
                logger.error(f"é€²åº¦ç›£æ§éŒ¯èª¤: {e}")
    
    async def send_cover_image(self, channel_id: int, image_path: Path):
        """ç™¼é€å°é¢åœ–ç‰‡ä½œç‚ºé™„ä»¶"""
        try:
            channel = self.bot.get_channel(channel_id)
            if channel and image_path and image_path.exists():
                await channel.send(file=discord.File(image_path))
                logger.info(f"å·²ç™¼é€å°é¢åœ–ç‰‡: {image_path.name}")
        except Exception as e:
            logger.error(f"ç™¼é€å°é¢åœ–ç‰‡å¤±æ•—: {e}")
    
    async def update_progress_message(self, channel_id: int, message_id: int,
                                       current: int, total: int,
                                       progress_bar: str, eta: str, title: str):
        """ç·¨è¼¯è¨Šæ¯æ›´æ–°ä¸‹è¼‰é€²åº¦"""
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # ç·¨è¼¯è¨Šæ¯
            new_content = (
                f"ğŸ”„ ä¸‹è¼‰ä¸­...\n"
                f"ğŸ“– {title}\n"
                f"{progress_bar}\n"
                f"({current}/{total}) â±ï¸ é ä¼°å‰©é¤˜: {eta}"
            )
            await message.edit(content=new_content)
            
        except Exception as e:
            logger.error(f"æ›´æ–°é€²åº¦è¨Šæ¯å¤±æ•—: {e}")
    
    async def update_pdf_progress_message(self, channel_id: int, message_id: int,
                                          progress: int, pdf_bar: str, download_bar: str, 
                                          total_pages: int, title: str, eta: str = ""):
        """ç·¨è¼¯è¨Šæ¯æ›´æ–° PDF è½‰æ›é€²åº¦"""
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # ç·¨è¼¯è¨Šæ¯ - é¡¯ç¤ºå…©æ¢é€²åº¦æ¢
            new_content = (
                f"ğŸ“„ è£½ä½œ PDF ä¸­...\n"
                f"ğŸ“– {title}\n"
                f"ä¸‹è¼‰: \n{download_bar}\n"
                f"({total_pages}/{total_pages})\n"
                f"PDF: \n{pdf_bar}\n"
                f"â±ï¸ é ä¼°å‰©é¤˜: {eta}"
            )
            await message.edit(content=new_content)
            
        except Exception as e:
            logger.error(f"æ›´æ–° PDF é€²åº¦è¨Šæ¯å¤±æ•—: {e}")
    
    async def update_final_progress(self, channel_id: int, message_id: int, 
                                    success: bool, total: int, title: str, media_id: str = ""):
        """æ›´æ–°æœ€çµ‚é€²åº¦ç‹€æ…‹"""
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # æ›´æ–°è¨Šæ¯å…§å®¹å’Œè¡¨æƒ…
            if success:
                progress_bar = create_progress_bar(total, total)
                await message.edit(content=f"âœ… ä¸‹è¼‰å®Œæˆ\nğŸ“– {title}\n{progress_bar}\n({total}/{total})")
                await message.add_reaction('âœ…')
            else:
                await message.add_reaction('âŒ')
            
        except Exception as e:
            logger.error(f"æ›´æ–°æœ€çµ‚é€²åº¦å¤±æ•—: {e}")
    
    async def send_start_message(self, channel_id: int, gallery_id: str, pages: int, title: str, media_id: str = "") -> int:
        """
        ç™¼é€é–‹å§‹ä¸‹è¼‰è¨Šæ¯ï¼ˆåŒ…å«é æ•¸å’Œé ä¼°æ™‚é–“ï¼‰
        
        Returns:
            è¨Šæ¯ IDï¼Œå¤±æ•—æ™‚è¿”å› None
        """
        try:
            channel = self.bot.get_channel(channel_id)
            if channel:
                # è¨ˆç®—é ä¼°æ™‚é–“
                est_seconds = pages * SECONDS_PER_PAGE
                if est_seconds >= 60:
                    est_str = f"{int(est_seconds // 60)}åˆ†{int(est_seconds % 60)}ç§’"
                else:
                    est_str = f"{int(est_seconds)}ç§’"
                
                # åˆå§‹é€²åº¦æ¢
                progress_bar = create_progress_bar(0, pages)
                
                # ç™¼é€é€²åº¦è¨Šæ¯
                msg = await channel.send(
                    f"ğŸ”„ é–‹å§‹ä¸‹è¼‰ **#{gallery_id}**\n"
                    f"ğŸ“– {title}\n"
                    f"{progress_bar}\n"
                    f"(0/{pages}) â±ï¸ é ä¼°: {est_str}"
                )
                
                return msg.id
        except Exception as e:
            logger.error(f"ç™¼é€é–‹å§‹è¨Šæ¯å¤±æ•—: {e}")
        return None
    
    async def update_status_reaction(self, channel_id: int, message_id: int, success: bool):
        """æ›´æ–°ç‹€æ…‹è¨Šæ¯çš„è¡¨æƒ…ï¼šæ·»åŠ  âœ… æˆ– âŒï¼ˆå·²ä¸å†ä½¿ç”¨ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰"""
        if not message_id:
            return
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # æ·»åŠ çµæœè¡¨æƒ…
            result_emoji = 'âœ…' if success else 'âŒ'
            await message.add_reaction(result_emoji)
            
        except Exception as e:
            logger.error(f"æ›´æ–°ç‹€æ…‹è¡¨æƒ…å¤±æ•—: {e}")
    
    async def send_result(self, channel_id: int, message: str):
        """ç™¼é€çµæœè¨Šæ¯åˆ° Discord é »é“"""
        try:
            channel = self.bot.get_channel(channel_id)
            if channel:
                await channel.send(message)
        except Exception as e:
            logger.error(f"ç™¼é€è¨Šæ¯å¤±æ•—: {e}")
    
    def stop(self):
        """åœæ­¢å·¥ä½œåŸ·è¡Œç·’"""
        self.running = False


# ==================== Discord Bot ====================

class HentaiFetcherBot(commands.Bot):
    """
    HentaiFetcher Discord Bot (ä½¿ç”¨ Slash Commands)
    """
    
    def __init__(self):
        # è¨­å®š Intents
        intents = discord.Intents.default()
        intents.message_content = True
        
        super().__init__(
            command_prefix='!',
            intents=intents,
            help_command=None  # ä½¿ç”¨è‡ªè¨‚ help
        )
        
        self.worker: Optional[DownloadWorker] = None
    
    async def setup_hook(self):
        """Bot å•Ÿå‹•æ™‚çš„è¨­å®š"""
        # å•Ÿå‹•å·¥ä½œåŸ·è¡Œç·’
        self.worker = DownloadWorker(self)
        self.worker.start()
        logger.info("Bot setup å®Œæˆï¼Œä¸‹è¼‰åŸ·è¡Œç·’å·²å•Ÿå‹•")
        
        # åŒæ­¥æ–œç·šæŒ‡ä»¤
        try:
            synced = await self.tree.sync()
            logger.info(f"å·²åŒæ­¥ {len(synced)} å€‹æ–œç·šæŒ‡ä»¤")
        except Exception as e:
            logger.error(f"åŒæ­¥æ–œç·šæŒ‡ä»¤å¤±æ•—: {e}")
    
    async def on_ready(self):
        """Bot é€£ç·šæˆåŠŸæ™‚è§¸ç™¼"""
        logger.info(f'Bot å·²ç™»å…¥: {self.user.name} (ID: {self.user.id})')
        logger.info(f'å·²é€£æ¥åˆ° {len(self.guilds)} å€‹ä¼ºæœå™¨')
        
        # è¨­å®šç‹€æ…‹
        await self.change_presence(
            activity=discord.Activity(
                type=discord.ActivityType.watching,
                name="#hentaifetcher"
            )
        )
        
        # é¡¯ç¤ºå°ˆç”¨é »é“è¨­å®š
        logger.info(f"å°ˆç”¨é »é“åç¨±: {DEDICATED_CHANNEL_NAMES}")
        logger.info("âœ… Bot å·²å°±ç·’ï¼åœ¨å°ˆç”¨é »é“ç›´æ¥è²¼ç¶²å€æˆ–æ•¸å­—å³å¯ä¸‹è¼‰")
    
    async def on_message(self, message):
        """è™•ç†è¨Šæ¯ - æ”¯æ´å°ˆç”¨é »é“ï¼ˆä¸éœ€ !dlï¼‰å’Œå‚³çµ±æŒ‡ä»¤æ¨¡å¼"""
        # å¿½ç•¥ Bot è‡ªå·±çš„è¨Šæ¯
        if message.author.bot:
            return
        
        # è¨Šæ¯å»é‡ - é¿å…é‡è¤‡è™•ç†
        if is_message_processed(message.id):
            print(f"[DEBUG] è·³éé‡è¤‡è¨Šæ¯: {message.id}", flush=True)
            return
        
        content = message.content.strip()
        
        # å¿½ç•¥ç©ºè¨Šæ¯
        if not content:
            return
        
        # æª¢æŸ¥æ˜¯å¦åœ¨å°ˆç”¨é »é“ä¸­
        is_dedicated_channel = (
            message.channel.name.lower() in [n.lower() for n in DEDICATED_CHANNEL_NAMES] or
            message.channel.id in DEDICATED_CHANNEL_IDS
        )
        
        # Debug: è¨˜éŒ„æ”¶åˆ°çš„è¨Šæ¯
        if is_dedicated_channel:
            print(f"[å°ˆç”¨é »é“] æ”¶åˆ°è¨Šæ¯ (ID:{message.id}): {repr(content[:100])}", flush=True)
        else:
            print(f"[DEBUG] æ”¶åˆ°è¨Šæ¯ (ID:{message.id}): {repr(content[:100])}", flush=True)
        
        # ===== å°ˆç”¨é »é“æ¨¡å¼ï¼šä¸éœ€è¦ !dl å‰ç¶´ =====
        if is_dedicated_channel and not content.startswith('!'):
            # æª¢æŸ¥æ˜¯å¦ç‚ºå·²çŸ¥çš„æŒ‡ä»¤ (ä¸éœ€è¦ ! å‰ç¶´çš„ç‰ˆæœ¬)
            known_commands = [
                'search', 's', 'find',           # æœå°‹
                'read', 'open', 'pdf',           # é–±è®€
                'eagle', 'lib', 'library',       # çµ±è¨ˆ
                'reindex', 'rebuild', 'sync',    # é‡å»ºç´¢å¼•
                'queue', 'q',                    # ä½‡åˆ—
                'status',                        # ç‹€æ…‹
                'list', 'ls',                    # åˆ—è¡¨
                'random', 'rand', 'r',           # éš¨æ©Ÿ
                'fixcover', 'fc', 'addcover',    # å°é¢
                'cleanup', 'clean', 'dedup',     # æ¸…ç†
                'ping', 'version', 'v', 'ver',   # ç³»çµ±
                'help', 'h',                     # èªªæ˜
                'test',                          # æ¸¬è©¦
            ]
            
            first_word = content.split()[0].lower() if content else ''
            
            if first_word in known_commands:
                # æ˜¯æŒ‡ä»¤ï¼Œè½‰æ›ç‚º !æŒ‡ä»¤ æ ¼å¼è®“ commands æ¡†æ¶è™•ç†
                message.content = '!' + content
                await self.process_commands(message)
                return
            
            # ä¸æ˜¯æŒ‡ä»¤ï¼Œç•¶ä½œä¸‹è¼‰è«‹æ±‚è™•ç†
            await self.handle_direct_download(message, content)
            return
        
        # ===== å‚³çµ±æ¨¡å¼ï¼šè™•ç† !dl æŒ‡ä»¤ï¼ˆæ”¯æ´å¤šè¡Œï¼‰=====
        if content.startswith('!dl'):
            # å¼·åˆ¶è¼¸å‡º debug è¨Šæ¯
            print(f"[DEBUG] !dl æŒ‡ä»¤åµæ¸¬åˆ°!", flush=True)
            print(f"[DEBUG] å®Œæ•´å…§å®¹é•·åº¦: {len(content)}", flush=True)
            print(f"[DEBUG] å®Œæ•´å…§å®¹: {repr(content)}", flush=True)
            logger.info(f"æ”¶åˆ° !dl æŒ‡ä»¤ï¼Œå®Œæ•´å…§å®¹: {repr(content)}")
            
            # æå– !dl ä¹‹å¾Œçš„æ‰€æœ‰å…§å®¹ï¼ˆåŒ…æ‹¬æ›è¡Œï¼‰
            urls_text = content[3:].strip()  # ç§»é™¤ "!dl" å‰ç¶´
            
            print(f"[DEBUG] è§£ææ–‡å­—: {repr(urls_text)}", flush=True)
            logger.info(f"è§£ææ–‡å­—: {repr(urls_text)}")
            
            if not urls_text:
                await message.channel.send(
                    "ğŸ“– **!dl ä½¿ç”¨æ–¹å¼**\n"
                    "```\n"
                    "!dl 421633\n"
                    "!dl 421633 607769 613358\n"
                    "!dl https://nhentai.net/g/421633/\n"
                    "```\n"
                    "ä¹Ÿå¯ä»¥ç›´æ¥è²¼å¤šè¡Œï¼š\n"
                    "```\n"
                    "!dl 421633\n"
                    "607769\n"
                    "613358\n"
                    "```"
                )
                return
            
            # è§£ææ‰€æœ‰ç¶²å€
            parsed_urls = parse_input_to_urls(urls_text)
            
            print(f"[DEBUG] è§£æçµæœæ•¸é‡: {len(parsed_urls)}", flush=True)
            print(f"[DEBUG] è§£æçµæœ: {parsed_urls}", flush=True)
            logger.info(f"è§£æçµæœ: {parsed_urls}")
            
            if not parsed_urls:
                await message.channel.send("âš ï¸ ç„¡æ³•è§£æè¼¸å…¥ã€‚è«‹æä¾›æœ‰æ•ˆçš„ç¶²å€æˆ– nhentai è™Ÿç¢¼ã€‚")
                return
            
            # æå–æ‰€æœ‰ gallery ID ä¸¦æª¢æŸ¥é‡è¤‡
            new_urls = []
            already_exists = []
            
            for url in parsed_urls:
                match = re.search(r'/g/(\d+)', url)
                if match:
                    gallery_id = match.group(1)
                    # æª¢æŸ¥æ˜¯å¦å·²ä¸‹è¼‰
                    exists, info = check_already_downloaded(gallery_id)
                    if exists:
                        already_exists.append((gallery_id, info))
                    else:
                        new_urls.append((url, gallery_id))
                else:
                    new_urls.append((url, None))
            
            # å›å ±å·²å­˜åœ¨çš„é …ç›®
            if already_exists:
                if len(already_exists) == 1:
                    gid, info = already_exists[0]
                    title = info.get('title', '')[:40]
                    web_url = info.get('web_url', '')
                    await message.channel.send(f"ğŸ“š **#{gid}** å·²å­˜åœ¨\nğŸ“– {title}\nğŸ”— {web_url}")
                else:
                    exist_list = "\n".join([f"â€¢ `{gid}`: {info.get('title', '')[:30]}" for gid, info in already_exists[:5]])
                    await message.channel.send(f"ğŸ“š **{len(already_exists)}** å€‹å·²å­˜åœ¨ï¼ˆè·³éï¼‰:\n{exist_list}")
            
            # å¦‚æœæ²’æœ‰æ–°çš„è¦ä¸‹è¼‰
            if not new_urls:
                return
            
            # ç™¼é€ç‹€æ…‹è¨Šæ¯ï¼ˆç°¡åŒ–ç‰ˆï¼Œåªé¡¯ç¤ºè™Ÿç¢¼ï¼‰
            queue_size = download_queue.qsize() + len(new_urls)
            gallery_ids = [gid for _, gid in new_urls if gid]
            
            if len(new_urls) == 1 and gallery_ids:
                await message.channel.send(f"ğŸ“¥ **#{gallery_ids[0]}** å·²åŠ å…¥ä½‡åˆ—\nğŸ“Š ä½‡åˆ—: {queue_size}")
            elif len(gallery_ids) <= 15:
                id_list = ", ".join([f"`{gid}`" for gid in gallery_ids])
                await message.channel.send(f"ğŸ“¥ **{len(gallery_ids)}** å€‹å·²åŠ å…¥ä½‡åˆ—\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
            else:
                await message.channel.send(f"ğŸ“¥ **{len(new_urls)}** å€‹å·²åŠ å…¥ä½‡åˆ—\nğŸ“Š ä½‡åˆ—: {queue_size}")
            
            # åŠ å…¥ä½‡åˆ—ï¼ˆä¸å†å‚³é status_msg_idï¼Œå› ç‚º loading emoji æ”¹åœ¨é–‹å§‹ä¸‹è¼‰æ™‚é¡¯ç¤ºï¼‰
            for url, _ in new_urls:
                download_queue.put((url, message.channel.id, None))
            
            logger.info(f"æ–°å¢ {len(new_urls)} å€‹ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {message.author})")
            return
        
        # ===== è™•ç† !test æŒ‡ä»¤ï¼ˆå¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼Œè·³éé‡è¤‡æª¢æŸ¥ï¼‰=====
        if content.startswith('!test'):
            print(f"[DEBUG] !test æŒ‡ä»¤åµæ¸¬åˆ°!", flush=True)
            logger.info(f"æ”¶åˆ° !test æŒ‡ä»¤ï¼Œå®Œæ•´å…§å®¹: {repr(content)}")
            
            # æå– !test ä¹‹å¾Œçš„æ‰€æœ‰å…§å®¹
            urls_text = content[5:].strip()  # ç§»é™¤ "!test" å‰ç¶´
            
            if not urls_text:
                await message.channel.send(
                    "ğŸ§ª **!test ä½¿ç”¨æ–¹å¼ï¼ˆå¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼‰**\n"
                    "```\n"
                    "!test 421633\n"
                    "!test https://nhentai.net/g/421633/\n"
                    "```\n"
                    "âš ï¸ æ­¤æ¨¡å¼æœƒè·³éé‡è¤‡æª¢æŸ¥ï¼Œå³ä½¿å·²ä¸‹è¼‰éä¹Ÿæœƒé‡æ–°ä¸‹è¼‰"
                )
                return
            
            # è§£ææ‰€æœ‰ç¶²å€
            parsed_urls = parse_input_to_urls(urls_text)
            
            if not parsed_urls:
                await message.channel.send("âš ï¸ ç„¡æ³•è§£æè¼¸å…¥ã€‚è«‹æä¾›æœ‰æ•ˆçš„ç¶²å€æˆ– nhentai è™Ÿç¢¼ã€‚")
                return
            
            # ç™¼é€ç‹€æ…‹è¨Šæ¯
            queue_size = download_queue.qsize() + len(parsed_urls)
            
            # æå–æ‰€æœ‰ gallery ID
            gallery_ids = []
            for url in parsed_urls:
                match = re.search(r'/g/(\d+)', url)
                if match:
                    gallery_ids.append(match.group(1))
            
            if len(parsed_urls) == 1 and gallery_ids:
                await message.channel.send(f"ğŸ§ª **#{gallery_ids[0]}** å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ“Š ä½‡åˆ—: {queue_size}")
            else:
                id_list = ", ".join([f"`{gid}`" for gid in gallery_ids[:10]])
                await message.channel.send(f"ğŸ§ª **{len(gallery_ids)}** å€‹å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
            
            # åŠ å…¥ä½‡åˆ—ï¼ˆç¬¬4å€‹åƒæ•¸ True è¡¨ç¤º test_modeï¼‰
            for url in parsed_urls:
                download_queue.put((url, message.channel.id, None, True))
            
            logger.info(f"æ–°å¢ {len(parsed_urls)} å€‹ TEST ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {message.author})")
            return
        
        # è™•ç†å…¶ä»–æŒ‡ä»¤
        await self.process_commands(message)
    
    async def handle_direct_download(self, message, content: str):
        """
        è™•ç†å°ˆç”¨é »é“ä¸­çš„ç›´æ¥ä¸‹è¼‰è«‹æ±‚
        ä¸éœ€è¦ ! å‰ç¶´ï¼Œç›´æ¥è²¼ç¶²å€ã€æ•¸å­—æˆ–æŒ‡ä»¤å³å¯
        """
        content_lower = content.lower().strip()
        
        # ===== è™•ç†æŒ‡ä»¤ï¼ˆä¸éœ€è¦ ! å‰ç¶´ï¼‰=====
        # help / h
        if content_lower in ['help', 'h']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('help')
            await self.invoke(ctx)
            return
        
        # queue / q
        if content_lower in ['queue', 'q']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('queue')
            await self.invoke(ctx)
            return
        
        # status
        if content_lower == 'status':
            ctx = await self.get_context(message)
            ctx.command = self.get_command('status')
            await self.invoke(ctx)
            return
        
        # ping
        if content_lower == 'ping':
            ctx = await self.get_context(message)
            ctx.command = self.get_command('ping')
            await self.invoke(ctx)
            return
        
        # version / v
        if content_lower in ['version', 'v']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('version')
            await self.invoke(ctx)
            return
        
        # list / ls / library
        if content_lower in ['list', 'ls', 'library']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('list')
            await self.invoke(ctx)
            return
        
        # cleanup / clean / dedup
        if content_lower in ['cleanup', 'clean', 'dedup']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('cleanup')
            await self.invoke(ctx)
            return
        
        # fixcover / fc / addcover
        if content_lower in ['fixcover', 'fc', 'addcover']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('fixcover')
            await self.invoke(ctx)
            return
        
        # random / rand / r [æ•°é‡]
        if content_lower.startswith('random ') or content_lower.startswith('rand ') or content_lower.startswith('r ') or content_lower in ['random', 'rand', 'r']:
            # æå–æ•°é‡å‚æ•°
            parts = content.split()
            count = 1
            if len(parts) > 1:
                try:
                    count = int(parts[1])
                except:
                    count = 1
            
            # ç›´æ¥è°ƒç”¨å‡½æ•°
            ctx = await self.get_context(message)
            await random_command(ctx, count)
            return
        
        # dl <å…§å®¹> - ä¹Ÿæ”¯æ´ä¸å¸¶ ! çš„ dl
        if content_lower.startswith('dl ') or content_lower == 'dl':
            content = content[2:].strip() if len(content) > 2 else ''
            if not content:
                await message.channel.send(
                    "ğŸ“– **ä¸‹è¼‰ä½¿ç”¨æ–¹å¼**\n"
                    "ç›´æ¥è²¼ç¶²å€æˆ–è™Ÿç¢¼å³å¯ï¼\n"
                    "```\n"
                    "421633\n"
                    "421633 607769 613358\n"
                    "https://nhentai.net/g/421633/\n"
                    "```"
                )
                return
        
        # test <å…§å®¹> - å¼·åˆ¶é‡æ–°ä¸‹è¼‰
        if content_lower.startswith('test ') or content_lower == 'test':
            test_content = content[4:].strip() if len(content) > 4 else ''
            if not test_content:
                await message.channel.send(
                    "ğŸ§ª **Test æ¨¡å¼ä½¿ç”¨æ–¹å¼ï¼ˆå¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼‰**\n"
                    "```\n"
                    "test 421633\n"
                    "test https://nhentai.net/g/421633/\n"
                    "```\n"
                    "âš ï¸ æ­¤æ¨¡å¼æœƒè·³éé‡è¤‡æª¢æŸ¥"
                )
                return
            
            # è§£æ test å…§å®¹
            test_urls = parse_input_to_urls(test_content)
            if not test_urls:
                await message.channel.send(f"âš ï¸ ç„¡æ³•è§£æ: `{test_content[:50]}`")
                return
            
            # åŠ å…¥ä½‡åˆ—ï¼ˆtest æ¨¡å¼ï¼‰
            queue_size = download_queue.qsize() + len(test_urls)
            gallery_ids = []
            for url in test_urls:
                match = re.search(r'/g/(\d+)', url)
                if match:
                    gallery_ids.append(match.group(1))
            
            if len(test_urls) == 1 and gallery_ids:
                await message.channel.send(f"ğŸ§ª **#{gallery_ids[0]}** å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ“Š ä½‡åˆ—: {queue_size}")
            else:
                id_list = ", ".join([f"`{gid}`" for gid in gallery_ids[:10]])
                await message.channel.send(f"ğŸ§ª **{len(gallery_ids)}** å€‹å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
            
            for url in test_urls:
                download_queue.put((url, message.channel.id, None, True))
            
            logger.info(f"[å°ˆç”¨é »é“] æ–°å¢ {len(test_urls)} å€‹ TEST ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {message.author})")
            return
        
        # è§£æè¼¸å…¥
        parsed_urls = parse_input_to_urls(content)
        
        if not parsed_urls:
            # å¦‚æœç„¡æ³•è§£æï¼Œéœé»˜å¿½ç•¥ï¼ˆä¸ç™¼é€éŒ¯èª¤è¨Šæ¯ï¼Œé¿å…æ‰“æ“¾ï¼‰
            # ä½†å¦‚æœå…§å®¹çœ‹èµ·ä¾†åƒæ˜¯æƒ³è¦ä¸‹è¼‰ï¼ˆç´”æ•¸å­—æˆ–åŒ…å« nhentaiï¼‰ï¼Œçµ¦äºˆæç¤º
            if re.search(r'\d{4,7}', content) or 'nhentai' in content.lower():
                await message.channel.send(f"âš ï¸ ç„¡æ³•è§£æ: `{content[:50]}`\nè«‹ç¢ºèªæ ¼å¼æ­£ç¢ºï¼ˆä¾‹å¦‚: `607769` æˆ– `https://nhentai.net/g/607769/`ï¼‰")
            return
        
        # é©—è­‰ä¸¦åŠ å…¥ä½‡åˆ—
        valid_urls = []
        invalid_urls = []
        already_exists = []
        
        # æ·»åŠ  reaction è¡¨ç¤ºè™•ç†ä¸­
        try:
            await message.add_reaction('â³')
        except:
            pass
        
        for url in parsed_urls:
            # æå– gallery ID
            match = re.search(r'/g/(\d+)', url)
            if match:
                gallery_id = match.group(1)
                
                # å…ˆæª¢æŸ¥æ˜¯å¦å·²ä¸‹è¼‰
                exists, exist_info = check_already_downloaded(gallery_id)
                if exists:
                    already_exists.append((gallery_id, exist_info))
                    continue
                
                # é©—è­‰æ˜¯å¦å¯è¨ªå•
                is_valid, info = verify_nhentai_url(gallery_id)
                
                if is_valid:
                    valid_urls.append((url, gallery_id, info))
                else:
                    invalid_urls.append((gallery_id, info))
            else:
                invalid_urls.append((url, "ç„¡æ•ˆæ ¼å¼"))
        
        # ç§»é™¤è™•ç†ä¸­ reaction
        try:
            await message.remove_reaction('â³', self.user)
        except:
            pass
        
        # å›å ±å·²å­˜åœ¨çš„é …ç›®
        if already_exists:
            if len(already_exists) == 1:
                gid, info = already_exists[0]
                title = info.get('title', '')[:40]
                web_url = info.get('web_url', '')
                await message.channel.send(f"ğŸ“š **#{gid}** å·²å­˜åœ¨\nğŸ“– {title}\nğŸ”— {web_url}")
            else:
                exist_list = "\n".join([f"â€¢ `{gid}`: {info.get('title', '')[:30]}" for gid, info in already_exists[:5]])
                await message.channel.send(f"ğŸ“š **{len(already_exists)}** å€‹å·²å­˜åœ¨ï¼ˆè·³éï¼‰:\n{exist_list}")
        
        # è™•ç†ç„¡æ•ˆçš„ URL
        if invalid_urls:
            error_list = "\n".join([f"â€¢ `{id}`: {reason}" for id, reason in invalid_urls[:5]])
            await message.channel.send(f"âŒ ä»¥ä¸‹ç„¡æ³•ä¸‹è¼‰:\n{error_list}")
        
        # åŠ å…¥æœ‰æ•ˆçš„ URL
        if valid_urls:
            queue_size = download_queue.qsize() + len(valid_urls)
            
            # ç™¼é€ç°¡åŒ–çš„ç‹€æ…‹è¨Šæ¯ï¼ˆåªé¡¯ç¤ºè™Ÿç¢¼ï¼‰
            if len(valid_urls) == 1:
                _, gallery_id, _ = valid_urls[0]
                await message.channel.send(f"ğŸ“¥ **#{gallery_id}** å·²åŠ å…¥ä½‡åˆ—\nğŸ“Š ä½‡åˆ—: {queue_size}")
            else:
                id_list = ", ".join([f"`{gid}`" for _, gid, _ in valid_urls[:10]])
                await message.channel.send(f"ğŸ“¥ **{len(valid_urls)}** å€‹å·²åŠ å…¥ä½‡åˆ—\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
            
            # æ·»åŠ æˆåŠŸ reaction åˆ°åŸå§‹è¨Šæ¯
            try:
                await message.add_reaction('âœ…')
            except:
                pass
            
            # åŠ å…¥ä½‡åˆ—ï¼ˆä¸å‚³é status_msg_idï¼Œloading emoji æ”¹åœ¨é–‹å§‹ä¸‹è¼‰æ™‚é¡¯ç¤ºï¼‰
            for url, gallery_id, title in valid_urls:
                download_queue.put((url, message.channel.id, None))
            
            logger.info(f"[å°ˆç”¨é »é“] æ–°å¢ {len(valid_urls)} å€‹ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {message.author})")
    
    async def on_command_error(self, ctx, error):
        """å…¨åŸŸéŒ¯èª¤è™•ç†"""
        if isinstance(error, commands.CommandNotFound):
            return  # å¿½ç•¥æœªçŸ¥æŒ‡ä»¤
        
        logger.error(f"æŒ‡ä»¤éŒ¯èª¤: {error}")
        await ctx.send(f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤: {str(error)}")


# å»ºç«‹ Bot å¯¦ä¾‹
bot = HentaiFetcherBot()


# ==================== æ–œç·šæŒ‡ä»¤ ====================

@bot.tree.command(name='dl', description='ä¸‹è¼‰ nhentai æœ¬å­')
@app_commands.describe(
    gallery_ids='ä¸€å€‹æˆ–å¤šå€‹ nhentai è™Ÿç¢¼ï¼Œç”¨ç©ºæ ¼åˆ†éš”',
    force='å¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼ˆè·³éé‡è¤‡æª¢æŸ¥ï¼‰'
)
async def dl_command(interaction: discord.Interaction, gallery_ids: str, force: bool = False):
    """ä¸‹è¼‰ nhentai æœ¬å­"""
    await interaction.response.defer()
    
    # è§£æè¼¸å…¥
    parsed_urls = parse_input_to_urls(gallery_ids)
    
    if not parsed_urls:
        await interaction.followup.send("âš ï¸ ç„¡æ³•è§£æè¼¸å…¥ã€‚è«‹æä¾›æœ‰æ•ˆçš„ nhentai è™Ÿç¢¼ã€‚")
        return
    
    # å¦‚æœä¸æ˜¯å¼·åˆ¶æ¨¡å¼ï¼Œæª¢æŸ¥é‡è¤‡
    new_urls = []
    already_exists = []
    
    if not force:
        for url in parsed_urls:
            match = re.search(r'/g/(\d+)', url)
            if match:
                gallery_id = match.group(1)
                exists, info = check_already_downloaded(gallery_id)
                if exists:
                    already_exists.append((gallery_id, info))
                else:
                    new_urls.append((url, gallery_id))
            else:
                new_urls.append((url, None))
        
        # å›å ±å·²å­˜åœ¨çš„é …ç›®
        if already_exists:
            if len(already_exists) == 1:
                gid, info = already_exists[0]
                title = info.get('title', '')[:40]
                web_url = info.get('web_url', '')
                await interaction.followup.send(f"ğŸ“š **#{gid}** å·²å­˜åœ¨\nğŸ“– {title}\nğŸ”— {web_url}")
            else:
                exist_list = "\n".join([f"â€¢ `{gid}`: {info.get('title', '')[:30]}" for gid, info in already_exists[:5]])
                await interaction.followup.send(f"ğŸ“š **{len(already_exists)}** å€‹å·²å­˜åœ¨ï¼ˆè·³éï¼‰:\n{exist_list}")
        
        if not new_urls:
            return
    else:
        new_urls = [(url, re.search(r'/g/(\d+)', url).group(1) if re.search(r'/g/(\d+)', url) else None) for url in parsed_urls]
    
    # åŠ å…¥ä½‡åˆ—
    queue_size = download_queue.qsize() + len(new_urls)
    gallery_id_list = [gid for _, gid in new_urls if gid]
    
    mode_str = "ï¼ˆå¼·åˆ¶æ¨¡å¼ï¼‰" if force else ""
    if len(new_urls) == 1 and gallery_id_list:
        await interaction.followup.send(f"ğŸ“¥ **#{gallery_id_list[0]}** å·²åŠ å…¥ä½‡åˆ—{mode_str}\nğŸ“Š ä½‡åˆ—: {queue_size}")
    else:
        id_list = ", ".join([f"`{gid}`" for gid in gallery_id_list[:10]])
        await interaction.followup.send(f"ğŸ“¥ **{len(gallery_id_list)}** å€‹å·²åŠ å…¥ä½‡åˆ—{mode_str}\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
    
    # åŠ å…¥ä½‡åˆ—
    for url, _ in new_urls:
        download_queue.put((url, interaction.channel_id, None, force))
    
    logger.info(f"æ–°å¢ {len(new_urls)} å€‹ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {interaction.user})")


@bot.tree.command(name='queue', description='æŸ¥çœ‹ä¸‹è¼‰ä½‡åˆ—ç‹€æ…‹')
async def queue_command(interaction: discord.Interaction):
    """æŸ¥çœ‹ä¸‹è¼‰ä½‡åˆ—"""
    size = download_queue.qsize()
    await interaction.response.send_message(f"ğŸ“Š ä½‡åˆ—ä¸­ç­‰å¾…ä»»å‹™: {size}")


@bot.tree.command(name='ping', description='æ¸¬è©¦æ©Ÿå™¨äººé€£ç·š')
async def ping_command(interaction: discord.Interaction):
    """æ¸¬è©¦é€£ç·š"""
    latency = round(bot.latency * 1000)
    await interaction.response.send_message(f"ğŸ“ Pong! å»¶é²: {latency}ms")


@bot.tree.command(name='version', description='é¡¯ç¤ºæ©Ÿå™¨äººç‰ˆæœ¬')
async def version_command(interaction: discord.Interaction):
    """é¡¯ç¤ºç‰ˆæœ¬"""
    await interaction.response.send_message(f"ğŸ“¦ HentaiFetcher ç‰ˆæœ¬: **{VERSION}**")


@bot.tree.command(name='status', description='é¡¯ç¤ºæ©Ÿå™¨äººç‹€æ…‹')
async def status_command(interaction: discord.Interaction):
    """é¡¯ç¤ºç‹€æ…‹"""
    embed = discord.Embed(
        title="ğŸ“Š HentaiFetcher Status",
        color=discord.Color.blue()
    )
    embed.add_field(name="ä½‡åˆ—ä»»å‹™", value=str(download_queue.qsize()), inline=True)
    embed.add_field(name="å»¶é²", value=f"{round(bot.latency * 1000)}ms", inline=True)
    embed.add_field(name="ä¼ºæœå™¨æ•¸", value=str(len(bot.guilds)), inline=True)
    
    # é¡¯ç¤ºç›®å‰ä¸‹è¼‰ç‹€æ…‹
    if bot.worker and bot.worker.current_task:
        match = re.search(r'/g/(\d+)', bot.worker.current_task)
        task_id = match.group(1) if match else "..."
        embed.add_field(name="ç›®å‰ä¸‹è¼‰", value=f"ğŸ”„ `{task_id}`", inline=True)
    else:
        embed.add_field(name="ç›®å‰ä¸‹è¼‰", value="â³ ç­‰å¾…ä¸­", inline=True)
    
    embed.set_footer(text="ä½¿ç”¨ /dl <è™Ÿç¢¼> é–‹å§‹ä¸‹è¼‰")
    
    await interaction.response.send_message(embed=embed)


@bot.tree.command(name='list', description='åˆ—å‡ºæ‰€æœ‰å·²ä¸‹è¼‰çš„æœ¬å­')
async def list_command(interaction: discord.Interaction):
    """åˆ—å‡ºæ‰€æœ‰å·²ä¸‹è¼‰çš„æœ¬å­"""
    await interaction.response.defer()  # å¯èƒ½éœ€è¦è¼ƒé•·æ™‚é–“
    
    try:
        from urllib.parse import quote
        
        if not DOWNLOAD_DIR.exists():
            await interaction.followup.send("ğŸ“‚ ä¸‹è¼‰è³‡æ–™å¤¾ä¸å­˜åœ¨")
            return
        
        # ç²å–æ‰€æœ‰å­è³‡æ–™å¤¾
        folders = [f for f in DOWNLOAD_DIR.iterdir() if f.is_dir()]
        
        if not folders:
            await interaction.followup.send("ğŸ“‚ ç›®å‰æ²’æœ‰ä»»ä½•ä¸‹è¼‰")
            return
        
        # æ§‹å»ºç´”æ–‡å­—è¨Šæ¯ï¼ˆåˆ†æ‰¹ç™¼é€ä»¥é¿å… 2000 å­—å…ƒé™åˆ¶ï¼‰
        items = []
        
        for folder in folders:
            folder_name = folder.name
            
            # å˜—è©¦å¾ metadata.json ç²å– gallery_id
            metadata_path = folder / "metadata.json"
            gallery_id = ""
            if metadata_path.exists():
                try:
                    with open(metadata_path, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                        # å„ªå…ˆå¾ gallery_id ç²å–
                        gallery_id = metadata.get('gallery_id', '')
                        # å¦‚æœæ²’æœ‰ï¼Œå¾ URL æå–
                        if not gallery_id:
                            url = metadata.get('url', '')
                            match = re.search(r'/g/(\d+)', url)
                            if match:
                                gallery_id = match.group(1)
                except:
                    pass
            
            items.append((gallery_id, folder_name))
        
        # æŒ‰è™Ÿç¢¼æ’åºï¼ˆå¾å°åˆ°å¤§ï¼‰
        items.sort(key=lambda x: int(x[0]) if x[0].isdigit() else 0)
        
        # æ§‹å»ºè¼¸å‡º
        msg_lines = []
        for gallery_id, folder_name in items:
            # æ ¼å¼ï¼š`#è™Ÿç¢¼` æ›¸åï¼ˆä¸è¦é€£çµï¼‰
            if gallery_id:
                msg_lines.append(f"`#{gallery_id}` {folder_name}")
            else:
                msg_lines.append(f"{folder_name}")
        
        # ç™¼é€ç¬¬ä¸€æ¢è¨Šæ¯
        header = f"ğŸ“š **å·²ä¸‹è¼‰çš„æœ¬å­** (å…± {len(folders)} æœ¬)\n"
        await interaction.followup.send(header)
        
        current_batch = []
        current_length = 0
        
        for line in msg_lines:
            line_length = len(line) + 1  # +1 for newline
            if current_length + line_length > 1800:
                # ç™¼é€ç•¶å‰æ‰¹æ¬¡
                await interaction.channel.send("\n".join(current_batch))
                current_batch = [line]
                current_length = line_length
            else:
                current_batch.append(line)
                current_length += line_length
        
        # ç™¼é€æœ€å¾Œä¸€æ‰¹
        if current_batch:
            await interaction.channel.send("\n".join(current_batch))
        
    except Exception as e:
        logger.error(f"åˆ—å‡ºä¸‹è¼‰å¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ åˆ—å‡ºå¤±æ•—: {e}")


@bot.tree.command(name='random', description='éš¨æ©Ÿé¡¯ç¤ºæœ¬å­')
@app_commands.describe(count='é¡¯ç¤ºæ•¸é‡ (1-5)')
async def random_command(interaction: discord.Interaction, count: int = 1):
    """éš¨æ©Ÿé¡¯ç¤ºæœ¬å­"""
    await interaction.response.defer()
    
    try:
        from eagle_library import EagleLibrary
        from pathlib import Path
        import re
        
        eagle = EagleLibrary()
        
        # é™åˆ¶æ•¸é‡
        count = max(1, min(count, 5))  # 1-5 æœ¬
        
        # å¾ Eagle Library éš¨æ©Ÿé¸å–
        selected = eagle.get_random(count)
        
        if not selected:
            await interaction.followup.send("ğŸ“‚ Eagle Library ä¸­æ²’æœ‰ä»»ä½•æœ¬å­")
            return
        
        for item in selected:
            title = item.get('title', 'æœªçŸ¥')
            gallery_id = item.get('nhentai_id', 'æœªçŸ¥')
            web_url = item.get('web_url', '')
            tags = item.get('tags', [])
            eagle_folder = item.get('folder_path', '')
            
            # è§£æ tags
            artists = [tag.replace('artist:', '') for tag in tags if isinstance(tag, str) and tag.startswith('artist:')]
            parodies = [tag.replace('parody:', '') for tag in tags if isinstance(tag, str) and tag.startswith('parody:')]
            groups = [tag.replace('group:', '') for tag in tags if isinstance(tag, str) and tag.startswith('group:')]
            languages = [tag.replace('language:', '') for tag in tags if isinstance(tag, str) and tag.startswith('language:')]
            other_tags = [tag for tag in tags if isinstance(tag, str) and not any(tag.startswith(prefix) for prefix in ['artist:', 'parody:', 'group:', 'language:', 'type:'])]
            
            # å…ˆç™¼é€å°é¢åœ–ç‰‡
            cover_sent = False
            if eagle_folder:
                try:
                    folder_path = Path(eagle_folder)
                    # Eagle è³‡æ–™å¤¾ä¸­å¯èƒ½çš„å°é¢æª”å
                    for cover_name in ['cover.jpg', 'cover.png', 'cover.webp', 'thumbnail.png']:
                        cover_path = folder_path / cover_name
                        if cover_path.exists():
                            file = discord.File(str(cover_path), filename=cover_name)
                            await interaction.channel.send(file=file)
                            cover_sent = True
                            logger.info(f"ç™¼é€å°é¢: {cover_name}")
                            break
                    
                    # å¦‚æœæ²’æ‰¾åˆ°å°é¢ï¼Œæ‰¾ç¬¬ä¸€å¼µåœ–ç‰‡
                    if not cover_sent:
                        for ext in ['*.jpg', '*.jpeg', '*.png', '*.webp']:
                            images = list(folder_path.glob(ext))
                            if images:
                                images.sort(key=lambda x: x.name)
                                file = discord.File(str(images[0]), filename=images[0].name)
                                await interaction.channel.send(file=file)
                                cover_sent = True
                                break
                except Exception as e:
                    logger.debug(f"å°é¢ç™¼é€å¤±æ•—: {e}")
            
            # æ§‹å»ºè³‡æ–™è¨Šæ¯
            msg_lines = []
            
            # æ¨™é¡Œèˆ‡é€£çµ
            msg_lines.append(f"ğŸ“– **#{gallery_id}**")
            if web_url:
                msg_lines.append(f"ğŸ“¥ {web_url}")
            msg_lines.append(f"\n**{title}**\n")
            
            # åŸºæœ¬ä¿¡æ¯
            info_lines = []
            if artists:
                info_lines.append(f"âœï¸ ä½œè€…: {', '.join(artists[:3])}")
            if groups:
                info_lines.append(f"ğŸ‘¥ ç¤¾åœ˜: {', '.join(groups[:2])}")
            if parodies:
                info_lines.append(f"ğŸ¬ åŸä½œ: {', '.join(parodies[:3])}")
            if languages:
                info_lines.append(f"ğŸŒ èªè¨€: {', '.join(languages)}")
            
            if info_lines:
                msg_lines.extend(info_lines)
            
            # Tags
            if other_tags:
                msg_lines.append(f"\nğŸ·ï¸ {', '.join([f'`{tag}`' for tag in other_tags[:10]])}")
                if len(other_tags) > 10:
                    msg_lines.append(f"`+{len(other_tags)-10} more`")
            
            # ç™¼é€è³‡æ–™è¨Šæ¯
            final_msg = "\n".join(msg_lines)
            if len(final_msg) > 1900:
                final_msg = final_msg[:1900] + "..."
            await interaction.followup.send(final_msg)
    
    except ImportError:
        await interaction.followup.send("âŒ Eagle Library æ¨¡çµ„æœªå®‰è£")
    except Exception as e:
        logger.error(f"éš¨æ©Ÿé¡¯ç¤ºå¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ éš¨æ©Ÿé¡¯ç¤ºå¤±æ•—: {e}")


@bot.tree.command(name='fixcover', description='ç‚ºå·²ä¸‹è¼‰çš„æœ¬å­è£œå……å°é¢')
async def fixcover_command(interaction: discord.Interaction):
    """ç‚ºå·²æœ‰çš„æœ¬å­è£œå……å°é¢"""
    await interaction.response.defer()
    
    try:
        if not DOWNLOAD_DIR.exists():
            await interaction.followup.send("ğŸ“‚ ä¸‹è¼‰è³‡æ–™å¤¾ä¸å­˜åœ¨")
            return
        
        await interaction.followup.send("ğŸ” é–‹å§‹æƒæä¸¦è£œå……å°é¢...")
        
        folders = [f for f in DOWNLOAD_DIR.iterdir() if f.is_dir()]
        fixed_count = 0
        skipped_count = 0
        fallback_count = 0  # ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢çš„æ•¸é‡
        failed_count = 0
        
        for folder in folders:
            # æª¢æŸ¥æ˜¯å¦å·²æœ‰å°é¢
            has_cover = any(list(folder.glob(f"cover.{ext}")) for ext in ['jpg', 'jpeg', 'png', 'gif', 'webp'])
            
            if has_cover:
                skipped_count += 1
                continue
            
            # å¾ metadata.json ç²å– gallery_id
            metadata_path = folder / "metadata.json"
            gallery_id = ""
            
            if metadata_path.exists():
                try:
                    with open(metadata_path, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                        # å¾ url æå– gallery_id
                        url = metadata.get('url', '')
                        match = re.search(r'/g/(\d+)', url)
                        if match:
                            gallery_id = match.group(1)
                except Exception as e:
                    logger.error(f"è®€å– metadata å¤±æ•— ({folder.name}): {e}")
            
            cover_success = False
            
            if gallery_id:
                # å˜—è©¦å¾ nhentai ä¸‹è¼‰å°é¢
                if download_nhentai_cover(gallery_id, folder):
                    fixed_count += 1
                    cover_success = True
                    logger.info(f"è£œå……å°é¢æˆåŠŸ (nhentai å°é¢): {folder.name}")
                else:
                    # å°é¢ä¸‹è¼‰å¤±æ•—ï¼Œå˜—è©¦ä¸‹è¼‰ç¬¬ä¸€é ä½œç‚ºå°é¢
                    await asyncio.sleep(0.3)  # çŸ­æš«å»¶é²é¿å…è«‹æ±‚å¤ªå¿«
                    if download_nhentai_first_page(gallery_id, folder):
                        fallback_count += 1
                        cover_success = True
                        logger.info(f"è£œå……å°é¢æˆåŠŸ (nhentai ç¬¬ä¸€é ): {folder.name}")
                # é¿å…è«‹æ±‚å¤ªé »ç¹
                await asyncio.sleep(0.5)
            
            # å¦‚æœå¾ nhentai éƒ½å¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨è³‡æ–™å¤¾å…§çš„ç¬¬ä¸€å¼µåœ–ç‰‡
            if not cover_success:
                first_image = get_first_image_as_cover(folder)
                if first_image:
                    fallback_count += 1
                    cover_success = True
                    logger.info(f"è£œå……å°é¢æˆåŠŸ (æœ¬åœ°åœ–ç‰‡): {folder.name}")
                else:
                    failed_count += 1
                    logger.warning(f"è£œå……å°é¢å¤±æ•— (æ‰€æœ‰æ–¹æ³•éƒ½å¤±æ•—): {folder.name}")
        
        msg = f"âœ… å®Œæˆï¼\n"
        msg += f"ğŸ“¥ å¾ nhentai å°é¢ä¸‹è¼‰äº† {fixed_count} å€‹\n"
        if fallback_count > 0:
            msg += f"ğŸ–¼ï¸ ä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ {fallback_count} å€‹\n"
        msg += f"â­ï¸ è·³é {skipped_count} å€‹å·²æœ‰å°é¢\n"
        if failed_count > 0:
            msg += f"âŒ å¤±æ•— {failed_count} å€‹"
        await interaction.channel.send(msg)
        
    except Exception as e:
        logger.error(f"è£œå……å°é¢å¤±æ•—: {e}")
        await interaction.channel.send(f"âŒ è£œå……å°é¢å¤±æ•—: {e}")


@bot.tree.command(name='cleanup', description='æ¸…é™¤é‡è¤‡çš„è³‡æ–™å¤¾')
async def cleanup_command(interaction: discord.Interaction):
    """æ¸…é™¤é‡è¤‡çš„è³‡æ–™å¤¾ï¼ˆæœ‰æ™‚é–“æˆ³å¾Œç¶´çš„ï¼‰"""
    await interaction.response.defer()
    
    try:
        if not DOWNLOAD_DIR.exists():
            await interaction.followup.send("ğŸ“‚ ä¸‹è¼‰è³‡æ–™å¤¾ä¸å­˜åœ¨")
            return
        
        # æ‰¾å‡ºæœ‰æ™‚é–“æˆ³å¾Œç¶´çš„è³‡æ–™å¤¾ï¼ˆæ ¼å¼ï¼šæ¨™é¡Œ_æ™‚é–“æˆ³ï¼‰
        import re
        timestamp_pattern = re.compile(r'^(.+)_(\d{10})$')  # 10 ä½æ•¸æ™‚é–“æˆ³
        
        folders = [f for f in DOWNLOAD_DIR.iterdir() if f.is_dir()]
        duplicates = []
        
        for folder in folders:
            match = timestamp_pattern.match(folder.name)
            if match:
                original_name = match.group(1)
                original_path = DOWNLOAD_DIR / original_name
                
                # å¦‚æœåŸå§‹è³‡æ–™å¤¾ä¹Ÿå­˜åœ¨ï¼Œé€™å€‹å°±æ˜¯é‡è¤‡çš„
                if original_path.exists() and original_path.is_dir():
                    duplicates.append(folder)
        
        if not duplicates:
            await interaction.followup.send("âœ… æ²’æœ‰ç™¼ç¾é‡è¤‡çš„è³‡æ–™å¤¾")
            return
        
        # é¡¯ç¤ºå°‡è¦åˆªé™¤çš„è³‡æ–™å¤¾
        msg = f"ğŸ” ç™¼ç¾ {len(duplicates)} å€‹é‡è¤‡è³‡æ–™å¤¾ï¼š\n"
        for dup in duplicates[:10]:
            msg += f"â€¢ `{dup.name}`\n"
        if len(duplicates) > 10:
            msg += f"... é‚„æœ‰ {len(duplicates) - 10} å€‹\n"
        msg += "\nâš ï¸ ç¢ºå®šè¦åˆªé™¤å—ï¼Ÿå›è¦† `ç¢ºèª` æˆ– `yes` ä¾†åŸ·è¡Œåˆªé™¤"
        
        await interaction.followup.send(msg)
        
        # ç­‰å¾…ç¢ºèª
        def check(m):
            return m.author.id == interaction.user.id and m.channel.id == interaction.channel_id and m.content.lower() in ['ç¢ºèª', 'yes', 'y']
        
        try:
            confirm_msg = await bot.wait_for('message', timeout=30.0, check=check)
        except:
            await interaction.channel.send("â° è¶…æ™‚ï¼Œå–æ¶ˆæ“ä½œ")
            return
        
        # åŸ·è¡Œåˆªé™¤
        deleted = 0
        for dup in duplicates:
            try:
                shutil.rmtree(dup)
                deleted += 1
                logger.info(f"å·²åˆªé™¤é‡è¤‡è³‡æ–™å¤¾: {dup.name}")
            except Exception as e:
                logger.error(f"åˆªé™¤å¤±æ•— {dup.name}: {e}")
        
        await interaction.channel.send(f"âœ… å·²åˆªé™¤ {deleted}/{len(duplicates)} å€‹é‡è¤‡è³‡æ–™å¤¾")
        
    except Exception as e:
        logger.error(f"æ¸…é™¤é‡è¤‡å¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ æ¸…é™¤å¤±æ•—: {e}")


# ==================== Eagle Library æœå°‹æŒ‡ä»¤ ====================

@bot.tree.command(name='search', description='æœå°‹ Eagle Library ä¸­çš„æœ¬å­')
@app_commands.describe(query='æœå°‹é—œéµå­—æˆ– nhentai ID')
async def search_command(interaction: discord.Interaction, query: str):
    """æœå°‹ Eagle Library ä¸­çš„æœ¬å­"""
    await interaction.response.defer()
    
    try:
        from eagle_library import EagleLibrary
        eagle = EagleLibrary()
        
        # åˆ¤æ–·æ˜¯ ID é‚„æ˜¯é—œéµå­—
        query = query.strip()
        results = []
        
        if query.isdigit():
            # ç”¨ nhentai ID æœå°‹
            result = eagle.find_by_nhentai_id(query)
            if result:
                results = [result]
            search_type = f"nhentai ID `{query}`"
        else:
            # ç”¨é—œéµå­—æœå°‹
            results = eagle.find_by_title(query)
            search_type = f"é—œéµå­— `{query}`"
        
        if not results:
            await interaction.followup.send(f"ğŸ” æ‰¾ä¸åˆ°ç¬¦åˆ {search_type} çš„çµæœ")
            return
        
        # é™åˆ¶é¡¯ç¤ºæ•¸é‡
        total = len(results)
        results = results[:10]
        
        embed = discord.Embed(
            title=f"ğŸ” æœå°‹çµæœ - {search_type}",
            description=f"æ‰¾åˆ° {total} å€‹çµæœ" + (f"ï¼ˆé¡¯ç¤ºå‰ 10 å€‹ï¼‰" if total > 10 else ""),
            color=discord.Color.blue()
        )
        
        for i, r in enumerate(results, 1):
            title = r.get('title', 'æœªçŸ¥')
            if len(title) > 50:
                title = title[:47] + "..."
            
            nhentai_id = r.get('nhentai_id', 'N/A')
            web_url = r.get('web_url', '')
            
            # å»ºç«‹æ¬„ä½å…§å®¹
            value = f"ğŸ“– ID: `{nhentai_id}`\n"
            if web_url:
                value += f"ğŸ”— [é–‹å•Ÿ PDF]({web_url})"
            
            embed.add_field(
                name=f"{i}. {title}",
                value=value,
                inline=False
            )
        
        embed.set_footer(text="ä½¿ç”¨ /read <ID> ç›´æ¥å–å¾—é€£çµ")
        await interaction.followup.send(embed=embed)
        
    except ImportError:
        await interaction.followup.send("âŒ Eagle Library æ¨¡çµ„æœªå®‰è£")
    except Exception as e:
        logger.error(f"æœå°‹å¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ æœå°‹å¤±æ•—: {e}")


@bot.tree.command(name='read', description='å–å¾—æœ¬å­çš„ PDF é€£çµ')
@app_commands.describe(nhentai_id='nhentai ID æˆ–ç¶²å€')
async def read_command(interaction: discord.Interaction, nhentai_id: str):
    """å–å¾—æœ¬å­çš„ PDF é€£çµ"""
    await interaction.response.defer()
    
    # æ¸…ç†è¼¸å…¥
    nhentai_id = nhentai_id.strip()
    if not nhentai_id.isdigit():
        # å˜—è©¦å¾ç¶²å€æå–
        match = re.search(r'/g/(\d+)', nhentai_id)
        if match:
            nhentai_id = match.group(1)
        else:
            await interaction.followup.send("âŒ è«‹æä¾›æœ‰æ•ˆçš„ nhentai ID æˆ–ç¶²å€")
            return
    
    try:
        from eagle_library import EagleLibrary
        eagle = EagleLibrary()
        
        result = eagle.find_by_nhentai_id(nhentai_id)
        
        if not result:
            await interaction.followup.send(f"ğŸ” æ‰¾ä¸åˆ° nhentai ID `{nhentai_id}` çš„æœ¬å­\nğŸ’¡ å¯èƒ½å°šæœªåŒ¯å…¥ Eagleï¼Œè«‹å…ˆä½¿ç”¨ `/dl {nhentai_id}` ä¸‹è¼‰")
            return
        
        title = result.get('title', 'æœªçŸ¥')
        web_url = result.get('web_url', '')
        nhentai_url = result.get('nhentai_url', f"https://nhentai.net/g/{nhentai_id}/")
        tags = result.get('tags', [])
        
        embed = discord.Embed(
            title=f"ğŸ“– {title}",
            color=discord.Color.green()
        )
        
        embed.add_field(name="ğŸ”¢ nhentai ID", value=f"`{nhentai_id}`", inline=True)
        embed.add_field(name="ğŸŒ nhentai", value=f"[é–‹å•Ÿ]({nhentai_url})", inline=True)
        
        if web_url:
            embed.add_field(name="ğŸ“„ PDF", value=f"[é–‹å•Ÿé–±è®€]({web_url})", inline=True)
        
        # é¡¯ç¤ºéƒ¨åˆ†æ¨™ç±¤
        if tags:
            # éæ¿¾ä¸¦é¡¯ç¤ºä¸»è¦æ¨™ç±¤
            display_tags = [t for t in tags[:8] if not t.startswith(('type:', 'language:'))]
            if display_tags:
                embed.add_field(
                    name="ğŸ·ï¸ æ¨™ç±¤",
                    value=" ".join([f"`{t}`" for t in display_tags[:6]]),
                    inline=False
                )
        
        embed.set_footer(text="é»æ“Š PDF é€£çµå³å¯åœ¨ç€è¦½å™¨ä¸­é–±è®€")
        
        await interaction.followup.send(embed=embed)
        
    except ImportError:
        await interaction.followup.send("âŒ Eagle Library æ¨¡çµ„æœªå®‰è£")
    except Exception as e:
        logger.error(f"è®€å–å¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ è®€å–å¤±æ•—: {e}")


@bot.tree.command(name='eagle', description='é¡¯ç¤º Eagle Library çµ±è¨ˆ')
async def eagle_stats_command(interaction: discord.Interaction):
    """é¡¯ç¤º Eagle Library çµ±è¨ˆ"""
    await interaction.response.defer()
    
    try:
        from eagle_library import EagleLibrary
        eagle = EagleLibrary()
        
        stats = eagle.get_stats()
        
        embed = discord.Embed(
            title="ğŸ¦… Eagle Library çµ±è¨ˆ",
            color=discord.Color.gold()
        )
        
        embed.add_field(name="ğŸ“š å·²åŒ¯å…¥", value=f"`{stats['total_count']}` æœ¬", inline=True)
        embed.add_field(name="ğŸ”¢ æœ‰ ID", value=f"`{stats['with_nhentai_id']}` æœ¬", inline=True)
        
        if stats.get('last_updated'):
            from datetime import datetime
            try:
                dt = datetime.fromisoformat(stats['last_updated'].replace('Z', '+00:00'))
                embed.add_field(
                    name="ğŸ• æœ€å¾Œæ›´æ–°",
                    value=dt.strftime("%Y-%m-%d %H:%M"),
                    inline=True
                )
            except:
                pass
        
        embed.set_footer(text="ä½¿ç”¨ /search <é—œéµå­—> æœå°‹ | /read <ID> å–å¾—é€£çµ | /reindex é‡å»ºç´¢å¼•")
        
        await interaction.followup.send(embed=embed)
        
    except ImportError:
        await interaction.followup.send("âŒ Eagle Library æ¨¡çµ„æœªå®‰è£")
    except Exception as e:
        logger.error(f"çµ±è¨ˆå¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ çµ±è¨ˆå¤±æ•—: {e}")


@bot.tree.command(name='reindex', description='é‡å»º Eagle Library ç´¢å¼•')
async def reindex_command(interaction: discord.Interaction):
    """é‡å»º Eagle Library ç´¢å¼•"""
    await interaction.response.defer()
    
    try:
        from eagle_library import EagleLibrary
        eagle = EagleLibrary()
        
        await interaction.followup.send("ğŸ”„ æ­£åœ¨æƒæ Eagle Library...")
        
        added = eagle.rebuild_index()
        stats = eagle.get_stats()
        
        if added > 0:
            await interaction.channel.send(f"âœ… ç´¢å¼•é‡å»ºå®Œæˆï¼\nğŸ“¥ æ–°å¢ `{added}` å€‹é …ç›®\nğŸ“š ç¸½è¨ˆ `{stats['total_count']}` æœ¬")
        else:
            await interaction.channel.send(f"âœ… ç´¢å¼•å·²æ˜¯æœ€æ–°ï¼\nğŸ“š ç¸½è¨ˆ `{stats['total_count']}` æœ¬")
        
    except ImportError:
        await interaction.followup.send("âŒ Eagle Library æ¨¡çµ„æœªå®‰è£")
    except Exception as e:
        logger.error(f"é‡å»ºç´¢å¼•å¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ é‡å»ºç´¢å¼•å¤±æ•—: {e}")


@bot.tree.command(name='help', description='é¡¯ç¤ºä½¿ç”¨èªªæ˜')
async def help_command(interaction: discord.Interaction):
    """é¡¯ç¤ºèªªæ˜"""
    embed = discord.Embed(
        title="ğŸ“– HentaiFetcher ä½¿ç”¨èªªæ˜",
        description="è‡ªå‹•ä¸‹è¼‰æ¼«ç•«ä¸¦è½‰æ›ç‚º PDFï¼Œç”Ÿæˆ Eagle ç›¸å®¹ metadata",
        color=discord.Color.green()
    )
    
    # æª¢æŸ¥æ˜¯å¦åœ¨å°ˆç”¨é »é“
    is_dedicated = (
        interaction.channel.name.lower() in [n.lower() for n in DEDICATED_CHANNEL_NAMES] or
        interaction.channel_id in DEDICATED_CHANNEL_IDS
    )
    
    if is_dedicated:
        embed.add_field(
            name="ğŸ¯ å°ˆç”¨é »é“æ¨¡å¼ï¼ˆæ­¤é »é“ï¼‰",
            value="**æ‰€æœ‰æŒ‡ä»¤éƒ½ä¸éœ€è¦å‰ç¶´ï¼Œç›´æ¥è¼¸å…¥ï¼**\n"
                  "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                  "**ğŸ“¥ ä¸‹è¼‰** - ç›´æ¥è²¼ç¶²å€æˆ–è™Ÿç¢¼ï¼š\n"
                  "```\n"
                  "421633\n"
                  "https://nhentai.net/g/607769/\n"
                  "```\n"
                  "**ğŸ§ª å¼·åˆ¶é‡æ–°ä¸‹è¼‰**ï¼š`test <è™Ÿç¢¼>`\n",
            inline=False
        )
    
    embed.add_field(
        name="ğŸ“Š æ–œç·šæŒ‡ä»¤",
        value="`/queue` - æŸ¥çœ‹ä½‡åˆ—\n"
              "`/status` - Bot ç‹€æ…‹\n"
              "`/list` - åˆ—å‡ºå·²ä¸‹è¼‰\n"
              "`/random [æ•¸é‡]` - éš¨æ©Ÿé¡¯ç¤º\n"
              "`/fixcover` - è£œå……å°é¢\n"
              "`/cleanup` - æ¸…é™¤é‡è¤‡",
        inline=True
    )
    
    embed.add_field(
        name="ğŸ¦… Eagle Library",
        value="`/search <é—œéµå­—>` - æœå°‹æœ¬å­\n"
              "`/read <ID>` - å–å¾— PDF é€£çµ\n"
              "`/eagle` - Library çµ±è¨ˆ\n"
              "`/reindex` - é‡å»ºç´¢å¼•",
        inline=True
    )
    
    embed.add_field(
        name="â„¹ï¸ ç³»çµ±",
        value="`/ping` - æ¸¬è©¦é€£ç·š\n"
              "`/version` - ç‰ˆæœ¬è™Ÿ\n"
              "`/help` - é¡¯ç¤ºæ­¤èªªæ˜",
        inline=True
    )
    
    embed.add_field(
        name="ğŸ“ è¼¸å‡ºçµæœ",
        value="ä¸‹è¼‰å®Œæˆå¾Œæœƒç”Ÿæˆï¼š\n"
              "```\n"
              "downloads/[Gallery_ID]/\n"
              "â”œâ”€â”€ [Gallery_ID].pdf\n"
              "â”œâ”€â”€ cover.jpg\n"
              "â””â”€â”€ metadata.json\n"
              "```",
        inline=False
    )
    
    if is_dedicated:
        embed.set_footer(text="ğŸ¯ å°ˆç”¨é »é“ï¼šå¯ç›´æ¥è²¼è™Ÿç¢¼ä¸‹è¼‰ï¼")
    else:
        embed.set_footer(text="ğŸ’¡ ä½¿ç”¨æ–œç·šæŒ‡ä»¤ / é–‹å§‹")
    
    await interaction.response.send_message(embed=embed)


# ==================== ä¸»ç¨‹å¼å…¥å£ ====================

def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    # å–å¾— Discord Token
    token = os.environ.get('DISCORD_TOKEN')
    
    if not token:
        logger.error("éŒ¯èª¤: æœªè¨­å®š DISCORD_TOKEN ç’°å¢ƒè®Šæ•¸")
        logger.error("è«‹åœ¨ docker-compose.yml ä¸­è¨­å®š DISCORD_TOKEN")
        sys.exit(1)
    
    try:
        logger.info("æ­£åœ¨å•Ÿå‹• HentaiFetcher Bot...")
        bot.run(token)
    except discord.LoginFailure:
        logger.error("Discord ç™»å…¥å¤±æ•—: Token ç„¡æ•ˆ")
        sys.exit(1)
    except Exception as e:
        logger.exception(f"Bot åŸ·è¡ŒéŒ¯èª¤: {e}")
        sys.exit(1)
    finally:
        # åœæ­¢å·¥ä½œåŸ·è¡Œç·’
        if bot.worker:
            bot.worker.stop()


if __name__ == '__main__':
    main()
