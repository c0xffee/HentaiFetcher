#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HentaiFetcher - Discord Bot è‡ªå‹•åŒ–æ¼«ç•«ä¸‹è¼‰å™¨
==============================================
ç‰ˆæœ¬: 3.0.0 - æ–œç·šæŒ‡ä»¤ç‰ˆæœ¬
åŠŸèƒ½ï¼š
1. Discord Bot ä½¿ç”¨æ–œç·šæŒ‡ä»¤ (/dl, /search, /read ç­‰)
2. ä½¿ç”¨ gallery-dl ä¸‹è¼‰åœ–ç‰‡èˆ‡ metadata
3. ä½¿ç”¨ Pillow è½‰æ›ç‚ºç­‰å¯¬ PDF
4. ç”Ÿæˆ Eagle ç›¸å®¹çš„ metadata.json
5. è‡ªå‹•æ¸…ç†åŸå§‹åœ–ç‰‡æª”æ¡ˆ
6. æ•´åˆ Eagle Library æŸ¥è©¢
"""

# ç‰ˆæœ¬è™Ÿ - ç”¨ä¾†ç¢ºèªå®¹å™¨æ˜¯å¦æ›´æ–°
VERSION = "3.3.6"

print(f"[STARTUP] HentaiFetcher ç‰ˆæœ¬ {VERSION} æ­£åœ¨è¼‰å…¥...", flush=True)

import os
import sys
import json
import time
import shutil
import asyncio
import logging
import subprocess
import threading
import re
import requests
from queue import Queue, Empty
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, List
from urllib.parse import quote

import discord
from discord.ext import commands
from discord import app_commands

# è¼‰å…¥ .env æª”æ¡ˆï¼ˆæœ¬åœ°æ¸¬è©¦ç”¨ï¼‰
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("[STARTUP] å·²è¼‰å…¥ .env æª”æ¡ˆ", flush=True)
except ImportError:
    pass  # Docker ç’°å¢ƒä¸éœ€è¦ dotenv

print(f"[STARTUP] æ¨¡çµ„è¼‰å…¥å®Œæˆ", flush=True)

# ==================== è¨­å®šå€å¡Š ====================

# åˆ¤æ–·é‹è¡Œç’°å¢ƒï¼ˆDocker æˆ–æœ¬åœ°ï¼‰
import platform
IS_DOCKER = platform.system() == 'Linux' and os.path.exists('/app')

if IS_DOCKER:
    # Docker ç’°å¢ƒ - ä½¿ç”¨å®¹å™¨å…§è·¯å¾‘
    BASE_DIR = Path('/app')
    print("[STARTUP] é‹è¡Œç’°å¢ƒ: Docker", flush=True)
else:
    # æœ¬åœ°æ¸¬è©¦ç’°å¢ƒ - ä½¿ç”¨å°ˆæ¡ˆè³‡æ–™å¤¾
    BASE_DIR = Path(__file__).parent.resolve()
    print(f"[STARTUP] é‹è¡Œç’°å¢ƒ: æœ¬åœ° ({BASE_DIR})", flush=True)

# çµ±ä¸€ä½¿ç”¨ç›¸åŒçš„å­è³‡æ–™å¤¾
CONFIG_DIR = BASE_DIR / 'config'
DOWNLOAD_DIR = BASE_DIR / 'downloads'
TEMP_DIR = BASE_DIR / 'temp'

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
CONFIG_DIR.mkdir(parents=True, exist_ok=True)
DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)
TEMP_DIR.mkdir(parents=True, exist_ok=True)

# æ—¥èªŒè¨­å®š
log_file = CONFIG_DIR / 'bot.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(str(log_file), encoding='utf-8')
    ]
)
logger = logging.getLogger('HentaiFetcher')

# ä¸‹è¼‰ä½‡åˆ— - çµæ§‹: (url, channel_id, status_message_id, force_mode, batch_id)
download_queue: Queue = Queue()

# å–æ¶ˆä¸‹è¼‰è¿½è¹¤å™¨ - ç”¨æ–¼æ¨™è¨˜éœ€è¦å–æ¶ˆçš„ä¸‹è¼‰ä»»å‹™
# çµæ§‹: {gallery_id: threading.Event}  - Event è¢« set æ™‚è¡¨ç¤ºä»»å‹™æ‡‰è©²è¢«å–æ¶ˆ
cancel_events: Dict[str, threading.Event] = {}
cancel_lock = threading.Lock()

def request_cancel(gallery_id: str) -> bool:
    """è«‹æ±‚å–æ¶ˆä¸‹è¼‰"""
    with cancel_lock:
        if gallery_id in cancel_events:
            cancel_events[gallery_id].set()
            return True
        return False

def register_cancel_event(gallery_id: str) -> threading.Event:
    """è¨»å†Šå–æ¶ˆäº‹ä»¶"""
    with cancel_lock:
        event = threading.Event()
        cancel_events[gallery_id] = event
        return event

def unregister_cancel_event(gallery_id: str):
    """å–æ¶ˆè¨»å†Šå–æ¶ˆäº‹ä»¶"""
    with cancel_lock:
        cancel_events.pop(gallery_id, None)

def is_cancelled(gallery_id: str) -> bool:
    """æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ"""
    with cancel_lock:
        event = cancel_events.get(gallery_id)
        return event.is_set() if event else False

# æ‰¹æ¬¡ä¸‹è¼‰è¿½è¹¤å™¨ - ç”¨æ–¼çµ±è¨ˆå¤šæª”æ¡ˆä¸‹è¼‰çµæœ
# çµæ§‹: {batch_id: {'total': int, 'success': int, 'failed': int, 'channel_id': int, 'gallery_ids': List[str]}}
batch_tracker: Dict[str, Dict[str, Any]] = {}
batch_lock = threading.Lock()

def generate_batch_id() -> str:
    """ç”Ÿæˆæ‰¹æ¬¡ ID"""
    return f"B{int(datetime.now().timestamp() * 1000)}"

def init_batch(batch_id: str, total: int, channel_id: int, gallery_ids: List[str]):
    """åˆå§‹åŒ–æ‰¹æ¬¡è¿½è¹¤"""
    with batch_lock:
        batch_tracker[batch_id] = {
            'total': total,
            'success': 0,
            'failed': 0,
            'channel_id': channel_id,
            'gallery_ids': gallery_ids,
            'completed_ids': [],
            'failed_ids': []
        }

def update_batch(batch_id: str, success: bool, gallery_id: str = None) -> Optional[Dict[str, Any]]:
    """
    æ›´æ–°æ‰¹æ¬¡ç‹€æ…‹ï¼Œå¦‚æœå®Œæˆå‰‡è¿”å›çµ±è¨ˆçµæœ
    
    Returns:
        å¦‚æœæ‰¹æ¬¡å®Œæˆï¼Œè¿”å›çµ±è¨ˆè³‡è¨Šï¼›å¦å‰‡è¿”å› None
    """
    with batch_lock:
        if batch_id not in batch_tracker:
            return None
        
        batch = batch_tracker[batch_id]
        if success:
            batch['success'] += 1
            if gallery_id:
                batch['completed_ids'].append(gallery_id)
        else:
            batch['failed'] += 1
            if gallery_id:
                batch['failed_ids'].append(gallery_id)
        
        # æª¢æŸ¥æ˜¯å¦å®Œæˆ
        if batch['success'] + batch['failed'] >= batch['total']:
            result = batch.copy()
            del batch_tracker[batch_id]
            return result
        
        return None

# é€²åº¦æ¢è¨­å®š
PROGRESS_UPDATE_INTERVAL = 3  # æ¯ 3 ç§’æ›´æ–°ä¸€æ¬¡é€²åº¦
SECONDS_PER_PAGE = 3.6  # é ä¼°æ¯é ä¸‹è¼‰æ™‚é–“ï¼ˆå¯¦æ¸¬å¹³å‡å€¼ï¼‰
PROGRESS_BAR_WIDTH = 15  # é€²åº¦æ¢å¯¬åº¦ï¼ˆæ ¼æ•¸ï¼‰

# PDF Web å­˜å–è¨­å®š
PDF_WEB_BASE_URL = "http://192.168.0.32:8888"  # Web Station åŸºç¤ URL


def create_progress_bar(current: int, total: int, width: int = PROGRESS_BAR_WIDTH) -> str:
    """
    å‰µå»º emoji é€²åº¦æ¢
    
    Args:
        current: ç›®å‰å®Œæˆæ•¸é‡
        total: ç¸½æ•¸é‡
        width: é€²åº¦æ¢å¯¬åº¦ï¼ˆæ ¼æ•¸ï¼‰
    
    Returns:
        é€²åº¦æ¢å­—ä¸²ï¼Œä¾‹å¦‚ï¼šğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œâ¬œâ¬œ 50%
    """
    if total <= 0:
        return "â¬œ" * width + " 0%"
    
    percentage = min(current / total, 1.0)
    filled = int(percentage * width)
    empty = width - filled
    
    bar = "ğŸŸ©" * filled + "â¬œ" * empty
    percent_text = f"{int(percentage * 100)}%"
    
    return f"{bar} {percent_text}"


# è¨Šæ¯å»é‡ï¼ˆé¿å…é‡è¤‡è™•ç†åŒä¸€è¨Šæ¯ï¼‰
processed_messages: set = set()

# å°ˆç”¨é »é“è¨­å®š - åœ¨é€™äº›é »é“ä¸­ä¸éœ€è¦ !dl å‰ç¶´
# å¯è¨­å®šé »é“åç¨±æˆ–é »é“ IDï¼ˆè¨­å®šåç¨±æ›´æ–¹ä¾¿ï¼‰
DEDICATED_CHANNEL_NAMES = ['hentaifetcher', 'hentai-fetcher', 'nhentai']  # é »é“åç¨±
DEDICATED_CHANNEL_IDS = []  # æˆ–ç›´æ¥è¨­å®šé »é“ ID
MAX_PROCESSED_MESSAGES = 1000  # æœ€å¤šä¿ç•™ 1000 ç­†è¨˜éŒ„

def is_message_processed(message_id: int) -> bool:
    """æª¢æŸ¥è¨Šæ¯æ˜¯å¦å·²è™•ç†é"""
    global processed_messages
    if message_id in processed_messages:
        return True
    
    # æ¸…ç†éèˆŠçš„è¨˜éŒ„
    if len(processed_messages) >= MAX_PROCESSED_MESSAGES:
        # æ¸…é™¤ä¸€åŠçš„è¨˜éŒ„
        processed_messages = set(list(processed_messages)[MAX_PROCESSED_MESSAGES // 2:])
    
    processed_messages.add(message_id)
    return False

# ==================== å·¥å…·å‡½å¼ ====================

def parse_input_to_urls(input_text: str) -> List[str]:
    """
    è§£æä½¿ç”¨è€…è¼¸å…¥ï¼Œæ”¯æ´å¤šç¨®æ ¼å¼ï¼š
    - å®Œæ•´ç¶²å€: https://nhentai.net/g/123456/
    - ç´”æ•¸å­—: 123456
    - å¤šå€‹è¼¸å…¥ï¼ˆç©ºç™½ã€é€—è™Ÿã€æ›è¡Œåˆ†éš”ï¼‰
    - æ··åˆè¼¸å…¥: 421633 https://nhentai.net/g/607769/ 613358
    
    Args:
        input_text: ä½¿ç”¨è€…è¼¸å…¥çš„æ–‡å­—
    
    Returns:
        è§£æå¾Œçš„å®Œæ•´ URL åˆ—è¡¨
    """
    urls = []
    
    # æ¨™æº–åŒ–æ›è¡Œç¬¦è™Ÿï¼ˆè™•ç† Windows/Mac/Linux ä¸åŒçš„æ›è¡Œï¼‰
    normalized_text = input_text.replace('\r\n', '\n').replace('\r', '\n')
    
    # Debug æ—¥èªŒ
    logger.debug(f"åŸå§‹è¼¸å…¥: {repr(input_text)}")
    logger.debug(f"æ¨™æº–åŒ–å¾Œ: {repr(normalized_text)}")
    
    # æŒ‰è¡Œåˆ†å‰²è™•ç†
    lines = normalized_text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # æ¯è¡Œå¯èƒ½æœ‰å¤šå€‹é …ç›®ï¼ˆç©ºç™½æˆ–é€—è™Ÿåˆ†éš”ï¼‰
        parts = re.split(r'[\s,;]+', line)
        
        for part in parts:
            part = part.strip()
            if not part:
                continue
            
            # å¦‚æœæ˜¯å®Œæ•´ URL
            if part.startswith(('http://', 'https://')):
                # æ¸…ç† URL çµå°¾å¯èƒ½çš„æ¨™é»ç¬¦è™Ÿ
                url = part.rstrip('.,;')
                urls.append(url)
            # å¦‚æœæ˜¯ç´”æ•¸å­—
            elif part.isdigit():
                urls.append(f"https://nhentai.net/g/{part}/")
            # å˜—è©¦æå–æ•¸å­—ï¼ˆä¾‹å¦‚: g/123456 æˆ– #123456ï¼‰
            else:
                match = re.search(r'(\d{4,7})', part)
                if match:
                    urls.append(f"https://nhentai.net/g/{match.group(1)}/")
    
    # å»é™¤é‡è¤‡ä¸¦ä¿æŒé †åº
    seen = set()
    unique_urls = []
    for url in urls:
        if url not in seen:
            seen.add(url)
            unique_urls.append(url)
    
    logger.info(f"è§£æåˆ° {len(unique_urls)} å€‹ URL")
    return unique_urls


def sanitize_filename(name: str, max_length: int = 200) -> str:
    """
    æ¸…ç†æª”æ¡ˆåç¨±ï¼Œç§»é™¤ä¸åˆæ³•å­—å…ƒ
    
    Args:
        name: åŸå§‹åç¨±
        max_length: æœ€å¤§é•·åº¦é™åˆ¶ï¼ˆé è¨­ 200ï¼Œä¿ç•™å®Œæ•´æ¨™é¡Œï¼‰
    
    Returns:
        æ¸…ç†å¾Œçš„å®‰å…¨æª”æ¡ˆåç¨±
    """
    # ç§»é™¤æˆ–æ›¿æ›ä¸åˆæ³•çš„æª”æ¡ˆåç¨±å­—å…ƒ
    invalid_chars = r'[<>:"/\\|?*\x00-\x1f]'
    sanitized = re.sub(invalid_chars, '_', name)
    
    # ç§»é™¤å‰å¾Œç©ºç™½å’Œé»
    sanitized = sanitized.strip(' .')
    
    # åªåœ¨è¶…éç³»çµ±é™åˆ¶æ™‚æ‰æˆªæ–·ï¼ˆLinux æª”åä¸Šé™ 255ï¼‰
    if max_length and len(sanitized) > max_length:
        sanitized = sanitized[:max_length].strip(' .')
    
    # å¦‚æœçµæœç‚ºç©ºï¼Œä½¿ç”¨é è¨­åç¨±
    if not sanitized:
        sanitized = f"download_{int(time.time())}"
    
    return sanitized


def generate_eagle_id() -> str:
    """
    ç”Ÿæˆ Eagle ç›¸å®¹çš„å”¯ä¸€ ID (åŸºæ–¼æ™‚é–“æˆ³)
    
    Returns:
        å”¯ä¸€è­˜åˆ¥ç¢¼å­—ä¸²
    """
    return f"L{int(datetime.now().timestamp() * 1000)}"


# å¿«é€Ÿ reindex æ¨™è¨˜ - ç”¨æ–¼é¿å…é »ç¹é‡è¤‡ç´¢å¼•
_last_reindex_time: float = 0
REINDEX_COOLDOWN = 60  # 60 ç§’å…§ä¸é‡è¤‡ reindex

def quick_reindex() -> int:
    """
    å¿«é€Ÿé‡å»ºç´¢å¼• (æœ‰å†·å»æ™‚é–“é™åˆ¶)
    
    Returns:
        æ–°å¢é …ç›®æ•¸ï¼Œå¦‚æœè·³éå‰‡è¿”å› -1
    """
    global _last_reindex_time
    
    current_time = time.time()
    if current_time - _last_reindex_time < REINDEX_COOLDOWN:
        logger.debug(f"è·³é reindex (å†·å»ä¸­)")
        return -1
    
    try:
        from eagle_library import EagleLibrary
        eagle = EagleLibrary()
        added = eagle.rebuild_index()
        _last_reindex_time = time.time()
        logger.info(f"å¿«é€Ÿ reindex å®Œæˆï¼Œæ–°å¢ {added} é …")
        return added
    except Exception as e:
        logger.warning(f"å¿«é€Ÿ reindex å¤±æ•—: {e}")
        return 0


def check_already_downloaded(gallery_id: str, do_reindex: bool = False) -> tuple[bool, Optional[dict]]:
    """
    æª¢æŸ¥ gallery æ˜¯å¦å·²ç¶“ä¸‹è¼‰é (å­˜åœ¨æ–¼ Eagle Library)
    
    Args:
        gallery_id: nhentai Gallery ID
        do_reindex: æ˜¯å¦å…ˆåŸ·è¡Œå¿«é€Ÿ reindex
    
    Returns:
        (å·²å­˜åœ¨, çµæœè³‡è¨Š) - å¦‚æœå·²å­˜åœ¨ï¼ŒçµæœåŒ…å« web_url, title ç­‰
    """
    try:
        # å¯é¸ï¼šå…ˆåŸ·è¡Œå¿«é€Ÿ reindex
        if do_reindex:
            quick_reindex()
        
        from eagle_library import EagleLibrary
        eagle = EagleLibrary()
        result = eagle.find_by_nhentai_id(gallery_id)
        if result:
            return True, result
        return False, None
    except Exception as e:
        logger.warning(f"æª¢æŸ¥é‡è¤‡ä¸‹è¼‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False, None


def verify_nhentai_url(gallery_id: str) -> tuple[bool, str]:
    """
    é©—è­‰ nhentai gallery æ˜¯å¦å­˜åœ¨ä¸”å¯è¨ªå•
    
    Args:
        gallery_id: Gallery ID
    
    Returns:
        (æ˜¯å¦æœ‰æ•ˆ, æ¨™é¡Œæˆ–éŒ¯èª¤è¨Šæ¯)
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            title = data.get('title', {}).get('english', '') or data.get('title', {}).get('japanese', '')
            return True, title[:50] + '...' if len(title) > 50 else title
        elif response.status_code == 404:
            return False, "Gallery ä¸å­˜åœ¨"
        else:
            return False, f"HTTP {response.status_code}"
    except requests.Timeout:
        return False, "é€£ç·šé€¾æ™‚"
    except Exception as e:
        return False, str(e)


def get_nhentai_page_count(gallery_id: str) -> tuple[int, str, str]:
    """
    å¾ nhentai API ç²å–é æ•¸ã€æ¨™é¡Œå’Œ media_id
    
    Args:
        gallery_id: Gallery ID
    
    Returns:
        (é æ•¸, æ¨™é¡Œ, media_id) - å¤±æ•—æ™‚é æ•¸ç‚º 0
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            pages = data.get('num_pages', 0)
            title = data.get('title', {}).get('japanese', '') or data.get('title', {}).get('english', '')
            media_id = str(data.get('media_id', ''))
            return pages, title[:40] + '...' if len(title) > 40 else title, media_id
    except:
        pass
    
    return 0, "", ""


def fetch_nhentai_extra_info(gallery_id: str) -> Dict[str, Any]:
    """
    å¾ nhentai API ç²å–é¡å¤–è³‡è¨Šï¼ˆæ”¶è—æ•¸ã€è©•è«–ç­‰ï¼‰
    
    Args:
        gallery_id: Gallery ID
    
    Returns:
        åŒ…å« favorites å’Œ comments çš„å­—å…¸
    """
    result = {
        'favorites': 0,
        'comments': []
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    # ç²å–æ”¶è—æ•¸
    try:
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=30)
        if response.status_code == 200:
            data = response.json()
            result['favorites'] = data.get('num_favorites', 0)
            logger.info(f"ç²å–æ”¶è—æ•¸: {result['favorites']}")
    except Exception as e:
        logger.warning(f"ç²å–æ”¶è—æ•¸å¤±æ•—: {e}")
    
    # ç²å–è©•è«–
    try:
        comments_url = f"https://nhentai.net/api/gallery/{gallery_id}/comments"
        response = requests.get(comments_url, headers=headers, timeout=30)
        if response.status_code == 200:
            result['comments'] = response.json()
            logger.info(f"ç²å–è©•è«–æ•¸: {len(result['comments'])}")
    except Exception as e:
        logger.warning(f"ç²å–è©•è«–å¤±æ•—: {e}")
    
    return result


def download_nhentai_cover(gallery_id: str, save_path: Path) -> bool:
    """
    å¾ nhentai ä¸‹è¼‰å°é¢åœ–ç‰‡
    
    Args:
        gallery_id: Gallery ID
        save_path: ä¿å­˜è·¯å¾‘ï¼ˆè³‡æ–™å¤¾ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        # ç²å– gallery è³‡è¨Š
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=30)
        if response.status_code != 200:
            logger.warning(f"ç„¡æ³•ç²å– gallery è³‡è¨Š: {gallery_id}")
            return False
        
        data = response.json()
        media_id = data.get('media_id', '')
        if not media_id:
            logger.warning(f"æ‰¾ä¸åˆ° media_id: {gallery_id}")
            return False
        
        # ç²å–å°é¢æ ¼å¼
        images = data.get('images', {})
        cover = images.get('cover', {})
        cover_type = cover.get('t', 'j')  # j=jpg, p=png, g=gif
        
        ext_map = {'j': 'jpg', 'p': 'png', 'g': 'gif'}
        ext = ext_map.get(cover_type, 'jpg')
        
        # å˜—è©¦å¤šå€‹ URL æ ¼å¼ä¸‹è¼‰å°é¢
        cover_urls = [
            f"https://t.nhentai.net/galleries/{media_id}/cover.{ext}",
            f"https://t3.nhentai.net/galleries/{media_id}/cover.{ext}",
            f"https://i.nhentai.net/galleries/{media_id}/cover.{ext}",
            f"https://i5.nhentai.net/galleries/{media_id}/cover.{ext}",
        ]
        
        for cover_url in cover_urls:
            try:
                logger.info(f"å˜—è©¦ä¸‹è¼‰å°é¢: {cover_url}")
                response = requests.get(cover_url, headers=headers, timeout=30)
                if response.status_code == 200:
                    cover_path = save_path / f"cover.{ext}"
                    with open(cover_path, 'wb') as f:
                        f.write(response.content)
                    logger.info(f"å°é¢å·²ä¿å­˜: {cover_path}")
                    return True
            except Exception as e:
                logger.debug(f"å˜—è©¦ {cover_url} å¤±æ•—: {e}")
                continue
        
        logger.warning(f"æ‰€æœ‰å°é¢ URL éƒ½å¤±æ•—")
        return False
            
    except Exception as e:
        logger.error(f"ä¸‹è¼‰å°é¢éŒ¯èª¤: {e}")
        return False


def download_nhentai_first_page(gallery_id: str, save_path: Path) -> bool:
    """
    å¾ nhentai ä¸‹è¼‰ç¬¬ä¸€é åœ–ç‰‡ä½œç‚ºå°é¢ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
    
    Args:
        gallery_id: Gallery ID
        save_path: ä¿å­˜è·¯å¾‘ï¼ˆè³‡æ–™å¤¾ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        # ç²å– gallery è³‡è¨Š
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=30)
        if response.status_code != 200:
            logger.warning(f"ç„¡æ³•ç²å– gallery è³‡è¨Š: {gallery_id}")
            return False
        
        data = response.json()
        media_id = data.get('media_id', '')
        if not media_id:
            logger.warning(f"æ‰¾ä¸åˆ° media_id: {gallery_id}")
            return False
        
        # ç²å–ç¬¬ä¸€é æ ¼å¼
        images = data.get('images', {})
        pages = images.get('pages', [])
        if not pages:
            logger.warning(f"æ‰¾ä¸åˆ°é é¢è³‡è¨Š: {gallery_id}")
            return False
        
        first_page = pages[0]
        page_type = first_page.get('t', 'j')  # j=jpg, p=png, g=gif, w=webp
        
        ext_map = {'j': 'jpg', 'p': 'png', 'g': 'gif', 'w': 'webp'}
        ext = ext_map.get(page_type, 'jpg')
        
        # å˜—è©¦å¤šå€‹ URL æ ¼å¼ä¸‹è¼‰ç¬¬ä¸€é 
        first_page_urls = [
            f"https://i.nhentai.net/galleries/{media_id}/1.{ext}",
            f"https://i2.nhentai.net/galleries/{media_id}/1.{ext}",
            f"https://i5.nhentai.net/galleries/{media_id}/1.{ext}",
            f"https://i7.nhentai.net/galleries/{media_id}/1.{ext}",
        ]
        
        for page_url in first_page_urls:
            try:
                logger.info(f"å˜—è©¦ä¸‹è¼‰ç¬¬ä¸€é ä½œç‚ºå°é¢: {page_url}")
                response = requests.get(page_url, headers=headers, timeout=30)
                if response.status_code == 200:
                    cover_path = save_path / f"cover.{ext}"
                    with open(cover_path, 'wb') as f:
                        f.write(response.content)
                    logger.info(f"ç¬¬ä¸€é å·²ä¿å­˜ç‚ºå°é¢: {cover_path}")
                    return True
            except Exception as e:
                logger.debug(f"å˜—è©¦ {page_url} å¤±æ•—: {e}")
                continue
        
        logger.warning(f"æ‰€æœ‰ç¬¬ä¸€é  URL éƒ½å¤±æ•—")
        return False
            
    except Exception as e:
        logger.error(f"ä¸‹è¼‰ç¬¬ä¸€é éŒ¯èª¤: {e}")
        return False


def natural_sort_key(s: str):
    """
    è‡ªç„¶æ’åºéµå‡½æ•¸ - è®“æ•¸å­—æŒ‰æ•¸å€¼å¤§å°æ’åº
    ä¾‹å¦‚: 1.jpg, 2.jpg, 10.jpg è€Œä¸æ˜¯ 1.jpg, 10.jpg, 2.jpg
    """
    import re
    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\d+)', s)]


def get_first_image_as_cover(folder_path: Path) -> bool:
    """
    ä½¿ç”¨è³‡æ–™å¤¾å…§çš„ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢
    
    Args:
        folder_path: è³‡æ–™å¤¾è·¯å¾‘
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp'}
        
        # æ‰¾åˆ°æ‰€æœ‰åœ–ç‰‡ï¼ˆæ’é™¤å·²æœ‰çš„ cover é–‹é ­æª”æ¡ˆï¼‰
        images = []
        for file in folder_path.iterdir():
            if file.is_file() and file.suffix.lower() in image_extensions:
                # æ’é™¤å°é¢æª”æ¡ˆ
                if not file.stem.lower().startswith('cover'):
                    images.append(file)
        
        if not images:
            logger.warning(f"è³‡æ–™å¤¾å…§æ²’æœ‰å¯ç”¨çš„åœ–ç‰‡: {folder_path}")
            return False
        
        # æŒ‰æª”åè‡ªç„¶æ’åºï¼Œå–ç¬¬ä¸€å¼µ
        images.sort(key=lambda x: natural_sort_key(x.name))
        first_image = images[0]
        
        # è¤‡è£½ç‚ºå°é¢
        cover_ext = first_image.suffix.lower()
        cover_path = folder_path / f"cover{cover_ext}"
        
        import shutil
        shutil.copy2(first_image, cover_path)
        logger.info(f"å·²ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢: {first_image.name} -> cover{cover_ext}")
        return True
        
    except Exception as e:
        logger.error(f"ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢å¤±æ•—: {e}")
        return False


def format_comment_time(timestamp: int) -> str:
    """æ ¼å¼åŒ–è©•è«–æ™‚é–“ç‚ºç›¸å°æ™‚é–“"""
    dt = datetime.fromtimestamp(timestamp)
    now = datetime.now()
    diff = now - dt
    
    if diff.days > 30:
        months = diff.days // 30
        weeks = (diff.days % 30) // 7
        if weeks > 0:
            return f"{months} å€‹æœˆ, {weeks} é€±å‰"
        return f"{months} å€‹æœˆå‰"
    elif diff.days > 7:
        weeks = diff.days // 7
        return f"{weeks} é€±å‰"
    elif diff.days > 0:
        return f"{diff.days} å¤©å‰"
    elif diff.seconds > 3600:
        return f"{diff.seconds // 3600} å°æ™‚å‰"
    else:
        return f"{diff.seconds // 60} åˆ†é˜å‰"


def format_comments_for_annotation(comments: list, max_comments: int = 5) -> str:
    """
    æ ¼å¼åŒ–è©•è«–ç”¨æ–¼ annotation
    
    Args:
        comments: è©•è«–åˆ—è¡¨
        max_comments: æœ€å¤§é¡¯ç¤ºè©•è«–æ•¸
    
    Returns:
        æ ¼å¼åŒ–çš„è©•è«–å­—ä¸²
    """
    if not comments:
        return ""
    
    lines = ["\nğŸ’¬ ç”¨æˆ¶è©•è«–:"]
    
    for i, comment in enumerate(comments[:max_comments]):
        username = comment.get('poster', {}).get('username', 'åŒ¿å')
        body = comment.get('body', '')
        post_date = comment.get('post_date', 0)
        time_str = format_comment_time(post_date) if post_date else ''
        
        lines.append(f"  [{username}] ({time_str})")
        lines.append(f"  {body}")
        if i < len(comments[:max_comments]) - 1:
            lines.append("")
    
    if len(comments) > max_comments:
        lines.append(f"  ... é‚„æœ‰ {len(comments) - max_comments} å‰‡è©•è«–")
    
    return "\n".join(lines)


def parse_gallery_dl_info(info_path: Path) -> Optional[Dict[str, Any]]:
    """
    è§£æ gallery-dl ç”Ÿæˆçš„ info.json æˆ– gallery_metadata.json
    
    gallery-dl --dump-json è¼¸å‡ºæ ¼å¼:
    {
        "title": "...",
        "title_en": "...",
        "title_ja": "...",
        "gallery_id": 123456,
        "count": 34,
        "type": "doujinshi",
        "artist": ["name"],
        "group": ["name"],
        "parody": ["name"],
        "characters": [],
        "language": "Chinese",
        "tags": ["tag1", "tag2", ...]
    }
    
    Args:
        info_path: info.json æª”æ¡ˆè·¯å¾‘
    
    Returns:
        è§£æå¾Œçš„ metadata å­—å…¸ï¼Œå¤±æ•—å‰‡è¿”å› None
    """
    try:
        with open(info_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # åˆå§‹åŒ–çµæœçµæ§‹ï¼ˆæ“´å±•ç‰ˆï¼‰
        result = {
            'title': '',
            'title_japanese': '',  # æ—¥æ–‡å‰¯æ¨™é¡Œ
            'title_pretty': '',    # ç°¡çŸ­æ¨™é¡Œ
            'tags': [],
            'url': '',
            'gallery_id': '',
            'pages': 0,
            'favorites': 0,
            'category': '',
            'type': '',
            'artist': [],
            'group': [],
            'parody': [],
            'character': [],
            'language': '',
        }
        
        # è™•ç† gallery-dl è¼¸å‡ºæ ¼å¼
        if isinstance(data, dict):
            # ===== æ¨™é¡Œè™•ç† =====
            # gallery-dl æ ¼å¼: title, title_en, title_ja éƒ½æ˜¯å­—ä¸²
            if 'title' in data:
                if isinstance(data['title'], dict):
                    # èˆŠç‰ˆ nhentai API æ ¼å¼: {"english": "...", "japanese": "...", "pretty": "..."}
                    result['title'] = (
                        data['title'].get('english') or 
                        data['title'].get('pretty') or 
                        data['title'].get('japanese') or 
                        ''
                    )
                    result['title_japanese'] = data['title'].get('japanese', '')
                    result['title_pretty'] = data['title'].get('pretty', '')
                else:
                    result['title'] = str(data['title'])
            
            # gallery-dl ä½¿ç”¨ title_en å’Œ title_ja
            if 'title_en' in data:
                if not result['title']:
                    result['title'] = data['title_en']
            
            if 'title_ja' in data:
                result['title_japanese'] = data['title_ja']
            
            # ===== Gallery ID =====
            if 'gallery_id' in data:
                result['gallery_id'] = str(data['gallery_id'])
            elif 'id' in data:
                result['gallery_id'] = str(data['id'])
            
            # ===== é æ•¸ =====
            # gallery-dl ä½¿ç”¨ countï¼Œnhentai API ä½¿ç”¨ num_pages
            if 'count' in data:
                result['pages'] = int(data['count'])
            elif 'num_pages' in data:
                result['pages'] = int(data['num_pages'])
            
            # ===== æ”¶è—æ•¸ =====
            if 'num_favorites' in data:
                result['favorites'] = int(data['num_favorites'])
            
            # ===== é¡å‹ (doujinshi, manga, etc.) =====
            if 'type' in data:
                result['type'] = data['type']
                result['category'] = data['type']  # å…¼å®¹èˆŠæ ¼å¼
            
            # ===== ä½œè€…åˆ—è¡¨ =====
            if 'artist' in data:
                if isinstance(data['artist'], list):
                    result['artist'] = data['artist']
                    for artist in data['artist']:
                        result['tags'].append(f"artist:{artist}")
                elif isinstance(data['artist'], str):
                    result['artist'] = [data['artist']]
                    result['tags'].append(f"artist:{data['artist']}")
            
            # ===== ç¤¾åœ˜åˆ—è¡¨ =====
            if 'group' in data:
                if isinstance(data['group'], list):
                    result['group'] = data['group']
                    for group in data['group']:
                        result['tags'].append(f"group:{group}")
                elif isinstance(data['group'], str):
                    result['group'] = [data['group']]
                    result['tags'].append(f"group:{data['group']}")
            
            # ===== åŸä½œåˆ—è¡¨ =====
            if 'parody' in data:
                if isinstance(data['parody'], list):
                    result['parody'] = data['parody']
                    for parody in data['parody']:
                        result['tags'].append(f"parody:{parody}")
                elif isinstance(data['parody'], str):
                    result['parody'] = [data['parody']]
                    result['tags'].append(f"parody:{data['parody']}")
            
            # ===== è§’è‰²åˆ—è¡¨ =====
            # gallery-dl ä½¿ç”¨ characters (è¤‡æ•¸)
            if 'characters' in data:
                if isinstance(data['characters'], list):
                    result['character'] = data['characters']
                    for char in data['characters']:
                        result['tags'].append(f"character:{char}")
            elif 'character' in data:
                if isinstance(data['character'], list):
                    result['character'] = data['character']
                    for char in data['character']:
                        result['tags'].append(f"character:{char}")
            
            # ===== èªè¨€ =====
            if 'language' in data:
                result['language'] = data['language']
                result['tags'].append(f"language:{data['language']}")
            
            # ===== æ¨™ç±¤è™•ç† =====
            if 'tags' in data:
                tags = data['tags']
                if isinstance(tags, list):
                    for tag in tags:
                        if isinstance(tag, dict):
                            # èˆŠç‰ˆ nhentai API æ ¼å¼: {type, name}
                            tag_name = tag.get('name', '')
                            tag_type = tag.get('type', '')
                            if tag_name:
                                if tag_type == 'category':
                                    result['category'] = tag_name
                                    result['tags'].append(f"category:{tag_name}")
                                elif tag_type == 'artist':
                                    if tag_name not in result['artist']:
                                        result['artist'].append(tag_name)
                                        result['tags'].append(f"artist:{tag_name}")
                                elif tag_type == 'group':
                                    if tag_name not in result['group']:
                                        result['group'].append(tag_name)
                                        result['tags'].append(f"group:{tag_name}")
                                elif tag_type == 'parody':
                                    if tag_name not in result['parody']:
                                        result['parody'].append(tag_name)
                                        result['tags'].append(f"parody:{tag_name}")
                                elif tag_type == 'character':
                                    if tag_name not in result['character']:
                                        result['character'].append(tag_name)
                                        result['tags'].append(f"character:{tag_name}")
                                elif tag_type == 'language':
                                    result['language'] = tag_name
                                    result['tags'].append(f"language:{tag_name}")
                                elif tag_type in ['tag', '']:
                                    result['tags'].append(tag_name)
                                else:
                                    result['tags'].append(f"{tag_type}:{tag_name}")
                        elif isinstance(tag, str):
                            # gallery-dl æ ¼å¼: ç›´æ¥å­—ä¸²é™£åˆ—
                            result['tags'].append(tag)
                elif isinstance(tags, str):
                    result['tags'] = [t.strip() for t in tags.split(',') if t.strip()]
            
            # ===== é¡å‹æ¨™ç±¤ =====
            if result['type']:
                result['tags'].append(f"type:{result['type']}")
            
            # ===== URL è™•ç† =====
            if 'gallery_url' in data:
                result['url'] = data['gallery_url']
            elif 'url' in data:
                result['url'] = data['url']
            
            # å˜—è©¦å¾ gallery_id æ§‹å»º URL
            if not result['url'] and result['gallery_id']:
                result['url'] = f"https://nhentai.net/g/{result['gallery_id']}/"
        
        # å»é™¤é‡è¤‡æ¨™ç±¤
        result['tags'] = list(dict.fromkeys(result['tags']))
        
        logger.info(f"è§£æåˆ°æ¨™é¡Œ: {result['title']}")
        logger.info(f"  æ—¥æ–‡æ¨™é¡Œ: {result['title_japanese']}")
        logger.info(f"  Gallery ID: {result['gallery_id']}, é æ•¸: {result['pages']}")
        logger.info(f"  ä½œè€…: {result['artist']}, ç¤¾åœ˜: {result['group']}")
        logger.info(f"  é¡å‹: {result['type']}, èªè¨€: {result['language']}")
        logger.info(f"  æ¨™ç±¤æ•¸: {len(result['tags'])}")
        return result
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON è§£æéŒ¯èª¤: {e}")
        return None
    except Exception as e:
        logger.error(f"è§£æ info.json æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def create_eagle_metadata(
    title: str,
    url: str,
    tags: List[str],
    annotation: str = "",
    extra_info: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    å»ºç«‹ Eagle ç›¸å®¹çš„ metadata.json å…§å®¹
    
    Eagle æ¨™æº–æ¬„ä½ï¼š
    - id: å”¯ä¸€è­˜åˆ¥ç¢¼
    - name: åç¨±
    - tags: æ¨™ç±¤åˆ—è¡¨ (Array)
    - url / website: ä¾†æºç¶²å€
    - annotation: è¨»é‡‹/å‚™è¨» (å†—é•·è³‡è¨Šæ”¾é€™è£¡)
    
    Args:
        title: æ¼«ç•«æ¨™é¡Œ
        url: ä¾†æºç¶²å€
        tags: æ¨™ç±¤åˆ—è¡¨
        annotation: åŸºæœ¬å‚™è¨»
        extra_info: é¡å¤–è³‡è¨Šï¼ˆå‰¯æ¨™é¡Œã€é æ•¸ã€æ”¶è—æ•¸ç­‰ï¼‰
    
    Returns:
        Eagle metadata å­—å…¸
    """
    # å»ºç«‹å®Œæ•´çš„ tags åˆ—è¡¨
    all_tags = list(tags)  # è¤‡è£½åŸæœ‰æ¨™ç±¤
    
    # å»ºç«‹ annotation å…§å®¹
    annotation_lines = []
    
    if extra_info:
        # ===== åŠ å…¥é¡å¤–æ¨™ç±¤ =====
        # é¡å‹æ¨™ç±¤
        if extra_info.get('type'):
            type_tag = f"type:{extra_info['type']}"
            if type_tag not in all_tags:
                all_tags.append(type_tag)
        
        # èªè¨€æ¨™ç±¤
        if extra_info.get('language'):
            lang_tag = f"language:{extra_info['language']}"
            if lang_tag not in all_tags:
                all_tags.append(lang_tag)
        
        # ä½œè€…æ¨™ç±¤
        if extra_info.get('artist'):
            for artist in extra_info['artist']:
                artist_tag = f"artist:{artist}"
                if artist_tag not in all_tags:
                    all_tags.append(artist_tag)
        
        # ç¤¾åœ˜æ¨™ç±¤
        if extra_info.get('group'):
            for group in extra_info['group']:
                group_tag = f"group:{group}"
                if group_tag not in all_tags:
                    all_tags.append(group_tag)
        
        # åŸä½œæ¨™ç±¤
        if extra_info.get('parody'):
            for parody in extra_info['parody']:
                parody_tag = f"parody:{parody}"
                if parody_tag not in all_tags:
                    all_tags.append(parody_tag)
        
        # è§’è‰²æ¨™ç±¤
        if extra_info.get('character'):
            for char in extra_info['character']:
                char_tag = f"character:{char}"
                if char_tag not in all_tags:
                    all_tags.append(char_tag)
        
        # ===== å»ºç«‹ annotation å…§å®¹ =====
        # è‹±æ–‡æ¨™é¡Œï¼ˆå¦‚æœä¸»æ¨™é¡Œæ˜¯æ—¥æ–‡ï¼Œé¡¯ç¤ºè‹±æ–‡æ¨™é¡Œä½œç‚ºåƒè€ƒï¼‰
        if extra_info.get('title_english'):
            annotation_lines.append(f"ğŸ“– è‹±æ–‡æ¨™é¡Œ: {extra_info['title_english']}")
        
        # é æ•¸
        if extra_info.get('pages'):
            annotation_lines.append(f"ğŸ“„ é æ•¸: {extra_info['pages']}")
        
        # æ”¶è—æ•¸
        if extra_info.get('favorites') and extra_info['favorites'] > 0:
            annotation_lines.append(f"â¤ï¸ æ”¶è—æ•¸: {extra_info['favorites']}")
        
        # é¡å‹
        if extra_info.get('type'):
            annotation_lines.append(f"ğŸ“ é¡å‹: {extra_info['type']}")
        
        # èªè¨€
        if extra_info.get('language'):
            annotation_lines.append(f"ğŸŒ èªè¨€: {extra_info['language']}")
        
        # ä½œè€…
        if extra_info.get('artist'):
            annotation_lines.append(f"ğŸ¨ ä½œè€…: {', '.join(extra_info['artist'])}")
        
        # ç¤¾åœ˜
        if extra_info.get('group'):
            annotation_lines.append(f"ğŸ‘¥ ç¤¾åœ˜: {', '.join(extra_info['group'])}")
        
        # åŸä½œ
        if extra_info.get('parody'):
            annotation_lines.append(f"ğŸ¬ åŸä½œ: {', '.join(extra_info['parody'])}")
        
        # è§’è‰²
        if extra_info.get('character') and len(extra_info['character']) > 0:
            annotation_lines.append(f"ğŸ‘¤ è§’è‰²: {', '.join(extra_info['character'])}")
        
        # ID (æ”¾åœ¨è¼ƒä¸‹é¢)
        if extra_info.get('gallery_id'):
            annotation_lines.append(f"ğŸ“” ID: {extra_info['gallery_id']}")
        
        # ç”¨æˆ¶è©•è«–
        if extra_info.get('comments'):
            comments_text = format_comments_for_annotation(extra_info['comments'])
            if comments_text:
                annotation_lines.append(comments_text)
    
    # åŠ å…¥ä¸‹è¼‰æ™‚é–“
    annotation_lines.append(f"\nâ° ä¸‹è¼‰æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    annotation_lines.append("ğŸ“¥ Downloaded via HentaiFetcher Bot")
    
    # å¦‚æœæœ‰é¡å¤–çš„åŸºæœ¬å‚™è¨»ï¼ŒåŠ åœ¨æœ€å¾Œ
    if annotation and annotation != "Downloaded via HentaiFetcher Bot":
        annotation_lines.append(f"\n{annotation}")
    
    # å»é™¤é‡è¤‡æ¨™ç±¤
    all_tags = list(dict.fromkeys(all_tags))
    
    # å»ºç«‹æœ€çµ‚ metadata
    metadata = {
        "id": generate_eagle_id(),
        "name": title,
        "url": url,
        "tags": all_tags,
        "annotation": "\n".join(annotation_lines)
    }
    
    return metadata


def find_info_json(directory: Path) -> Optional[Path]:
    """
    éè¿´æœå°‹ info.json æª”æ¡ˆ
    
    Args:
        directory: æœå°‹èµ·å§‹ç›®éŒ„
    
    Returns:
        æ‰¾åˆ°çš„ info.json è·¯å¾‘ï¼Œæœªæ‰¾åˆ°å‰‡è¿”å› None
    """
    # å„ªå…ˆæœå°‹æˆ‘å€‘è‡ªå·±ç”Ÿæˆçš„ metadata æª”æ¡ˆ
    our_metadata = directory / "gallery_metadata.json"
    if our_metadata.exists():
        return our_metadata
    
    # ç›´æ¥åœ¨ç›®éŒ„ä¸‹æœå°‹
    for json_file in directory.rglob('*.json'):
        if json_file.name == 'info.json' or 'info' in json_file.name.lower():
            return json_file
    
    # ä¹Ÿå˜—è©¦æœå°‹å…¶ä»–å¯èƒ½çš„ metadata æª”æ¡ˆ
    for json_file in directory.rglob('*.json'):
        return json_file  # è¿”å›ç¬¬ä¸€å€‹æ‰¾åˆ°çš„ JSON
    
    return None


def find_images(directory: Path) -> List[Path]:
    """
    æœå°‹ç›®éŒ„ä¸‹çš„æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ
    
    Args:
        directory: æœå°‹ç›®éŒ„
    
    Returns:
        åœ–ç‰‡æª”æ¡ˆè·¯å¾‘åˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
    """
    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp'}
    images = []
    
    for file in directory.rglob('*'):
        # æ’é™¤ .part æª”æ¡ˆï¼ˆæœªå®Œæˆçš„ä¸‹è¼‰ï¼‰
        if file.suffix.lower() in image_extensions and not file.name.endswith('.part'):
            images.append(file)
    
    # æŒ‰æª”åè‡ªç„¶æ’åº
    def natural_sort_key(path: Path):
        # æå–æ•¸å­—é€²è¡Œè‡ªç„¶æ’åº
        numbers = re.findall(r'\d+', path.stem)
        return [int(n) for n in numbers] if numbers else [path.stem]
    
    images.sort(key=natural_sort_key)
    return images


# ==================== ä¸‹è¼‰è™•ç†é¡åˆ¥ ====================

class DownloadProcessor:
    """
    ä¸‹è¼‰è™•ç†å™¨ï¼šè² è²¬åŸ·è¡Œ gallery-dlã€è½‰æ› PDF ä¸¦ç”Ÿæˆ metadata
    """
    
    def __init__(self, url: str, total_pages: int = 0, message_callback=None, cancel_event: threading.Event = None):
        """
        åˆå§‹åŒ–ä¸‹è¼‰è™•ç†å™¨
        
        Args:
            url: è¦ä¸‹è¼‰çš„ç¶²å€
            total_pages: é æœŸç¸½é æ•¸ï¼ˆç”¨æ–¼é€²åº¦è¨ˆç®—ï¼‰
            message_callback: ç‹€æ…‹æ›´æ–°å›èª¿å‡½å¼
            cancel_event: å–æ¶ˆäº‹ä»¶ï¼ˆè¢« set æ™‚æ‡‰ä¸­æ­¢ä¸‹è¼‰ï¼‰
        """
        self.url = url
        self.total_pages = total_pages
        self.message_callback = message_callback
        self.cancel_event = cancel_event
        self.temp_path: Optional[Path] = None
        self.output_path: Optional[Path] = None
        self.last_error: str = ""
        self.download_complete = False  # ä¸‹è¼‰æ˜¯å¦å®Œæˆ
        self.pdf_progress = 0  # PDF è½‰æ›é€²åº¦ (0-100)
        self.pdf_converting = False  # æ˜¯å¦æ­£åœ¨è½‰æ› PDF
    
    def is_cancelled(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ"""
        return self.cancel_event and self.cancel_event.is_set()
        
    def get_downloaded_count(self) -> int:
        """ç²å–å·²ä¸‹è¼‰çš„åœ–ç‰‡æ•¸é‡"""
        if not self.temp_path or not self.temp_path.exists():
            return 0
        return len(find_images(self.temp_path))
    
    def get_first_image_path(self) -> Path:
        """ç²å–ç¬¬ä¸€å¼µå·²ä¸‹è¼‰åœ–ç‰‡çš„è·¯å¾‘"""
        if not self.temp_path or not self.temp_path.exists():
            return None
        images = find_images(self.temp_path)
        if images:
            # æŒ‰æª”åæ’åºå–ç¬¬ä¸€å¼µ
            images.sort(key=lambda x: x.name)
            return images[0]
        return None
        
    async def send_status(self, message: str):
        """ç™¼é€ç‹€æ…‹è¨Šæ¯"""
        logger.info(message)
        if self.message_callback:
            try:
                await self.message_callback(message)
            except Exception as e:
                logger.warning(f"ç„¡æ³•ç™¼é€ç‹€æ…‹è¨Šæ¯: {e}")
    
    def download_with_gallery_dl(self) -> bool:
        """
        ä½¿ç”¨ gallery-dl ä¸‹è¼‰åœ–ç‰‡å’Œ metadata
        
        Returns:
            æˆåŠŸè¿”å› Trueï¼Œå¤±æ•—è¿”å› False
        """
        try:
            # å»ºç«‹å”¯ä¸€çš„æš«å­˜ç›®éŒ„ï¼ˆçµ±ä¸€ä½¿ç”¨ TEMP_DIRï¼‰
            self.temp_path = TEMP_DIR / f"dl_{int(time.time() * 1000)}"
            self.temp_path.mkdir(parents=True, exist_ok=True)
            
            print(f"[GALLERY-DL] ä¸‹è¼‰ç›®éŒ„: {self.temp_path}", flush=True)
            
            # æ ¹æ“šç’°å¢ƒé¸æ“‡ gallery-dl åŸ·è¡Œæ–¹å¼èˆ‡åƒæ•¸
            if IS_DOCKER:
                # Docker ç’°å¢ƒï¼šå…©éšæ®µä¸‹è¼‰
                # éšæ®µ 1: ä½¿ç”¨ gallery-dl --dump-json ç²å– metadata
                print(f"[GALLERY-DL] éšæ®µ1: ç²å– metadata...", flush=True)
                metadata_cmd = [
                    'gallery-dl',
                    '--dump-json',
                    '--user-agent', 'Mozilla/5.0',
                    self.url
                ]
                
                metadata_result = subprocess.run(
                    metadata_cmd,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                # è§£æä¸¦å„²å­˜ metadata
                if metadata_result.returncode == 0 and metadata_result.stdout.strip():
                    try:
                        # gallery-dl --dump-json è¼¸å‡ºçš„æ˜¯ JSON é™£åˆ—
                        metadata_list = json.loads(metadata_result.stdout)
                        if metadata_list and len(metadata_list) > 0:
                            # å–ç¬¬ä¸€å€‹å…ƒç´ çš„ metadataï¼ˆé€šå¸¸åŒ…å« gallery infoï¼‰
                            first_item = metadata_list[0]
                            if isinstance(first_item, list) and len(first_item) >= 2:
                                gallery_metadata = first_item[1]  # [url, metadata] æ ¼å¼
                            else:
                                gallery_metadata = first_item
                            
                            # å„²å­˜ metadata åˆ°æš«å­˜ç›®éŒ„
                            metadata_file = self.temp_path / "gallery_metadata.json"
                            with open(metadata_file, 'w', encoding='utf-8') as f:
                                json.dump(gallery_metadata, f, ensure_ascii=False, indent=2)
                            print(f"[GALLERY-DL] Metadata å·²å„²å­˜: {metadata_file}", flush=True)
                    except json.JSONDecodeError as e:
                        print(f"[GALLERY-DL] Metadata è§£æå¤±æ•—: {e}", flush=True)
                
                # éšæ®µ 2: ä½¿ç”¨ gallery-dl -g + aria2c å¤šç·šç¨‹ä¸‹è¼‰åœ–ç‰‡
                print(f"[GALLERY-DL] éšæ®µ2: å¤šç·šç¨‹ä¸‹è¼‰åœ–ç‰‡...", flush=True)
                cmd = (
                    f'gallery-dl --user-agent "Mozilla/5.0" -g "{self.url}" | '
                    f'aria2c -i - -x 8 -s 8 --user-agent="Mozilla/5.0" -d "{self.temp_path}"'
                )
                
                logger.info(f"åŸ·è¡ŒæŒ‡ä»¤: {cmd}")
                print(f"[GALLERY-DL+ARIA2] å‘½ä»¤: {cmd}", flush=True)
                
                # ä½¿ç”¨ shell=True åŸ·è¡Œç®¡é“å‘½ä»¤
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=900
                )
            else:
                # Windows ç’°å¢ƒï¼šå…©éšæ®µä¸‹è¼‰
                # éšæ®µ 1: ä½¿ç”¨ gallery-dl --dump-json ç²å– metadata
                print(f"[GALLERY-DL] éšæ®µ1: ç²å– metadata...", flush=True)
                metadata_cmd = [
                    sys.executable,
                    '-m', 'gallery_dl',
                    '--dump-json',
                    self.url
                ]
                
                metadata_result = subprocess.run(
                    metadata_cmd,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                # è§£æä¸¦å„²å­˜ metadata
                if metadata_result.returncode == 0 and metadata_result.stdout.strip():
                    try:
                        metadata_list = json.loads(metadata_result.stdout)
                        if metadata_list and len(metadata_list) > 0:
                            first_item = metadata_list[0]
                            if isinstance(first_item, list) and len(first_item) >= 2:
                                gallery_metadata = first_item[1]
                            else:
                                gallery_metadata = first_item
                            
                            metadata_file = self.temp_path / "gallery_metadata.json"
                            with open(metadata_file, 'w', encoding='utf-8') as f:
                                json.dump(gallery_metadata, f, ensure_ascii=False, indent=2)
                            print(f"[GALLERY-DL] Metadata å·²å„²å­˜: {metadata_file}", flush=True)
                    except json.JSONDecodeError as e:
                        print(f"[GALLERY-DL] Metadata è§£æå¤±æ•—: {e}", flush=True)
                
                # éšæ®µ 2: ä¸‹è¼‰åœ–ç‰‡
                print(f"[GALLERY-DL] éšæ®µ2: ä¸‹è¼‰åœ–ç‰‡...", flush=True)
                
                # è¨­å®šæª”è·¯å¾‘
                config_path = BASE_DIR / "config" / "gallery-dl.conf"
                
                cmd = [
                    sys.executable,
                    '-m', 'gallery_dl',
                    '--config', str(config_path),
                    '--dest', str(self.temp_path),
                    '--write-metadata',
                    self.url
                ]
                
                logger.info(f"åŸ·è¡ŒæŒ‡ä»¤: {' '.join(cmd)}")
                print(f"[GALLERY-DL] å‘½ä»¤: {cmd}", flush=True)
                
                # åŸ·è¡Œ gallery-dl å‘½ä»¤
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=900
                )
            print(f"[GALLERY-DL] åŸ·è¡Œå®Œæˆ", flush=True)
            
            # å¼·åˆ¶è¼¸å‡ºæ‰€æœ‰ gallery-dl æ—¥èªŒï¼ˆç”¨æ–¼é™¤éŒ¯ï¼‰
            print(f"[GALLERY-DL] URL: {self.url}", flush=True)
            print(f"[GALLERY-DL] è¿”å›ç¢¼: {result.returncode}", flush=True)
            print(f"[GALLERY-DL] STDOUT: {result.stdout[:2000] if result.stdout else '(ç©º)'}", flush=True)
            print(f"[GALLERY-DL] STDERR: {result.stderr[:2000] if result.stderr else '(ç©º)'}", flush=True)
            
            if result.returncode != 0:
                logger.error(f"gallery-dl è¿”å›ç¢¼: {result.returncode}")
                logger.error(f"gallery-dl STDERR: {result.stderr}")
                logger.error(f"gallery-dl STDOUT: {result.stdout}")
                
                # å„²å­˜è©³ç´°éŒ¯èª¤è¨Šæ¯ä¾› Discord å›å ±
                # cmd åœ¨ Docker ç’°å¢ƒæ˜¯å­—ä¸²ï¼ŒWindows ç’°å¢ƒæ˜¯åˆ—è¡¨
                cmd_str = cmd if isinstance(cmd, str) else ' '.join(cmd)
                error_lines = [
                    f"\u26a0\ufe0f **Debug è³‡è¨Š**",
                    f"\ud83d\udce6 ç‰ˆæœ¬: {VERSION}",
                    f"\ud83d\udcbb ç’°å¢ƒ: {'Docker' if IS_DOCKER else 'Windows'}",
                    f"\ud83d\udcc2 ä¸‹è¼‰ç›®éŒ„: `{self.temp_path}`",
                    f"\ud83d\udd27 åŸ·è¡Œå‘½ä»¤: `{cmd_str}`",
                    f"\ud83d\udd34 è¿”å›ç¢¼: {result.returncode}",
                ]
                
                if result.stderr:
                    error_lines.append(f"\n**STDERR:**\n```\n{result.stderr[:800]}\n```")
                if result.stdout:
                    error_lines.append(f"\n**STDOUT:**\n```\n{result.stdout[:800]}\n```")
                
                self.last_error = "\n".join(error_lines)
                return False
            
            logger.info(f"gallery-dl è¼¸å‡º: {result.stdout}")
            return True
            
        except subprocess.TimeoutExpired:
            logger.error("gallery-dl åŸ·è¡Œè¶…æ™‚")
            return False
        except Exception as e:
            logger.error(f"gallery-dl åŸ·è¡ŒéŒ¯èª¤: {e}")
            return False
    
    def convert_to_pdf(self, images: List[Path], output_pdf: Path) -> bool:
        """
        ä½¿ç”¨ Pillow å°‡åœ–ç‰‡è½‰æ›ç‚ºç­‰å¯¬ PDFï¼ˆæ”¯æ´é€²åº¦å›å ±ï¼‰
        
        æ‰€æœ‰åœ–ç‰‡æœƒè¢«èª¿æ•´ç‚ºçµ±ä¸€å¯¬åº¦ï¼ˆä½¿ç”¨æœ€å¤§å¯¬åº¦ï¼‰ï¼Œé«˜åº¦æŒ‰æ¯”ä¾‹ç¸®æ”¾ï¼Œ
        ç¢ºä¿ PDF æ¯ä¸€é éƒ½æ˜¯ 100% å¯¬åº¦å°é½Šã€‚
        
        Args:
            images: åœ–ç‰‡æª”æ¡ˆåˆ—è¡¨
            output_pdf: è¼¸å‡º PDF è·¯å¾‘
        
        Returns:
            æˆåŠŸè¿”å› Trueï¼Œå¤±æ•—è¿”å› False
        """
        if not images:
            logger.error("æ²’æœ‰åœ–ç‰‡å¯ä¾›è½‰æ›")
            return False
        
        try:
            from PIL import Image
            
            self.pdf_converting = True
            self.pdf_progress = 0
            
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
            output_pdf.parent.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"è½‰æ› {len(images)} å¼µåœ–ç‰‡ç‚ºç­‰å¯¬ PDF")
            
            total = len(images)
            
            # éšæ®µ 1: è®€å–æ‰€æœ‰åœ–ç‰‡ä¸¦æ‰¾å‡ºæœ€å¤§å¯¬åº¦ (0-20%)
            logger.info("éšæ®µ 1/3: åˆ†æåœ–ç‰‡å°ºå¯¸...")
            pil_images = []
            max_width = 0
            
            for i, img_path in enumerate(images):
                img = Image.open(img_path)
                # è½‰æ›ç‚º RGBï¼ˆPDF ä¸æ”¯æ´ RGBA é€æ˜é€šé“ï¼‰
                if img.mode in ('RGBA', 'P', 'LA'):
                    # å»ºç«‹ç™½è‰²èƒŒæ™¯
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    if img.mode in ('RGBA', 'LA'):
                        background.paste(img, mask=img.split()[-1])  # ä½¿ç”¨ alpha é€šé“ä½œç‚ºé®ç½©
                        img = background
                    else:
                        img = img.convert('RGB')
                elif img.mode != 'RGB':
                    img = img.convert('RGB')
                
                pil_images.append(img)
                if img.width > max_width:
                    max_width = img.width
                
                self.pdf_progress = int((i + 1) / total * 20)
                if (i + 1) % 10 == 0:
                    time.sleep(0.05)
            
            logger.info(f"çµ±ä¸€å¯¬åº¦: {max_width}px")
            
            # éšæ®µ 2: èª¿æ•´æ‰€æœ‰åœ–ç‰‡ç‚ºç­‰å¯¬ (20-70%)
            logger.info("éšæ®µ 2/3: èª¿æ•´åœ–ç‰‡ç‚ºç­‰å¯¬...")
            resized_images = []
            
            for i, img in enumerate(pil_images):
                if img.width != max_width:
                    # æŒ‰æ¯”ä¾‹ç¸®æ”¾åˆ°ç›®æ¨™å¯¬åº¦
                    ratio = max_width / img.width
                    new_height = int(img.height * ratio)
                    # ä½¿ç”¨é«˜å“è³ªç¸®æ”¾
                    resized_img = img.resize((max_width, new_height), Image.Resampling.LANCZOS)
                    resized_images.append(resized_img)
                else:
                    resized_images.append(img)
                
                self.pdf_progress = 20 + int((i + 1) / total * 50)
                if (i + 1) % 10 == 0:
                    time.sleep(0.05)
            
            # éšæ®µ 3: å„²å­˜ç‚º PDF (70-100%)
            logger.info("éšæ®µ 3/3: ç”Ÿæˆ PDF...")
            logger.info(f"PDF è¼¸å‡ºè·¯å¾‘: {output_pdf}")
            logger.info(f"è·¯å¾‘é•·åº¦: {len(str(output_pdf))} å­—å…ƒ")
            self.pdf_progress = 75
            
            # ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºåŸºåº•ï¼Œå…¶é¤˜ append
            first_image = resized_images[0]
            rest_images = resized_images[1:] if len(resized_images) > 1 else []
            
            try:
                first_image.save(
                    output_pdf,
                    "PDF",
                    save_all=True,
                    append_images=rest_images,
                    resolution=100.0
                )
                logger.info("PDF save å‘¼å«å®Œæˆ")
            except Exception as save_error:
                logger.error(f"PDF save å¤±æ•—: {save_error}")
                import traceback
                logger.error(traceback.format_exc())
                self.pdf_converting = False
                return False
            
            # æ¸…ç†è¨˜æ†¶é«” - ä½¿ç”¨ set è¿½è¹¤å·²é—œé–‰çš„åœ–ç‰‡ idï¼Œé¿å…æ¯”è¼ƒæ“ä½œ
            closed_ids = set()
            for img in pil_images:
                if id(img) not in closed_ids:
                    try:
                        img.close()
                    except Exception:
                        pass
                    closed_ids.add(id(img))
            for img in resized_images:
                if id(img) not in closed_ids:
                    try:
                        img.close()
                    except Exception:
                        pass
                    closed_ids.add(id(img))
            
            self.pdf_progress = 100
            self.pdf_converting = False
            
            # ç¢ºèª PDF å·²ç”Ÿæˆ
            if output_pdf.exists() and output_pdf.stat().st_size > 0:
                logger.info(f"PDF ç”ŸæˆæˆåŠŸ: {output_pdf}")
                return True
            else:
                logger.error("PDF æª”æ¡ˆæœªç”Ÿæˆæˆ–ç‚ºç©º")
                return False
                
        except Exception as e:
            logger.error(f"PDF è½‰æ›éŒ¯èª¤: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.pdf_converting = False
            return False
    
    def process(self) -> tuple[bool, str]:
        """
        åŸ·è¡Œå®Œæ•´çš„ä¸‹è¼‰è™•ç†æµç¨‹
        
        Returns:
            (æˆåŠŸç‹€æ…‹, çµæœè¨Šæ¯)
        """
        start_time = time.time()  # é–‹å§‹è¨ˆæ™‚
        
        try:
            # æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self.is_cancelled():
                return False, "ğŸš« ä¸‹è¼‰å·²å–æ¶ˆ"
            
            # æ­¥é©Ÿ 1: ä¸‹è¼‰
            logger.info(f"é–‹å§‹ä¸‹è¼‰: {self.url}")
            print(f"[PROCESS] é–‹å§‹ä¸‹è¼‰: {self.url}", flush=True)
            if not self.download_with_gallery_dl():
                # å†æ¬¡æª¢æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                if self.is_cancelled():
                    return False, "ğŸš« ä¸‹è¼‰å·²å–æ¶ˆ"
                error_detail = self.last_error if self.last_error else "æœªçŸ¥åŸå› "
                elapsed = time.time() - start_time
                return False, f"âŒ ä¸‹è¼‰å¤±æ•—\nğŸ”— {self.url}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s\n\n{error_detail}"
            
            # æª¢æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self.is_cancelled():
                return False, "ğŸš« ä¸‹è¼‰å·²å–æ¶ˆ"
            
            # å°‹æ‰¾ä¸‹è¼‰çš„å…§å®¹
            # gallery-dl å¯èƒ½æœƒå»ºç«‹å­ç›®éŒ„
            print(f"[PROCESS] æœå°‹åœ–ç‰‡ç›®éŒ„: {self.temp_path}", flush=True)
            images = find_images(self.temp_path)
            print(f"[PROCESS] æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡", flush=True)
            
            if not images:
                # åˆ—å‡ºç›®éŒ„å…§å®¹ä»¥ä¾¿é™¤éŒ¯
                try:
                    all_files = list(self.temp_path.rglob('*'))
                    print(f"[DEBUG] ç›®éŒ„å…§æ‰€æœ‰æª”æ¡ˆ: {[str(f) for f in all_files[:20]]}", flush=True)
                except Exception as e:
                    print(f"[DEBUG] ç„¡æ³•åˆ—å‡ºç›®éŒ„: {e}", flush=True)
                elapsed = time.time() - start_time
                return False, f"âŒ æ‰¾ä¸åˆ°ä¸‹è¼‰çš„åœ–ç‰‡\nğŸ”— {self.url}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s"
            
            logger.info(f"æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡")
            
            # æ­¥é©Ÿ 2: è§£æ metadata
            info_json = find_info_json(self.temp_path)
            
            if info_json:
                metadata = parse_gallery_dl_info(info_json)
            else:
                logger.warning("æ‰¾ä¸åˆ° info.jsonï¼Œä½¿ç”¨é è¨­ metadata")
                metadata = None
            
            # è¨­å®šæ¨™é¡Œ - å„ªå…ˆä½¿ç”¨æ—¥æ–‡æ¨™é¡Œ
            if metadata:
                # å„ªå…ˆé †åº: æ—¥æ–‡æ¨™é¡Œ > è‹±æ–‡æ¨™é¡Œ > URL ID
                if metadata.get('title_japanese'):
                    title = metadata['title_japanese']
                    logger.info(f"ä½¿ç”¨æ—¥æ–‡æ¨™é¡Œ: {title}")
                elif metadata.get('title'):
                    title = metadata['title']
                    logger.info(f"ä½¿ç”¨è‹±æ–‡æ¨™é¡Œ: {title}")
                else:
                    title = None
            else:
                title = None
            
            # æå– gallery_id ç”¨æ–¼ç›®éŒ„å’Œæª”åï¼ˆé¿å…è·¯å¾‘éé•·ï¼‰
            gallery_id_for_path = metadata.get('gallery_id', '') if metadata else ''
            if not gallery_id_for_path:
                # å˜—è©¦å¾ URL æå–
                match = re.search(r'/g/(\d+)', self.url)
                if match:
                    gallery_id_for_path = match.group(1)
                else:
                    gallery_id_for_path = str(int(time.time()))
            
            if not title:
                title = f"Gallery_{gallery_id_for_path}"
            
            safe_title = sanitize_filename(title)
            logger.info(f"ä½¿ç”¨æ¨™é¡Œ: {safe_title}")
            logger.info(f"ä½¿ç”¨ Gallery ID ä½œç‚ºç›®éŒ„å: {gallery_id_for_path}")
            
            # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾ - ä½¿ç”¨ gallery_id é¿å…è·¯å¾‘éé•·
            self.output_path = DOWNLOAD_DIR / gallery_id_for_path
            
            # å¦‚æœè³‡æ–™å¤¾å·²å­˜åœ¨ï¼Œä½¿ç”¨æ™‚é–“æˆ³å‘½åé¿å…è¦†è“‹
            if self.output_path.exists():
                self.output_path = DOWNLOAD_DIR / f"{gallery_id_for_path}_{int(time.time())}"
                logger.info(f"è³‡æ–™å¤¾å·²å­˜åœ¨ï¼Œä½¿ç”¨æ–°è³‡æ–™å¤¾ {self.output_path}")
            
            self.output_path.mkdir(parents=True, exist_ok=True)
            
            # æ­¥é©Ÿ 3: è½‰æ›ç‚º PDF - ä½¿ç”¨ gallery_id ä½œç‚ºæª”å
            pdf_path = self.output_path / f"{gallery_id_for_path}.pdf"
            if not self.convert_to_pdf(images, pdf_path):
                return False, "âŒ PDF è½‰æ›å¤±æ•—"
            
            # æ­¥é©Ÿ 3.5: è¤‡è£½ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢
            if images:
                try:
                    first_image = images[0]
                    # ç²å–å‰¯æª”å
                    ext = first_image.suffix  # ä¾‹å¦‚ .jpg, .png
                    cover_path = self.output_path / f"cover{ext}"
                    # è¤‡è£½ç¬¬ä¸€å¼µåœ–ç‰‡
                    shutil.copy2(first_image, cover_path)
                    logger.info(f"å°é¢å·²ä¿å­˜: {cover_path.name}")
                except Exception as e:
                    logger.warning(f"ä¿å­˜å°é¢å¤±æ•—: {e}")
            
            # æ­¥é©Ÿ 4: ç²å–é¡å¤–è³‡è¨Šï¼ˆæ”¶è—æ•¸ã€è©•è«–ï¼‰
            gallery_id = metadata.get('gallery_id', '') if metadata else ''
            if not gallery_id:
                # å˜—è©¦å¾ URL æå–
                match = re.search(r'/g/(\d+)', self.url)
                if match:
                    gallery_id = match.group(1)
            
            nhentai_extra = {}
            if gallery_id:
                logger.info(f"ç²å– nhentai é¡å¤–è³‡è¨Š (ID: {gallery_id})...")
                nhentai_extra = fetch_nhentai_extra_info(gallery_id)
            
            # æ­¥é©Ÿ 5: ç”Ÿæˆ Eagle metadataï¼ˆåŒ…å«æ“´å±•è³‡è¨Šï¼‰
            extra_info = None
            if metadata:
                extra_info = {
                    'title_japanese': metadata.get('title_japanese', ''),
                    'title_english': metadata.get('title', ''),  # è‹±æ–‡æ¨™é¡Œæ”¾ annotation
                    'title_pretty': metadata.get('title_pretty', ''),
                    'gallery_id': metadata.get('gallery_id', ''),
                    'pages': metadata.get('pages', 0),
                    'favorites': nhentai_extra.get('favorites', 0),  # å¾ API ç²å–
                    'category': metadata.get('category', ''),
                    'type': metadata.get('type', ''),
                    'artist': metadata.get('artist', []),
                    'group': metadata.get('group', []),
                    'parody': metadata.get('parody', []),
                    'character': metadata.get('character', []),
                    'language': metadata.get('language', ''),
                    'comments': nhentai_extra.get('comments', []),  # è©•è«–
                }
            
            eagle_metadata = create_eagle_metadata(
                title=title,  # å·²ç¶“æ˜¯æ—¥æ–‡æ¨™é¡Œå„ªå…ˆ
                url=metadata.get('url', self.url) if metadata else self.url,
                tags=metadata.get('tags', []) if metadata else [],
                annotation="",
                extra_info=extra_info
            )
            
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨ï¼ˆé˜²æ­¢ UNC è·¯å¾‘å•é¡Œï¼‰
            self.output_path.mkdir(parents=True, exist_ok=True)
            
            metadata_path = self.output_path / "metadata.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(eagle_metadata, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Eagle metadata å·²ç”Ÿæˆ: {metadata_path}")
            
            # æ­¥é©Ÿ 5: æ¸…ç†æš«å­˜æª”æ¡ˆ
            if self.temp_path and self.temp_path.exists():
                shutil.rmtree(self.temp_path)
                logger.info(f"å·²æ¸…ç†æš«å­˜ç›®éŒ„: {self.temp_path}")
            
            # è¨ˆç®—è€—æ™‚
            elapsed = time.time() - start_time
            if elapsed >= 60:
                elapsed_str = f"{int(elapsed // 60)}åˆ†{int(elapsed % 60)}ç§’"
            else:
                elapsed_str = f"{elapsed:.1f}ç§’"
            
            # ç²å–é æ•¸
            page_count = metadata.get('pages', len(images)) if metadata else len(images)
            
            # è½‰æ›è·¯å¾‘ç‚ºå­—ä¸²ï¼Œç¢ºä¿ UNC è·¯å¾‘æ­£ç¢ºé¡¯ç¤º
            output_path_str = str(self.output_path)
            if output_path_str.startswith('\\\\'):
                output_path_str = output_path_str  # å·²ç¶“æ˜¯æ­£ç¢ºçš„ UNC è·¯å¾‘
            elif output_path_str.startswith('\\') and not output_path_str.startswith('\\\\'):
                output_path_str = '\\' + output_path_str  # è£œä¸Šç¼ºå°‘çš„æ–œç·š
            
            # ç”Ÿæˆ PDF Web é€£çµ - ä½¿ç”¨å¯¦éš›è³‡æ–™å¤¾åç¨±ï¼ˆå¯èƒ½æœ‰æ™‚é–“æˆ³å¾Œç¶´ï¼‰
            from urllib.parse import quote
            folder_name = self.output_path.name  # ä½¿ç”¨å¯¦éš›è³‡æ–™å¤¾åç¨±
            pdf_filename = f"{gallery_id_for_path}.pdf"
            pdf_web_url = f"{PDF_WEB_BASE_URL}/{quote(folder_name)}/{quote(pdf_filename)}"
            
            # ä½¿ç”¨ç´” URL é¡¯ç¤ºï¼ˆé¿å… markdown é€£çµè¢«ç·¨ç¢¼çš„æ‹¬è™Ÿç ´å£ï¼‰
            return True, f"âœ… å®Œæˆ: **{safe_title}**\nğŸ“„ {page_count}é  â±ï¸ {elapsed_str}\nğŸ“¥ {pdf_web_url}\nğŸ“ {output_path_str}"
            
        except Exception as e:
            logger.exception(f"è™•ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            
            # è¨ˆç®—è€—æ™‚
            elapsed = time.time() - start_time
            
            # æ¸…ç†æš«å­˜æª”æ¡ˆ
            if self.temp_path and self.temp_path.exists():
                try:
                    shutil.rmtree(self.temp_path)
                except Exception:
                    pass
            
            return False, f"âŒ éŒ¯èª¤: {str(e)}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s"


# ==================== Worker Thread ====================

class DownloadWorker(threading.Thread):
    """
    ä¸‹è¼‰å·¥ä½œåŸ·è¡Œç·’ï¼šå¾ä½‡åˆ—ä¸­å–å‡ºä»»å‹™ä¸¦åŸ·è¡Œ
    """
    
    def __init__(self, bot):
        super().__init__(daemon=True)
        self.bot = bot
        self.running = True
        self.current_task: Optional[str] = None  # æ­£åœ¨è™•ç†çš„ URL
    
    def run(self):
        """å·¥ä½œåŸ·è¡Œç·’ä¸»è¿´åœˆ"""
        logger.info("ä¸‹è¼‰å·¥ä½œåŸ·è¡Œç·’å·²å•Ÿå‹•")
        
        while self.running:
            try:
                # å¾ä½‡åˆ—å–å¾—ä»»å‹™ï¼ˆé˜»å¡å¼ç­‰å¾…ï¼Œ1ç§’è¶…æ™‚ï¼‰
                task = download_queue.get(timeout=1)
                
                if task is None:
                    continue
                
                # æ”¯æ´æ ¼å¼: 
                # (url, channel_id)
                # (url, channel_id, status_msg_id)
                # (url, channel_id, status_msg_id, test_mode)
                # (url, channel_id, status_msg_id, test_mode, batch_id)
                batch_id = None
                if len(task) == 5:
                    url, channel_id, status_msg_id, test_mode, batch_id = task
                elif len(task) == 4:
                    url, channel_id, status_msg_id, test_mode = task
                elif len(task) == 3:
                    url, channel_id, status_msg_id = task
                    test_mode = False
                else:
                    url, channel_id = task
                    status_msg_id = None
                    test_mode = False
                
                self.current_task = url
                logger.info(f"è™•ç†ä¸‹è¼‰ä»»å‹™: {url}")
                
                # æå– gallery ID ä¸¦ç²å–é æ•¸ï¼Œç™¼é€é–‹å§‹è¨Šæ¯
                start_msg_id = None
                pages = 0
                title = ""
                media_id = ""
                current_gallery_id = None
                cancel_event = None
                match = re.search(r'/g/(\d+)', url)
                if match:
                    current_gallery_id = match.group(1)
                    gallery_id = current_gallery_id
                    
                    # è¨»å†Šå–æ¶ˆäº‹ä»¶
                    cancel_event = register_cancel_event(gallery_id)
                    
                    pages, title, media_id = get_nhentai_page_count(gallery_id)
                    if pages > 0:
                        # ç™¼é€é–‹å§‹ä¸‹è¼‰è¨Šæ¯ï¼ˆåŒ…å«é æ•¸å’Œé ä¼°æ™‚é–“ï¼‰ï¼Œä¸¦è¿”å›è¨Šæ¯ ID
                        future = asyncio.run_coroutine_threadsafe(
                            self.send_start_message(channel_id, gallery_id, pages, title, media_id),
                            self.bot.loop
                        )
                        start_msg_id = future.result(timeout=10)
                
                # æª¢æŸ¥æ˜¯å¦åœ¨é–‹å§‹å‰å°±è¢«å–æ¶ˆ
                if current_gallery_id and is_cancelled(current_gallery_id):
                    logger.info(f"ä¸‹è¼‰å·²å–æ¶ˆ (é–‹å§‹å‰): {current_gallery_id}")
                    unregister_cancel_event(current_gallery_id)
                    self.current_task = None
                    download_queue.task_done()
                    continue
                
                # å‰µå»ºä¸‹è¼‰è™•ç†å™¨ï¼ˆå‚³å…¥å–æ¶ˆäº‹ä»¶ï¼‰
                processor = DownloadProcessor(url, total_pages=pages, cancel_event=cancel_event)
                
                # å•Ÿå‹•é€²åº¦ç›£æ§åŸ·è¡Œç·’
                progress_stop_event = threading.Event()
                if start_msg_id and pages > 0:
                    progress_thread = threading.Thread(
                        target=self._monitor_progress,
                        args=(processor, channel_id, start_msg_id, pages, title, gallery_id, media_id, progress_stop_event),
                        daemon=True
                    )
                    progress_thread.start()
                
                # åŸ·è¡Œä¸‹è¼‰è™•ç†
                success, message = processor.process()
                
                # æª¢æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                was_cancelled = current_gallery_id and is_cancelled(current_gallery_id)
                if was_cancelled:
                    success = False
                    message = f"ğŸš« ä¸‹è¼‰å·²å–æ¶ˆ: #{current_gallery_id}"
                
                # å–æ¶ˆè¨»å†Šå–æ¶ˆäº‹ä»¶
                if current_gallery_id:
                    unregister_cancel_event(current_gallery_id)
                
                # åœæ­¢é€²åº¦ç›£æ§
                progress_stop_event.set()
                
                # æ›´æ–°é–‹å§‹ä¸‹è¼‰è¨Šæ¯ï¼ˆé¡¯ç¤ºæœ€çµ‚ç‹€æ…‹ï¼‰
                if start_msg_id and not was_cancelled:
                    asyncio.run_coroutine_threadsafe(
                        self.update_final_progress(channel_id, start_msg_id, success, pages, title, gallery_id),
                        self.bot.loop
                    )
                
                # ç™¼é€çµæœåˆ° Discord (å–æ¶ˆæ™‚ä¸ç™¼é€é¡å¤–è¨Šæ¯)
                if not was_cancelled:
                    asyncio.run_coroutine_threadsafe(
                        self.send_result(channel_id, message),
                        self.bot.loop
                    )
                
                # æ›´æ–°æ‰¹æ¬¡è¿½è¹¤
                if batch_id:
                    batch_result = update_batch(batch_id, success, current_gallery_id)
                    if batch_result:
                        # æ‰¹æ¬¡å®Œæˆï¼Œç™¼é€ç¸½çµ
                        asyncio.run_coroutine_threadsafe(
                            self.send_batch_summary(batch_result),
                            self.bot.loop
                        )
                
                self.current_task = None
                download_queue.task_done()
            
            except Empty:
                # ä½‡åˆ—ç‚ºç©ºï¼Œé€™æ˜¯æ­£å¸¸çš„ï¼Œç¹¼çºŒç­‰å¾…
                continue
                
            except Exception as e:
                self.current_task = None
                logger.exception(f"å·¥ä½œåŸ·è¡Œç·’éŒ¯èª¤: {e}")
    
    def _monitor_progress(self, processor: DownloadProcessor, channel_id: int, 
                          message_id: int, total_pages: int, title: str, 
                          gallery_id: str, media_id: str, stop_event: threading.Event):
        """
        ç›£æ§ä¸‹è¼‰é€²åº¦ä¸¦æ›´æ–° Discord è¨Šæ¯
        
        åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­å®šæœŸæª¢æŸ¥å·²ä¸‹è¼‰çš„åœ–ç‰‡æ•¸é‡ï¼Œä¸¦ç·¨è¼¯è¨Šæ¯é¡¯ç¤ºé€²åº¦æ¢
        """
        last_count = 0
        last_pdf_progress = -1
        start_time = time.time()
        pdf_start_time = None  # PDF è½‰æ›é–‹å§‹æ™‚é–“
        first_image_sent = False  # è¿½è¹¤æ˜¯å¦å·²ç™¼é€ç¬¬ä¸€å¼µåœ–ç‰‡
        pdf_mode = False  # æ˜¯å¦é€²å…¥ PDF æ¨¡å¼
        
        while not stop_event.is_set():
            try:
                # æ ¹æ“šæ¨¡å¼èª¿æ•´æª¢æŸ¥é–“éš”
                check_interval = 1 if pdf_mode else PROGRESS_UPDATE_INTERVAL
                
                # ç­‰å¾…ä¸€æ®µæ™‚é–“
                if stop_event.wait(timeout=check_interval):
                    break  # æ”¶åˆ°åœæ­¢ä¿¡è™Ÿ
                
                # æª¢æŸ¥æ˜¯å¦åœ¨ PDF è½‰æ›éšæ®µ
                if processor.pdf_converting:
                    pdf_mode = True
                    pdf_progress = processor.pdf_progress
                    
                    # è¨˜éŒ„ PDF é–‹å§‹æ™‚é–“
                    if pdf_start_time is None:
                        pdf_start_time = time.time()
                    
                    if pdf_progress != last_pdf_progress:
                        last_pdf_progress = pdf_progress
                        
                        # è¨ˆç®— PDF é ä¼°å‰©é¤˜æ™‚é–“
                        pdf_eta_str = "è¨ˆç®—ä¸­..."
                        if pdf_progress > 0:
                            pdf_elapsed = time.time() - pdf_start_time
                            pdf_eta_seconds = (pdf_elapsed / pdf_progress) * (100 - pdf_progress)
                            if pdf_eta_seconds >= 60:
                                pdf_eta_str = f"{int(pdf_eta_seconds // 60)}åˆ†{int(pdf_eta_seconds % 60)}ç§’"
                            else:
                                pdf_eta_str = f"{int(pdf_eta_seconds)}ç§’"
                        
                        # é¡¯ç¤º PDF è½‰æ›é€²åº¦
                        pdf_bar = create_progress_bar(pdf_progress, 100)
                        # ä¸‹è¼‰é€²åº¦æ¢ä¿æŒ 100%
                        download_bar = create_progress_bar(total_pages, total_pages)
                        
                        asyncio.run_coroutine_threadsafe(
                            self.update_pdf_progress_message(
                                channel_id, message_id, 
                                pdf_progress, pdf_bar, download_bar, total_pages, title, pdf_eta_str
                            ),
                            self.bot.loop
                        )
                    continue
                
                # ç²å–å·²ä¸‹è¼‰æ•¸é‡
                current_count = processor.get_downloaded_count()
                
                # ç­‰ç¬¬ 3 å¼µåœ–ç‰‡ä¸‹è¼‰å®Œæˆå¾Œï¼Œç™¼é€ç¬¬ä¸€å¼µåœ–ç‰‡ï¼ˆç¢ºä¿ç¬¬ä¸€å¼µå·²å®Œæ•´ä¸‹è¼‰ï¼‰
                if current_count >= 3 and not first_image_sent:
                    first_image_sent = True
                    # ç­‰å¾… 1 ç§’ç¢ºä¿ NAS å¯«å…¥å®Œæˆ
                    time.sleep(1)
                    first_image = processor.get_first_image_path()
                    # ç¢ºèªæª”æ¡ˆå¤§å°å¤§æ–¼ 0
                    if first_image and first_image.exists() and first_image.stat().st_size > 0:
                        asyncio.run_coroutine_threadsafe(
                            self.send_cover_image(channel_id, first_image),
                            self.bot.loop
                        )
                
                # ä¸‹è¼‰å®Œæˆæ™‚ï¼Œåˆ‡æ›åˆ°æ›´é »ç¹çš„æª¢æŸ¥æ¨¡å¼ä»¥åµæ¸¬ PDF è½‰æ›
                if current_count >= total_pages:
                    pdf_mode = True
                
                # åªæœ‰é€²åº¦æœ‰è®ŠåŒ–æ™‚æ‰æ›´æ–°
                if current_count != last_count and current_count > 0:
                    last_count = current_count
                    
                    # è¨ˆç®—é€²åº¦å’Œé ä¼°å‰©é¤˜æ™‚é–“
                    progress_bar = create_progress_bar(current_count, total_pages)
                    elapsed = time.time() - start_time
                    
                    if current_count > 0:
                        avg_time_per_page = elapsed / current_count
                        remaining_pages = total_pages - current_count
                        eta_seconds = remaining_pages * avg_time_per_page
                        
                        if eta_seconds >= 60:
                            eta_str = f"{int(eta_seconds // 60)}åˆ†{int(eta_seconds % 60)}ç§’"
                        else:
                            eta_str = f"{int(eta_seconds)}ç§’"
                    else:
                        eta_str = "è¨ˆç®—ä¸­..."
                    
                    # æ›´æ–°è¨Šæ¯
                    asyncio.run_coroutine_threadsafe(
                        self.update_progress_message(
                            channel_id, message_id, 
                            current_count, total_pages, 
                            progress_bar, eta_str, title
                        ),
                        self.bot.loop
                    )
                    
            except Exception as e:
                logger.error(f"é€²åº¦ç›£æ§éŒ¯èª¤: {e}")
    
    async def send_cover_image(self, channel_id: int, image_path: Path):
        """ç™¼é€å°é¢åœ–ç‰‡ä½œç‚ºé™„ä»¶"""
        try:
            channel = self.bot.get_channel(channel_id)
            if channel and image_path and image_path.exists():
                await channel.send(file=discord.File(image_path))
                logger.info(f"å·²ç™¼é€å°é¢åœ–ç‰‡: {image_path.name}")
        except Exception as e:
            logger.error(f"ç™¼é€å°é¢åœ–ç‰‡å¤±æ•—: {e}")
    
    async def update_progress_message(self, channel_id: int, message_id: int,
                                       current: int, total: int,
                                       progress_bar: str, eta: str, title: str):
        """ç·¨è¼¯è¨Šæ¯æ›´æ–°ä¸‹è¼‰é€²åº¦"""
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # ç·¨è¼¯è¨Šæ¯
            new_content = (
                f"ğŸ”„ ä¸‹è¼‰ä¸­...\n"
                f"ğŸ“– {title}\n"
                f"{progress_bar}\n"
                f"({current}/{total}) â±ï¸ é ä¼°å‰©é¤˜: {eta}"
            )
            await message.edit(content=new_content)
            
        except Exception as e:
            logger.error(f"æ›´æ–°é€²åº¦è¨Šæ¯å¤±æ•—: {e}")
    
    async def update_pdf_progress_message(self, channel_id: int, message_id: int,
                                          progress: int, pdf_bar: str, download_bar: str, 
                                          total_pages: int, title: str, eta: str = ""):
        """ç·¨è¼¯è¨Šæ¯æ›´æ–° PDF è½‰æ›é€²åº¦"""
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # ç·¨è¼¯è¨Šæ¯ - é¡¯ç¤ºå…©æ¢é€²åº¦æ¢
            new_content = (
                f"ğŸ“„ è£½ä½œ PDF ä¸­...\n"
                f"ğŸ“– {title}\n"
                f"ä¸‹è¼‰: \n{download_bar}\n"
                f"({total_pages}/{total_pages})\n"
                f"PDF: \n{pdf_bar}\n"
                f"â±ï¸ é ä¼°å‰©é¤˜: {eta}"
            )
            await message.edit(content=new_content)
            
        except Exception as e:
            logger.error(f"æ›´æ–° PDF é€²åº¦è¨Šæ¯å¤±æ•—: {e}")
    
    async def update_final_progress(self, channel_id: int, message_id: int, 
                                    success: bool, total: int, title: str, gallery_id: str = ""):
        """æ›´æ–°æœ€çµ‚é€²åº¦ç‹€æ…‹"""
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # æ›´æ–°è¨Šæ¯å…§å®¹å’Œè¡¨æƒ…
            if success:
                progress_bar = create_progress_bar(total, total)
                
                # å»ºç«‹ä¸‹è¼‰å®Œæˆäº’å‹•è¦–åœ–
                from bot.views import DownloadCompleteView
                view = DownloadCompleteView(
                    gallery_id=gallery_id if gallery_id else "unknown",
                    title=title
                )
                
                await message.edit(
                    content=f"âœ… ä¸‹è¼‰å®Œæˆ\nğŸ“– {title}\n{progress_bar}\n({total}/{total})",
                    view=view
                )
                await message.add_reaction('âœ…')
            else:
                await message.add_reaction('âŒ')
            
        except Exception as e:
            logger.error(f"æ›´æ–°æœ€çµ‚é€²åº¦å¤±æ•—: {e}")
    
    async def send_start_message(self, channel_id: int, gallery_id: str, pages: int, title: str, media_id: str = "") -> int:
        """
        ç™¼é€é–‹å§‹ä¸‹è¼‰è¨Šæ¯ï¼ˆåŒ…å«é æ•¸å’Œé ä¼°æ™‚é–“ + å–æ¶ˆæŒ‰éˆ•ï¼‰
        
        Returns:
            è¨Šæ¯ IDï¼Œå¤±æ•—æ™‚è¿”å› None
        """
        try:
            channel = self.bot.get_channel(channel_id)
            if channel:
                # è¨ˆç®—é ä¼°æ™‚é–“
                est_seconds = pages * SECONDS_PER_PAGE
                if est_seconds >= 60:
                    est_str = f"{int(est_seconds // 60)}åˆ†{int(est_seconds % 60)}ç§’"
                else:
                    est_str = f"{int(est_seconds)}ç§’"
                
                # åˆå§‹é€²åº¦æ¢
                progress_bar = create_progress_bar(0, pages)
                
                # å»ºç«‹å¸¶æœ‰å–æ¶ˆæŒ‰éˆ•çš„ View
                from bot.views import DownloadProgressView
                view = DownloadProgressView(gallery_id=gallery_id, title=title)
                
                # ç™¼é€é€²åº¦è¨Šæ¯
                msg = await channel.send(
                    f"ğŸ”„ é–‹å§‹ä¸‹è¼‰ **#{gallery_id}**\n"
                    f"ğŸ“– {title}\n"
                    f"{progress_bar}\n"
                    f"(0/{pages}) â±ï¸ é ä¼°: {est_str}",
                    view=view
                )
                
                return msg.id
        except Exception as e:
            logger.error(f"ç™¼é€é–‹å§‹è¨Šæ¯å¤±æ•—: {e}")
        return None
    
    async def update_status_reaction(self, channel_id: int, message_id: int, success: bool):
        """æ›´æ–°ç‹€æ…‹è¨Šæ¯çš„è¡¨æƒ…ï¼šæ·»åŠ  âœ… æˆ– âŒï¼ˆå·²ä¸å†ä½¿ç”¨ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰"""
        if not message_id:
            return
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # æ·»åŠ çµæœè¡¨æƒ…
            result_emoji = 'âœ…' if success else 'âŒ'
            await message.add_reaction(result_emoji)
            
        except Exception as e:
            logger.error(f"æ›´æ–°ç‹€æ…‹è¡¨æƒ…å¤±æ•—: {e}")
    
    async def send_result(self, channel_id: int, message: str):
        """ç™¼é€çµæœè¨Šæ¯åˆ° Discord é »é“"""
        try:
            channel = self.bot.get_channel(channel_id)
            if channel:
                await channel.send(message)
        except Exception as e:
            logger.error(f"ç™¼é€è¨Šæ¯å¤±æ•—: {e}")
    
    async def send_batch_summary(self, batch_result: Dict[str, Any]):
        """ç™¼é€æ‰¹æ¬¡ä¸‹è¼‰å®Œæˆç¸½çµ"""
        try:
            channel = self.bot.get_channel(batch_result['channel_id'])
            if not channel:
                return
            
            total = batch_result['total']
            success = batch_result['success']
            failed = batch_result['failed']
            
            # æ§‹å»ºç¸½çµè¨Šæ¯
            if failed == 0:
                emoji = "ğŸ‰"
                status = "å…¨éƒ¨æˆåŠŸ"
            elif success == 0:
                emoji = "âŒ"
                status = "å…¨éƒ¨å¤±æ•—"
            else:
                emoji = "âš ï¸"
                status = "éƒ¨åˆ†å®Œæˆ"
            
            msg_lines = [
                f"{emoji} **æ‰¹æ¬¡ä¸‹è¼‰å®Œæˆ** - {status}",
                f"",
                f"ğŸ“Š **çµ±è¨ˆçµæœ**",
                f"â€¢ ç¸½è¨ˆ: {total} å€‹",
                f"â€¢ âœ… æˆåŠŸ: {success} å€‹",
                f"â€¢ âŒ å¤±æ•—: {failed} å€‹",
            ]
            
            # å¦‚æœæœ‰å¤±æ•—çš„ï¼Œåˆ—å‡ºå¤±æ•—çš„ ID
            if batch_result.get('failed_ids'):
                failed_ids = batch_result['failed_ids'][:10]  # æœ€å¤šé¡¯ç¤º 10 å€‹
                failed_list = ", ".join([f"`{gid}`" for gid in failed_ids])
                msg_lines.append(f"")
                msg_lines.append(f"âŒ å¤±æ•—æ¸…å–®: {failed_list}")
                if len(batch_result['failed_ids']) > 10:
                    msg_lines.append(f"... åŠå…¶ä»– {len(batch_result['failed_ids']) - 10} å€‹")
            
            await channel.send("\n".join(msg_lines))
            logger.info(f"æ‰¹æ¬¡ä¸‹è¼‰å®Œæˆ: {success}/{total} æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"ç™¼é€æ‰¹æ¬¡ç¸½çµå¤±æ•—: {e}")
    
    def stop(self):
        """åœæ­¢å·¥ä½œåŸ·è¡Œç·’"""
        self.running = False


# ==================== Discord Bot ====================

class HentaiFetcherBot(commands.Bot):
    """
    HentaiFetcher Discord Bot (ä½¿ç”¨ Slash Commands)
    """
    
    def __init__(self):
        # è¨­å®š Intents
        intents = discord.Intents.default()
        intents.message_content = True
        
        super().__init__(
            command_prefix='!',
            intents=intents,
            help_command=None  # ä½¿ç”¨è‡ªè¨‚ help
        )
        
        self.worker: Optional[DownloadWorker] = None
    
    async def setup_hook(self):
        """Bot å•Ÿå‹•æ™‚çš„è¨­å®š"""
        # å•Ÿå‹•å·¥ä½œåŸ·è¡Œç·’
        self.worker = DownloadWorker(self)
        self.worker.start()
        logger.info("Bot setup å®Œæˆï¼Œä¸‹è¼‰åŸ·è¡Œç·’å·²å•Ÿå‹•")
    
    async def on_guild_join(self, guild):
        """åŠ å…¥æ–°ä¼ºæœå™¨æ™‚åŒæ­¥æŒ‡ä»¤"""
        try:
            self.tree.copy_global_to(guild=guild)
            synced = await self.tree.sync(guild=guild)
            logger.info(f"å·²åŒæ­¥ {len(synced)} å€‹æ–œç·šæŒ‡ä»¤åˆ°æ–°ä¼ºæœå™¨: {guild.name}")
        except Exception as e:
            logger.error(f"åŒæ­¥æ–œç·šæŒ‡ä»¤åˆ° {guild.name} å¤±æ•—: {e}")
    
    async def on_ready(self):
        """Bot é€£ç·šæˆåŠŸæ™‚è§¸ç™¼"""
        logger.info(f'Bot å·²ç™»å…¥: {self.user.name} (ID: {self.user.id})')
        logger.info(f'å·²é€£æ¥åˆ° {len(self.guilds)} å€‹ä¼ºæœå™¨')
        
        # åŒæ­¥æ–œç·šæŒ‡ä»¤åˆ°æ‰€æœ‰å·²åŠ å…¥çš„ä¼ºæœå™¨ï¼ˆå³æ™‚ç”Ÿæ•ˆï¼‰
        try:
            for guild in self.guilds:
                self.tree.copy_global_to(guild=guild)
                synced = await self.tree.sync(guild=guild)
                logger.info(f"âœ… å·²åŒæ­¥ {len(synced)} å€‹æ–œç·šæŒ‡ä»¤åˆ°: {guild.name}")
        except Exception as e:
            logger.error(f"åŒæ­¥æ–œç·šæŒ‡ä»¤å¤±æ•—: {e}")
        
        # è¨­å®šç‹€æ…‹
        await self.change_presence(
            activity=discord.Activity(
                type=discord.ActivityType.watching,
                name="#hentaifetcher"
            )
        )
        
        # é¡¯ç¤ºå°ˆç”¨é »é“è¨­å®š
        logger.info(f"å°ˆç”¨é »é“åç¨±: {DEDICATED_CHANNEL_NAMES}")
        logger.info("âœ… Bot å·²å°±ç·’ï¼åœ¨å°ˆç”¨é »é“ç›´æ¥è²¼ç¶²å€æˆ–æ•¸å­—å³å¯ä¸‹è¼‰")
    
    async def on_message(self, message):
        """è™•ç†è¨Šæ¯ - æ”¯æ´å°ˆç”¨é »é“ï¼ˆä¸éœ€ !dlï¼‰å’Œå‚³çµ±æŒ‡ä»¤æ¨¡å¼"""
        # å¿½ç•¥ Bot è‡ªå·±çš„è¨Šæ¯
        if message.author.bot:
            return
        
        # è¨Šæ¯å»é‡ - é¿å…é‡è¤‡è™•ç†
        if is_message_processed(message.id):
            print(f"[DEBUG] è·³éé‡è¤‡è¨Šæ¯: {message.id}", flush=True)
            return
        
        content = message.content.strip()
        
        # å¿½ç•¥ç©ºè¨Šæ¯
        if not content:
            return
        
        # æª¢æŸ¥æ˜¯å¦åœ¨å°ˆç”¨é »é“ä¸­
        is_dedicated_channel = (
            message.channel.name.lower() in [n.lower() for n in DEDICATED_CHANNEL_NAMES] or
            message.channel.id in DEDICATED_CHANNEL_IDS
        )
        
        # Debug: è¨˜éŒ„æ”¶åˆ°çš„è¨Šæ¯
        if is_dedicated_channel:
            print(f"[å°ˆç”¨é »é“] æ”¶åˆ°è¨Šæ¯ (ID:{message.id}): {repr(content[:100])}", flush=True)
        else:
            print(f"[DEBUG] æ”¶åˆ°è¨Šæ¯ (ID:{message.id}): {repr(content[:100])}", flush=True)
        
        # ===== å°ˆç”¨é »é“æ¨¡å¼ï¼šä¸éœ€è¦ !dl å‰ç¶´ =====
        if is_dedicated_channel:
            # å¿½ç•¥æ–œç·šæŒ‡ä»¤ï¼ˆç”± Discord è™•ç†ï¼‰
            if content.startswith('/'):
                return
            
            # å¿½ç•¥ ! å‰ç¶´ï¼ˆèˆŠæŒ‡ä»¤æ ¼å¼ï¼Œæç¤ºç”¨æˆ¶ä½¿ç”¨æ–œç·šæŒ‡ä»¤ï¼‰
            if content.startswith('!'):
                await message.channel.send("ğŸ’¡ è«‹ä½¿ç”¨æ–œç·šæŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼š`/help`ã€`/search`")
                return
            
            # test æ¨¡å¼ - å¼·åˆ¶é‡æ–°ä¸‹è¼‰
            content_lower = content.lower().strip()
            if content_lower.startswith('test ') or content_lower == 'test':
                test_content = content[4:].strip() if len(content) > 4 else ''
                if not test_content:
                    await message.channel.send(
                        "ğŸ§ª **Test æ¨¡å¼ä½¿ç”¨æ–¹å¼ï¼ˆå¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼‰**\n"
                        "```\n"
                        "test 421633\n"
                        "```\n"
                        "âš ï¸ æ­¤æ¨¡å¼æœƒè·³éé‡è¤‡æª¢æŸ¥"
                    )
                    return
                
                # è§£æ test å…§å®¹
                test_urls = parse_input_to_urls(test_content)
                if not test_urls:
                    await message.channel.send(f"âš ï¸ ç„¡æ³•è§£æ: `{test_content[:50]}`")
                    return
                
                # åŠ å…¥ä½‡åˆ—ï¼ˆtest æ¨¡å¼ï¼‰
                queue_size = download_queue.qsize() + len(test_urls)
                gallery_ids = []
                for url in test_urls:
                    match = re.search(r'/g/(\d+)', url)
                    if match:
                        gallery_ids.append(match.group(1))
                
                if len(test_urls) == 1 and gallery_ids:
                    await message.channel.send(f"ğŸ§ª **#{gallery_ids[0]}** å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ“Š ä½‡åˆ—: {queue_size}")
                    batch_id = None
                else:
                    id_list = ", ".join([f"`{gid}`" for gid in gallery_ids[:10]])
                    await message.channel.send(f"ğŸ§ª **{len(gallery_ids)}** å€‹å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
                    # å¤šå€‹ä¸‹è¼‰å•Ÿç”¨æ‰¹æ¬¡è¿½è¹¤
                    batch_id = generate_batch_id()
                    init_batch(batch_id, len(test_urls), message.channel.id, gallery_ids)
                
                for url in test_urls:
                    download_queue.put((url, message.channel.id, None, True, batch_id))
                
                logger.info(f"[å°ˆç”¨é »é“] æ–°å¢ {len(test_urls)} å€‹ TEST ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {message.author})" + (f" [æ‰¹æ¬¡: {batch_id}]" if batch_id else ""))
                return
            
            # è™•ç†ä¸‹è¼‰è«‹æ±‚ï¼ˆç›´æ¥è²¼è™Ÿç¢¼æˆ–ç¶²å€ï¼‰
            await self.handle_direct_download(message, content)
            return
        
        # ===== éå°ˆç”¨é »é“ï¼šæç¤ºä½¿ç”¨æ–œç·šæŒ‡ä»¤ =====
        if content.startswith('!'):
            await message.channel.send("ğŸ’¡ è«‹ä½¿ç”¨æ–œç·šæŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼š`/dl`ã€`/help`ã€`/search`")
            return
    
    async def handle_direct_download(self, message, content: str):
        """
        è™•ç†å°ˆç”¨é »é“ä¸­çš„ç›´æ¥ä¸‹è¼‰è«‹æ±‚
        ä¸éœ€è¦ ! å‰ç¶´ï¼Œç›´æ¥è²¼ç¶²å€ã€æ•¸å­—æˆ–æŒ‡ä»¤å³å¯
        """
        content_lower = content.lower().strip()
        
        # ===== è™•ç†æŒ‡ä»¤ï¼ˆä¸éœ€è¦ ! å‰ç¶´ï¼‰=====
        # help / h
        if content_lower in ['help', 'h']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('help')
            await self.invoke(ctx)
            return
        
        # queue / q
        if content_lower in ['queue', 'q']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('queue')
            await self.invoke(ctx)
            return
        
        # status
        if content_lower == 'status':
            ctx = await self.get_context(message)
            ctx.command = self.get_command('status')
            await self.invoke(ctx)
            return
        
        # ping
        if content_lower == 'ping':
            ctx = await self.get_context(message)
            ctx.command = self.get_command('ping')
            await self.invoke(ctx)
            return
        
        # version / v
        if content_lower in ['version', 'v']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('version')
            await self.invoke(ctx)
            return
        
        # list / ls / library
        if content_lower in ['list', 'ls', 'library']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('list')
            await self.invoke(ctx)
            return
        
        # cleanup / clean / dedup
        if content_lower in ['cleanup', 'clean', 'dedup']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('cleanup')
            await self.invoke(ctx)
            return
        
        # fixcover / fc / addcover
        if content_lower in ['fixcover', 'fc', 'addcover']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('fixcover')
            await self.invoke(ctx)
            return
        
        # random / rand / r [æ•°é‡]
        if content_lower.startswith('random ') or content_lower.startswith('rand ') or content_lower.startswith('r ') or content_lower in ['random', 'rand', 'r']:
            # æå–æ•°é‡å‚æ•°
            parts = content.split()
            count = 1
            if len(parts) > 1:
                try:
                    count = int(parts[1])
                except:
                    count = 1
            
            # ç›´æ¥è°ƒç”¨å‡½æ•°
            ctx = await self.get_context(message)
            await random_command(ctx, count)
            return
        
        # dl <å…§å®¹> - ä¹Ÿæ”¯æ´ä¸å¸¶ ! çš„ dl
        if content_lower.startswith('dl ') or content_lower == 'dl':
            content = content[2:].strip() if len(content) > 2 else ''
            if not content:
                await message.channel.send(
                    "ğŸ“– **ä¸‹è¼‰ä½¿ç”¨æ–¹å¼**\n"
                    "ç›´æ¥è²¼ç¶²å€æˆ–è™Ÿç¢¼å³å¯ï¼\n"
                    "```\n"
                    "421633\n"
                    "421633 607769 613358\n"
                    "https://nhentai.net/g/421633/\n"
                    "```"
                )
                return
        
        # test <å…§å®¹> - å¼·åˆ¶é‡æ–°ä¸‹è¼‰
        if content_lower.startswith('test ') or content_lower == 'test':
            test_content = content[4:].strip() if len(content) > 4 else ''
            if not test_content:
                await message.channel.send(
                    "ğŸ§ª **Test æ¨¡å¼ä½¿ç”¨æ–¹å¼ï¼ˆå¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼‰**\n"
                    "```\n"
                    "test 421633\n"
                    "test https://nhentai.net/g/421633/\n"
                    "```\n"
                    "âš ï¸ æ­¤æ¨¡å¼æœƒè·³éé‡è¤‡æª¢æŸ¥"
                )
                return
            
            # è§£æ test å…§å®¹
            test_urls = parse_input_to_urls(test_content)
            if not test_urls:
                await message.channel.send(f"âš ï¸ ç„¡æ³•è§£æ: `{test_content[:50]}`")
                return
            
            # åŠ å…¥ä½‡åˆ—ï¼ˆtest æ¨¡å¼ï¼‰
            queue_size = download_queue.qsize() + len(test_urls)
            gallery_ids = []
            for url in test_urls:
                match = re.search(r'/g/(\d+)', url)
                if match:
                    gallery_ids.append(match.group(1))
            
            if len(test_urls) == 1 and gallery_ids:
                await message.channel.send(f"ğŸ§ª **#{gallery_ids[0]}** å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ“Š ä½‡åˆ—: {queue_size}")
                batch_id = None
            else:
                id_list = ", ".join([f"`{gid}`" for gid in gallery_ids[:10]])
                await message.channel.send(f"ğŸ§ª **{len(gallery_ids)}** å€‹å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
                # å¤šå€‹ä¸‹è¼‰å•Ÿç”¨æ‰¹æ¬¡è¿½è¹¤
                batch_id = generate_batch_id()
                init_batch(batch_id, len(test_urls), message.channel.id, gallery_ids)
            
            for url in test_urls:
                download_queue.put((url, message.channel.id, None, True, batch_id))
            
            logger.info(f"[å°ˆç”¨é »é“] æ–°å¢ {len(test_urls)} å€‹ TEST ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {message.author})" + (f" [æ‰¹æ¬¡: {batch_id}]" if batch_id else ""))
            return
        
        # è§£æè¼¸å…¥
        parsed_urls = parse_input_to_urls(content)
        
        if not parsed_urls:
            # å¦‚æœç„¡æ³•è§£æï¼Œéœé»˜å¿½ç•¥ï¼ˆä¸ç™¼é€éŒ¯èª¤è¨Šæ¯ï¼Œé¿å…æ‰“æ“¾ï¼‰
            # ä½†å¦‚æœå…§å®¹çœ‹èµ·ä¾†åƒæ˜¯æƒ³è¦ä¸‹è¼‰ï¼ˆç´”æ•¸å­—æˆ–åŒ…å« nhentaiï¼‰ï¼Œçµ¦äºˆæç¤º
            if re.search(r'\d{4,7}', content) or 'nhentai' in content.lower():
                await message.channel.send(f"âš ï¸ ç„¡æ³•è§£æ: `{content[:50]}`\nè«‹ç¢ºèªæ ¼å¼æ­£ç¢ºï¼ˆä¾‹å¦‚: `607769` æˆ– `https://nhentai.net/g/607769/`ï¼‰")
            return
        
        # å»é™¤é‡è¤‡ URL (ä¾æ“š gallery_id)
        seen_ids = set()
        unique_urls = []
        for url in parsed_urls:
            match = re.search(r'/g/(\d+)', url)
            if match:
                gid = match.group(1)
                if gid not in seen_ids:
                    seen_ids.add(gid)
                    unique_urls.append(url)
            else:
                unique_urls.append(url)  # ç„¡æ³•è§£æçš„ä¿ç•™
        
        parsed_urls = unique_urls
        
        # é©—è­‰ä¸¦åŠ å…¥ä½‡åˆ—
        valid_urls = []
        invalid_urls = []
        already_exists = []
        
        # æ·»åŠ  reaction è¡¨ç¤ºè™•ç†ä¸­
        try:
            await message.add_reaction('â³')
        except:
            pass
        
        # ä¸‹è¼‰å‰å…ˆåŸ·è¡Œå¿«é€Ÿ reindex (é¦–å€‹ URL)
        first_check = True
        
        for url in parsed_urls:
            # æå– gallery ID
            match = re.search(r'/g/(\d+)', url)
            if match:
                gallery_id = match.group(1)
                
                # å…ˆæª¢æŸ¥æ˜¯å¦å·²ä¸‹è¼‰ (é¦–å€‹ URL æ™‚è§¸ç™¼ reindex)
                exists, exist_info = check_already_downloaded(gallery_id, do_reindex=first_check)
                first_check = False  # å¾ŒçºŒä¸å† reindex
                
                if exists:
                    already_exists.append((gallery_id, exist_info))
                    continue
                
                # é©—è­‰æ˜¯å¦å¯è¨ªå•
                is_valid, info = verify_nhentai_url(gallery_id)
                
                if is_valid:
                    valid_urls.append((url, gallery_id, info))
                else:
                    invalid_urls.append((gallery_id, info))
            else:
                invalid_urls.append((url, "ç„¡æ•ˆæ ¼å¼"))
        
        # ç§»é™¤è™•ç†ä¸­ reaction
        try:
            await message.remove_reaction('â³', self.user)
        except:
            pass
        
        # å›å ±å·²å­˜åœ¨çš„é …ç›®
        if already_exists:
            if len(already_exists) == 1:
                gid, info = already_exists[0]
                title = info.get('title', '')[:40]
                web_url = info.get('web_url', '')
                await message.channel.send(f"ğŸ“š **#{gid}** å·²å­˜åœ¨\nğŸ“– {title}\nğŸ”— {web_url}")
            else:
                exist_list = "\n".join([f"â€¢ `{gid}`: {info.get('title', '')[:30]}" for gid, info in already_exists[:5]])
                await message.channel.send(f"ğŸ“š **{len(already_exists)}** å€‹å·²å­˜åœ¨ï¼ˆè·³éï¼‰:\n{exist_list}")
        
        # è™•ç†ç„¡æ•ˆçš„ URL
        if invalid_urls:
            error_list = "\n".join([f"â€¢ `{id}`: {reason}" for id, reason in invalid_urls[:5]])
            await message.channel.send(f"âŒ ä»¥ä¸‹ç„¡æ³•ä¸‹è¼‰:\n{error_list}")
        
        # åŠ å…¥æœ‰æ•ˆçš„ URL
        if valid_urls:
            queue_size = download_queue.qsize() + len(valid_urls)
            gallery_id_list = [gid for _, gid, _ in valid_urls]
            
            # ç™¼é€ç°¡åŒ–çš„ç‹€æ…‹è¨Šæ¯ï¼ˆåªé¡¯ç¤ºè™Ÿç¢¼ï¼‰
            if len(valid_urls) == 1:
                _, gallery_id, _ = valid_urls[0]
                await message.channel.send(f"ğŸ“¥ **#{gallery_id}** å·²åŠ å…¥ä½‡åˆ—\nğŸ“Š ä½‡åˆ—: {queue_size}")
                batch_id = None
            else:
                id_list = ", ".join([f"`{gid}`" for _, gid, _ in valid_urls[:10]])
                await message.channel.send(f"ğŸ“¥ **{len(valid_urls)}** å€‹å·²åŠ å…¥ä½‡åˆ—\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
                # å¤šå€‹ä¸‹è¼‰å•Ÿç”¨æ‰¹æ¬¡è¿½è¹¤
                batch_id = generate_batch_id()
                init_batch(batch_id, len(valid_urls), message.channel.id, gallery_id_list)
            
            # æ·»åŠ æˆåŠŸ reaction åˆ°åŸå§‹è¨Šæ¯
            try:
                await message.add_reaction('âœ…')
            except:
                pass
            
            # åŠ å…¥ä½‡åˆ—ï¼ˆåŒ…å« batch_idï¼‰
            for url, gallery_id, title in valid_urls:
                download_queue.put((url, message.channel.id, None, False, batch_id))
            
            logger.info(f"[å°ˆç”¨é »é“] æ–°å¢ {len(valid_urls)} å€‹ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {message.author})" + (f" [æ‰¹æ¬¡: {batch_id}]" if batch_id else ""))
    
    async def on_command_error(self, ctx, error):
        """å…¨åŸŸéŒ¯èª¤è™•ç†"""
        if isinstance(error, commands.CommandNotFound):
            return  # å¿½ç•¥æœªçŸ¥æŒ‡ä»¤
        
        logger.error(f"æŒ‡ä»¤éŒ¯èª¤: {error}")
        await ctx.send(f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤: {str(error)}")


# å»ºç«‹ Bot å¯¦ä¾‹
bot = HentaiFetcherBot()


# ==================== æ–œç·šæŒ‡ä»¤ ====================

@bot.tree.command(name='dl', description='ä¸‹è¼‰ nhentai æœ¬å­')
@app_commands.describe(
    gallery_ids='ä¸€å€‹æˆ–å¤šå€‹ nhentai è™Ÿç¢¼ï¼Œç”¨ç©ºæ ¼åˆ†éš”',
    force='å¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼ˆè·³éé‡è¤‡æª¢æŸ¥ï¼‰'
)
async def dl_command(interaction: discord.Interaction, gallery_ids: str, force: bool = False):
    """ä¸‹è¼‰ nhentai æœ¬å­"""
    await interaction.response.defer()
    
    # è§£æè¼¸å…¥
    parsed_urls = parse_input_to_urls(gallery_ids)
    
    if not parsed_urls:
        await interaction.followup.send("âš ï¸ ç„¡æ³•è§£æè¼¸å…¥ã€‚è«‹æä¾›æœ‰æ•ˆçš„ nhentai è™Ÿç¢¼ã€‚")
        return
    
    # å»é™¤é‡è¤‡ URL (ä¾æ“š gallery_id)
    seen_ids = set()
    unique_urls = []
    for url in parsed_urls:
        match = re.search(r'/g/(\d+)', url)
        if match:
            gid = match.group(1)
            if gid not in seen_ids:
                seen_ids.add(gid)
                unique_urls.append(url)
        else:
            unique_urls.append(url)
    parsed_urls = unique_urls
    
    # å¦‚æœä¸æ˜¯å¼·åˆ¶æ¨¡å¼ï¼Œæª¢æŸ¥é‡è¤‡
    new_urls = []
    already_exists = []
    
    if not force:
        # ä¸‹è¼‰å‰å…ˆåŸ·è¡Œå¿«é€Ÿ reindex (é¦–å€‹ URL)
        first_check = True
        
        for url in parsed_urls:
            match = re.search(r'/g/(\d+)', url)
            if match:
                gallery_id = match.group(1)
                # é¦–å€‹ URL æ™‚è§¸ç™¼ reindex
                exists, info = check_already_downloaded(gallery_id, do_reindex=first_check)
                first_check = False
                
                if exists:
                    already_exists.append((gallery_id, info))
                else:
                    new_urls.append((url, gallery_id))
            else:
                new_urls.append((url, None))
        
        # å›å ±å·²å­˜åœ¨çš„é …ç›®
        if already_exists:
            if len(already_exists) == 1:
                gid, info = already_exists[0]
                title = info.get('title', '')[:40]
                web_url = info.get('web_url', '')
                await interaction.followup.send(f"ğŸ“š **#{gid}** å·²å­˜åœ¨\nğŸ“– {title}\nğŸ”— {web_url}")
            else:
                exist_list = "\n".join([f"â€¢ `{gid}`: {info.get('title', '')[:30]}" for gid, info in already_exists[:5]])
                await interaction.followup.send(f"ğŸ“š **{len(already_exists)}** å€‹å·²å­˜åœ¨ï¼ˆè·³éï¼‰:\n{exist_list}")
        
        if not new_urls:
            return
    else:
        new_urls = [(url, re.search(r'/g/(\d+)', url).group(1) if re.search(r'/g/(\d+)', url) else None) for url in parsed_urls]
    
    # åŠ å…¥ä½‡åˆ—
    queue_size = download_queue.qsize() + len(new_urls)
    gallery_id_list = [gid for _, gid in new_urls if gid]
    
    mode_str = "ï¼ˆå¼·åˆ¶æ¨¡å¼ï¼‰" if force else ""
    if len(new_urls) == 1 and gallery_id_list:
        await interaction.followup.send(f"ğŸ“¥ **#{gallery_id_list[0]}** å·²åŠ å…¥ä½‡åˆ—{mode_str}\nğŸ“Š ä½‡åˆ—: {queue_size}")
        # å–®å€‹ä¸‹è¼‰ä¸éœ€è¦æ‰¹æ¬¡è¿½è¹¤
        batch_id = None
    else:
        id_list = ", ".join([f"`{gid}`" for gid in gallery_id_list[:10]])
        await interaction.followup.send(f"ğŸ“¥ **{len(gallery_id_list)}** å€‹å·²åŠ å…¥ä½‡åˆ—{mode_str}\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
        # å¤šå€‹ä¸‹è¼‰å•Ÿç”¨æ‰¹æ¬¡è¿½è¹¤
        batch_id = generate_batch_id()
        init_batch(batch_id, len(new_urls), interaction.channel_id, gallery_id_list)
    
    # åŠ å…¥ä½‡åˆ—ï¼ˆåŒ…å« batch_idï¼‰
    for url, _ in new_urls:
        download_queue.put((url, interaction.channel_id, None, force, batch_id))
    
    logger.info(f"æ–°å¢ {len(new_urls)} å€‹ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {interaction.user})" + (f" [æ‰¹æ¬¡: {batch_id}]" if batch_id else ""))


@bot.tree.command(name='queue', description='æŸ¥çœ‹ä¸‹è¼‰ä½‡åˆ—ç‹€æ…‹')
async def queue_command(interaction: discord.Interaction):
    """æŸ¥çœ‹ä¸‹è¼‰ä½‡åˆ—"""
    size = download_queue.qsize()
    await interaction.response.send_message(f"ğŸ“Š ä½‡åˆ—ä¸­ç­‰å¾…ä»»å‹™: {size}")


@bot.tree.command(name='sync', description='å¼·åˆ¶åŒæ­¥æ–œç·šæŒ‡ä»¤ï¼ˆç®¡ç†å“¡å°ˆç”¨ï¼‰')
async def sync_command(interaction: discord.Interaction):
    """å¼·åˆ¶åŒæ­¥æ–œç·šæŒ‡ä»¤åˆ° Discord"""
    # æª¢æŸ¥æ¬Šé™ï¼ˆåªæœ‰ç®¡ç†å“¡å¯ä»¥ä½¿ç”¨ï¼‰
    if not interaction.user.guild_permissions.administrator:
        await interaction.response.send_message("âŒ æ­¤æŒ‡ä»¤åƒ…é™ç®¡ç†å“¡ä½¿ç”¨", ephemeral=True)
        return
    
    await interaction.response.defer(ephemeral=True)
    
    try:
        # åŒæ­¥åˆ°ç•¶å‰ä¼ºæœå™¨
        bot.tree.copy_global_to(guild=interaction.guild)
        synced = await bot.tree.sync(guild=interaction.guild)
        await interaction.followup.send(f"âœ… å·²åŒæ­¥ **{len(synced)}** å€‹æ–œç·šæŒ‡ä»¤åˆ°æ­¤ä¼ºæœå™¨\nğŸ’¡ æ–°åƒæ•¸æ‡‰è©²ç«‹å³ç”Ÿæ•ˆ", ephemeral=True)
        logger.info(f"æ‰‹å‹•åŒæ­¥æŒ‡ä»¤åˆ° {interaction.guild.name}: {len(synced)} å€‹")
    except Exception as e:
        await interaction.followup.send(f"âŒ åŒæ­¥å¤±æ•—: {e}", ephemeral=True)
        logger.error(f"æ‰‹å‹•åŒæ­¥æŒ‡ä»¤å¤±æ•—: {e}")


@bot.tree.command(name='ping', description='æ¸¬è©¦æ©Ÿå™¨äººé€£ç·š')
async def ping_command(interaction: discord.Interaction):
    """æ¸¬è©¦é€£ç·š"""
    latency = round(bot.latency * 1000)
    await interaction.response.send_message(f"ğŸ“ Pong! å»¶é²: {latency}ms")


@bot.tree.command(name='version', description='é¡¯ç¤ºæ©Ÿå™¨äººç‰ˆæœ¬')
async def version_command(interaction: discord.Interaction):
    """é¡¯ç¤ºç‰ˆæœ¬"""
    await interaction.response.send_message(f"ğŸ“¦ HentaiFetcher ç‰ˆæœ¬: **{VERSION}**")


@bot.tree.command(name='status', description='é¡¯ç¤ºæ©Ÿå™¨äººç‹€æ…‹')
async def status_command(interaction: discord.Interaction):
    """é¡¯ç¤ºç‹€æ…‹"""
    embed = discord.Embed(
        title="ğŸ“Š HentaiFetcher Status",
        color=discord.Color.blue()
    )
    embed.add_field(name="ä½‡åˆ—ä»»å‹™", value=str(download_queue.qsize()), inline=True)
    embed.add_field(name="å»¶é²", value=f"{round(bot.latency * 1000)}ms", inline=True)
    embed.add_field(name="ä¼ºæœå™¨æ•¸", value=str(len(bot.guilds)), inline=True)
    
    # é¡¯ç¤ºç›®å‰ä¸‹è¼‰ç‹€æ…‹
    if bot.worker and bot.worker.current_task:
        match = re.search(r'/g/(\d+)', bot.worker.current_task)
        task_id = match.group(1) if match else "..."
        embed.add_field(name="ç›®å‰ä¸‹è¼‰", value=f"ğŸ”„ `{task_id}`", inline=True)
    else:
        embed.add_field(name="ç›®å‰ä¸‹è¼‰", value="â³ ç­‰å¾…ä¸­", inline=True)
    
    embed.set_footer(text="ä½¿ç”¨ /dl <è™Ÿç¢¼> é–‹å§‹ä¸‹è¼‰")
    
    await interaction.response.send_message(embed=embed)


@bot.tree.command(name='list', description='åˆ—å‡ºæ‰€æœ‰å·²ä¸‹è¼‰çš„æœ¬å­ï¼ˆåŒ…å« Eagle Libraryï¼‰')
async def list_command(interaction: discord.Interaction):
    """åˆ—å‡ºæ‰€æœ‰å·²ä¸‹è¼‰çš„æœ¬å­ï¼ˆåˆ†é é¡¯ç¤ºï¼‰"""
    await interaction.response.defer()
    
    try:
        from urllib.parse import quote
        from eagle_library import EagleLibrary
        from bot.views import PaginatedListView
        
        # æ”¶é›†æ‰€æœ‰é …ç›®
        items = []  # (gallery_id, title, source)
        seen_ids = set()
        
        # 1. å¾ Eagle Library ç²å–
        try:
            eagle = EagleLibrary()
            eagle_items = eagle.list_all()
            for item in eagle_items:
                nid = item.get('nhentai_id', '')
                title = item.get('title', item.get('folder_name', ''))
                if nid:
                    seen_ids.add(nid)
                    items.append((nid, title, 'eagle'))
        except Exception as e:
            logger.debug(f"Eagle Library è¼‰å…¥å¤±æ•—: {e}")
        
        # 2. å¾ downloads è³‡æ–™å¤¾ç²å–ï¼ˆè·³éå·²åœ¨ Eagle ä¸­çš„ï¼‰
        if DOWNLOAD_DIR.exists():
            folders = [f for f in DOWNLOAD_DIR.iterdir() if f.is_dir()]
            
            for folder in folders:
                folder_name = folder.name
                
                # å˜—è©¦å¾ metadata.json ç²å– gallery_id
                metadata_path = folder / "metadata.json"
                gallery_id = ""
                title = folder_name
                if metadata_path.exists():
                    try:
                        with open(metadata_path, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                            # å„ªå…ˆå¾ gallery_id ç²å–
                            gallery_id = metadata.get('gallery_id', '')
                            # å¦‚æœæ²’æœ‰ï¼Œå¾ URL æå–
                            if not gallery_id:
                                url = metadata.get('url', '')
                                match = re.search(r'/g/(\d+)', url)
                                if match:
                                    gallery_id = match.group(1)
                            # å–å¾—æ¨™é¡Œ
                            title = metadata.get('name', folder_name)
                    except:
                        pass
                
                # åªåŠ å…¥ä¸åœ¨ Eagle ä¸­çš„
                if gallery_id and gallery_id not in seen_ids:
                    items.append((gallery_id, title, 'downloads'))
                    seen_ids.add(gallery_id)
                elif not gallery_id:
                    items.append(('', title, 'downloads'))
        
        if not items:
            await interaction.followup.send("ğŸ“‚ ç›®å‰æ²’æœ‰ä»»ä½•æœ¬å­")
            return
        
        # æŒ‰è™Ÿç¢¼æ’åºï¼ˆå¾å°åˆ°å¤§ï¼‰
        items.sort(key=lambda x: int(x[0]) if x[0].isdigit() else 0)
        
        # çµ±è¨ˆä¾†æºæ•¸é‡
        eagle_count = sum(1 for _, _, src in items if src == 'eagle')
        downloads_count = sum(1 for _, _, src in items if src == 'downloads')
        
        # å»ºç«‹åˆ†é è¦–åœ–
        view = PaginatedListView(
            items=items,
            eagle_count=eagle_count,
            downloads_count=downloads_count
        )
        
        # ç™¼é€å¸¶æœ‰åˆ†é çš„åµŒå…¥è¨Šæ¯
        await interaction.followup.send(embed=view.get_embed(), view=view)
        
    except Exception as e:
        logger.error(f"åˆ—å‡ºå¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ åˆ—å‡ºå¤±æ•—: {e}")


def get_all_downloads_items() -> List[Dict[str, Any]]:
    """
    ç²å– downloads è³‡æ–™å¤¾ä¸­æ‰€æœ‰æœ¬å­çš„è³‡è¨Š
    
    Returns:
        åŒ…å«æœ¬å­è³‡è¨Šçš„åˆ—è¡¨
    """
    results = []
    
    if not DOWNLOAD_DIR.exists():
        return results
    
    for folder in DOWNLOAD_DIR.iterdir():
        if not folder.is_dir():
            continue
        
        metadata_path = folder / "metadata.json"
        if not metadata_path.exists():
            continue
        
        try:
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # å¾ url æå– gallery_id
            url = metadata.get('url', '')
            match = re.search(r'/g/(\d+)', url)
            gallery_id = match.group(1) if match else folder.name
            
            results.append({
                'title': metadata.get('name', folder.name),
                'nhentai_id': gallery_id,
                'tags': metadata.get('tags', []),
                'folder_path': str(folder),
                'url': url,
                'annotation': metadata.get('annotation', ''),
                'source': 'downloads'
            })
        except Exception as e:
            logger.debug(f"è®€å– metadata å¤±æ•— ({folder.name}): {e}")
    
    return results


def search_in_downloads(query: str) -> List[Dict[str, Any]]:
    """
    åœ¨ downloads è³‡æ–™å¤¾ä¸­æœå°‹æœ¬å­
    
    Args:
        query: æœå°‹é—œéµå­—ï¼ˆæ”¯æ´ IDã€æ¨™é¡Œã€ä½œè€…ã€åŸä½œç­‰ï¼‰
    
    Returns:
        ç¬¦åˆæ¢ä»¶çš„æœ¬å­åˆ—è¡¨
    """
    import unicodedata
    
    all_items = get_all_downloads_items()
    results = []
    
    # æ¨™æº–åŒ–æŸ¥è©¢å­—ä¸²ï¼ˆç§»é™¤ç©ºç™½ã€è½‰å°å¯«ï¼‰
    query_normalized = unicodedata.normalize('NFKC', query.lower().strip())
    query_parts = query_normalized.split()  # åˆ†å‰²æˆå¤šå€‹é—œéµå­—
    
    for item in all_items:
        # æ§‹å»ºå¯æœå°‹çš„æ–‡å­—
        searchable_parts = [
            item.get('title', ''),
            item.get('nhentai_id', ''),
            ' '.join(item.get('tags', [])),
            item.get('annotation', '')
        ]
        searchable_text = unicodedata.normalize('NFKC', ' '.join(searchable_parts).lower())
        
        # æª¢æŸ¥æ˜¯å¦æ‰€æœ‰é—œéµå­—éƒ½åŒ¹é…
        if all(part in searchable_text for part in query_parts):
            results.append(item)
    
    return results


def find_item_by_id(gallery_id: str) -> Optional[Dict[str, Any]]:
    """
    ç”¨ ID åœ¨é›™ä¾†æºä¸­æŸ¥æ‰¾æœ¬å­
    
    Args:
        gallery_id: nhentai Gallery ID
    
    Returns:
        æ‰¾åˆ°çš„æœ¬å­è³‡è¨Šï¼Œæˆ– None
    """
    # 1. å…ˆæŸ¥ Eagle Library
    try:
        from eagle_library import EagleLibrary
        eagle = EagleLibrary()
        result = eagle.find_by_nhentai_id(gallery_id)
        if result:
            result['source'] = 'eagle'
            return result
    except:
        pass
    
    # 2. å†æŸ¥ downloads è³‡æ–™å¤¾
    all_downloads = get_all_downloads_items()
    for item in all_downloads:
        if item.get('nhentai_id') == gallery_id:
            return item
    
    return None


def parse_annotation_comments(annotation: str) -> List[Dict[str, str]]:
    """
    å¾ annotation ä¸­æå–ç”¨æˆ¶è©•è«–
    
    Args:
        annotation: metadata ä¸­çš„ annotation å­—ä¸²
    
    Returns:
        è©•è«–åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ åŒ…å« user å’Œ content
    """
    comments = []
    if not annotation:
        return comments
    
    # æŸ¥æ‰¾è©•è«–å€å¡Š
    if 'ğŸ’¬ ç”¨æˆ¶è©•è«–:' not in annotation:
        return comments
    
    comment_section = annotation.split('ğŸ’¬ ç”¨æˆ¶è©•è«–:')[1]
    
    # æˆªå–åˆ°ä¸‹ä¸€å€‹æ™‚é–“æˆ³è¨˜æˆ–çµå°¾
    if 'â°' in comment_section:
        comment_section = comment_section.split('â°')[0]
    
    lines = comment_section.split('\n')
    current_user = None
    current_content = []
    
    for line in lines:
        line = line.strip()
        if not line:
            # ç©ºè¡Œï¼šå„²å­˜ç•¶å‰è©•è«–
            if current_user and current_content:
                comments.append({
                    'user': current_user,
                    'content': ' '.join(current_content)
                })
                current_user = None
                current_content = []
            continue
        
        # è·³é "é‚„æœ‰ X å‰‡è©•è«–" 
        if line.startswith('...') and 'å‰‡è©•è«–' in line:
            continue
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºç”¨æˆ¶åè¡Œ [username] (time ago)
        if line.startswith('[') and ']' in line:
            # å…ˆå„²å­˜ä¸Šä¸€å€‹è©•è«–
            if current_user and current_content:
                comments.append({
                    'user': current_user,
                    'content': ' '.join(current_content)
                })
            current_user = line
            current_content = []
        else:
            # é€™æ˜¯è©•è«–å…§å®¹
            current_content.append(line)
    
    # å„²å­˜æœ€å¾Œä¸€å€‹è©•è«–
    if current_user and current_content:
        comments.append({
            'user': current_user,
            'content': ' '.join(current_content)
        })
    
    return comments


def get_random_from_downloads(count: int = 1) -> List[Dict[str, Any]]:
    """
    å¾ downloads è³‡æ–™å¤¾éš¨æ©Ÿé¸å–æœ¬å­
    
    Args:
        count: è¦é¸å–çš„æ•¸é‡
    
    Returns:
        åŒ…å«æœ¬å­è³‡è¨Šçš„åˆ—è¡¨
    """
    import random
    import secrets
    
    results = []
    
    if not DOWNLOAD_DIR.exists():
        return results
    
    # ç²å–æ‰€æœ‰æœ‰ metadata.json çš„å­è³‡æ–™å¤¾
    valid_folders = []
    for folder in DOWNLOAD_DIR.iterdir():
        if folder.is_dir():
            metadata_path = folder / "metadata.json"
            if metadata_path.exists():
                valid_folders.append(folder)
    
    if not valid_folders:
        return results
    
    # é™åˆ¶æ•¸é‡
    count = min(count, len(valid_folders))
    
    # ä½¿ç”¨ secrets æ¨¡çµ„é€²è¡ŒåŠ å¯†å®‰å…¨çš„éš¨æ©Ÿé¸å–ï¼ˆæ›´åŠ éš¨æ©Ÿï¼‰
    selected_indices = set()
    while len(selected_indices) < count:
        idx = secrets.randbelow(len(valid_folders))
        selected_indices.add(idx)
    
    selected_folders = [valid_folders[i] for i in selected_indices]
    
    for folder in selected_folders:
        metadata_path = folder / "metadata.json"
        try:
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # å¾ url æå– gallery_id
            url = metadata.get('url', '')
            match = re.search(r'/g/(\d+)', url)
            gallery_id = match.group(1) if match else folder.name
            
            results.append({
                'title': metadata.get('name', folder.name),
                'nhentai_id': gallery_id,
                'tags': metadata.get('tags', []),
                'folder_path': str(folder),
                'url': url,
                'source': 'downloads'
            })
        except Exception as e:
            logger.debug(f"è®€å– metadata å¤±æ•— ({folder.name}): {e}")
    
    return results


@bot.tree.command(name='random', description='éš¨æ©Ÿé¡¯ç¤ºæœ¬å­ï¼ˆé è¨­é›™ä¾†æºï¼‰')
@app_commands.describe(
    count='é¡¯ç¤ºæ•¸é‡ (1-5)',
    source='ä¾†æºï¼šall=å…¨éƒ¨(é è¨­), eagle=Eagle Library, downloads=ä¸‹è¼‰è³‡æ–™å¤¾'
)
@app_commands.choices(source=[
    app_commands.Choice(name='ğŸ”€ å…¨éƒ¨ (é è¨­)', value='all'),
    app_commands.Choice(name='ğŸ¦… Eagle Library', value='eagle'),
    app_commands.Choice(name='ğŸ“ ä¸‹è¼‰è³‡æ–™å¤¾', value='downloads'),
])
async def random_command(interaction: discord.Interaction, count: int = 1, source: str = 'all'):
    """éš¨æ©Ÿé¡¯ç¤ºæœ¬å­"""
    await interaction.response.defer()
    
    try:
        from eagle_library import EagleLibrary
        from pathlib import Path
        import re
        import secrets
        
        # é™åˆ¶æ•¸é‡
        count = max(1, min(count, 5))  # 1-5 æœ¬
        
        selected = []
        
        if source == 'eagle':
            # å¾ Eagle Library éš¨æ©Ÿé¸å–
            eagle = EagleLibrary()
            selected = eagle.get_random(count)
            if not selected:
                await interaction.followup.send("ğŸ“‚ Eagle Library ä¸­æ²’æœ‰ä»»ä½•æœ¬å­")
                return
        
        elif source == 'downloads':
            # å¾ downloads è³‡æ–™å¤¾éš¨æ©Ÿé¸å–
            selected = get_random_from_downloads(count)
            if not selected:
                await interaction.followup.send("ğŸ“‚ ä¸‹è¼‰è³‡æ–™å¤¾ä¸­æ²’æœ‰ä»»ä½•æœ¬å­")
                return
        
        elif source == 'all':
            # å¾å…©å€‹ä¾†æºåˆä½µå¾Œéš¨æ©Ÿé¸å–
            eagle = EagleLibrary()
            eagle_items = eagle.list_all()
            downloads_items = get_random_from_downloads(100)  # å…ˆå–å¾—æ‰€æœ‰ downloads
            
            # åˆä½µå…©å€‹ä¾†æºï¼ˆå»é‡ï¼‰
            all_items = []
            seen_ids = set()
            
            for item in eagle_items:
                nid = item.get('nhentai_id')
                if nid and nid not in seen_ids:
                    seen_ids.add(nid)
                    # è½‰æ›æ ¼å¼ä»¥ä¾¿å¾ŒçºŒè™•ç†
                    eagle_result = eagle.find_by_nhentai_id(nid)
                    if eagle_result:
                        eagle_result['source'] = 'eagle'
                        all_items.append(eagle_result)
            
            for item in downloads_items:
                nid = item.get('nhentai_id')
                if nid and nid not in seen_ids:
                    seen_ids.add(nid)
                    item['source'] = 'downloads'
                    all_items.append(item)
            
            if not all_items:
                await interaction.followup.send("ğŸ“‚ æ²’æœ‰ä»»ä½•æœ¬å­å¯ä¾›é¸æ“‡")
                return
            
            # ä½¿ç”¨ secrets é€²è¡Œæ›´éš¨æ©Ÿçš„é¸å–
            count = min(count, len(all_items))
            selected_indices = set()
            while len(selected_indices) < count:
                idx = secrets.randbelow(len(all_items))
                selected_indices.add(idx)
            selected = [all_items[i] for i in selected_indices]
        
        if not selected:
            await interaction.followup.send("ğŸ“‚ æ²’æœ‰ä»»ä½•æœ¬å­å¯ä¾›é¸æ“‡")
            return
        
        # é€æœ¬é¡¯ç¤ºï¼ˆå…ˆå°é¢ï¼Œå†è³‡è¨Šï¼‰- é¿å…é †åºéŒ¯äº‚
        from urllib.parse import quote
        
        for idx, item in enumerate(selected):
            title = item.get('title', 'æœªçŸ¥')
            gallery_id = item.get('nhentai_id', 'æœªçŸ¥')
            web_url = item.get('web_url', '')
            tags = item.get('tags', [])
            folder_path = item.get('folder_path', '')
            item_source = item.get('source', 'eagle')
            
            # è§£æ tags
            artists = [tag.replace('artist:', '') for tag in tags if isinstance(tag, str) and tag.startswith('artist:')]
            parodies = [tag.replace('parody:', '') for tag in tags if isinstance(tag, str) and tag.startswith('parody:')]
            groups = [tag.replace('group:', '') for tag in tags if isinstance(tag, str) and tag.startswith('group:')]
            languages = [tag.replace('language:', '') for tag in tags if isinstance(tag, str) and tag.startswith('language:')]
            other_tags = [tag for tag in tags if isinstance(tag, str) and not any(tag.startswith(prefix) for prefix in ['artist:', 'parody:', 'group:', 'language:', 'type:'])]
            
            # ===== 1. å…ˆç™¼é€å°é¢åœ–ç‰‡ =====
            cover_sent = False
            if folder_path:
                try:
                    folder = Path(folder_path)
                    # å°é¢æª”åå„ªå…ˆé †åº
                    for cover_name in ['cover.jpg', 'cover.png', 'cover.webp', 'thumbnail.png']:
                        cover_path = folder / cover_name
                        if cover_path.exists():
                            file = discord.File(str(cover_path), filename=cover_name)
                            if idx == 0:
                                await interaction.followup.send(file=file)
                            else:
                                await interaction.channel.send(file=file)
                            cover_sent = True
                            break
                    
                    # å¦‚æœæ²’æ‰¾åˆ°å°é¢ï¼Œæ‰¾ç¬¬ä¸€å¼µåœ–ç‰‡
                    if not cover_sent:
                        for ext in ['*.jpg', '*.jpeg', '*.png', '*.webp']:
                            images = list(folder.glob(ext))
                            if images:
                                images.sort(key=lambda x: x.name)
                                file = discord.File(str(images[0]), filename=images[0].name)
                                if idx == 0:
                                    await interaction.followup.send(file=file)
                                else:
                                    await interaction.channel.send(file=file)
                                cover_sent = True
                                break
                except Exception as e:
                    logger.debug(f"å°é¢ç™¼é€å¤±æ•—: {e}")
            
            # ===== 2. å†ç™¼é€è³‡æ–™è¨Šæ¯ =====
            msg_lines = []
            
            # ä¾†æºæ¨™è¨˜
            source_emoji = "ğŸ¦…" if item_source == 'eagle' else "ğŸ“"
            
            # è™Ÿç¢¼
            msg_lines.append(f"{source_emoji} **#{gallery_id}**")
            
            # æ¨™é¡Œå…§åµŒé€£çµ (emoji åœ¨é€£çµå¤–éƒ¨ä»¥ç¢ºä¿ markdown æ ¼å¼æ­£ç¢º)
            if item_source == 'eagle' and web_url:
                msg_lines.append(f"ğŸ“– [{title}]({web_url})")
            elif item_source == 'downloads' and gallery_id:
                pdf_web_url = f"{PDF_WEB_BASE_URL}/{quote(str(gallery_id))}/{quote(str(gallery_id))}.pdf"
                msg_lines.append(f"ğŸ“– [{title}]({pdf_web_url})")
            else:
                msg_lines.append(f"ğŸ“– **{title}**")
            
            msg_lines.append("")  # ç©ºè¡Œ
            
            # ===== é¡¯ç¤ºæ‰€æœ‰ metadata =====
            # ä¾†æº
            msg_lines.append(f"ğŸ“¦ ä¾†æº: {'Eagle Library' if item_source == 'eagle' else 'ä¸‹è¼‰è³‡æ–™å¤¾'}")
            
            # åŸºæœ¬è³‡è¨Š
            if artists:
                msg_lines.append(f"âœï¸ ä½œè€…: {', '.join(artists)}")
            if groups:
                msg_lines.append(f"ğŸ‘¥ ç¤¾åœ˜: {', '.join(groups)}")
            if parodies:
                msg_lines.append(f"ğŸ¬ åŸä½œ: {', '.join(parodies)}")
            if languages:
                msg_lines.append(f"ğŸŒ èªè¨€: {', '.join(languages)}")
            
            # è§’è‰²
            characters = [tag.replace('character:', '') for tag in tags if isinstance(tag, str) and tag.startswith('character:')]
            if characters:
                msg_lines.append(f"ğŸ‘¤ è§’è‰²: {', '.join(characters)}")
            
            # é¡å‹
            types = [tag.replace('type:', '') for tag in tags if isinstance(tag, str) and tag.startswith('type:')]
            if types:
                msg_lines.append(f"ğŸ“ é¡å‹: {', '.join(types)}")
            
            # ä½¿ç”¨è€…è©•è«– (å¾ annotation ä¸­æå–ï¼Œé¡¯ç¤ºå…¨éƒ¨)
            annotation = item.get('annotation', '')
            if annotation:
                comments = parse_annotation_comments(annotation)
                if comments:
                    msg_lines.append("")
                    msg_lines.append("ğŸ’¬ è©•è«–:")
                    for c in comments:
                        msg_lines.append(f"  **{c['user']}**")
                        if c['content']:
                            msg_lines.append(f"  {c['content']}")
            
            # Tags (é¡¯ç¤ºå…¨éƒ¨æ¨™ç±¤)
            if other_tags:
                msg_lines.append(f"")
                msg_lines.append(f"ğŸ·ï¸ æ¨™ç±¤: {', '.join([f'`{tag}`' for tag in other_tags])}")
            
            # ç™¼é€è³‡æ–™è¨Šæ¯
            final_msg = "\n".join(msg_lines)
            if len(final_msg) > 1900:
                final_msg = final_msg[:1900] + "..."
            
            # å»ºç«‹éš¨æ©Ÿçµæœäº’å‹•è¦–åœ–
            from bot.views import RandomResultView
            view = RandomResultView(
                gallery_id=gallery_id,
                title=title,
                item_source=item_source,
                web_url=web_url,
                artists=artists,
                source_filter=source
            )
            
            # ç¢ºä¿å°é¢å·²ç™¼é€æ‰ç™¼è³‡è¨Šï¼ˆé †åºæ­£ç¢ºï¼‰
            await interaction.channel.send(final_msg, view=view)
    
    except ImportError:
        await interaction.followup.send("âŒ Eagle Library æ¨¡çµ„æœªå®‰è£")
    except Exception as e:
        logger.error(f"éš¨æ©Ÿé¡¯ç¤ºå¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ éš¨æ©Ÿé¡¯ç¤ºå¤±æ•—: {e}")


@bot.tree.command(name='fixcover', description='ç‚ºå·²ä¸‹è¼‰çš„æœ¬å­è£œå……å°é¢')
async def fixcover_command(interaction: discord.Interaction):
    """ç‚ºå·²æœ‰çš„æœ¬å­è£œå……å°é¢"""
    await interaction.response.defer()
    
    try:
        if not DOWNLOAD_DIR.exists():
            await interaction.followup.send("ğŸ“‚ ä¸‹è¼‰è³‡æ–™å¤¾ä¸å­˜åœ¨")
            return
        
        await interaction.followup.send("ğŸ” é–‹å§‹æƒæä¸¦è£œå……å°é¢...")
        
        folders = [f for f in DOWNLOAD_DIR.iterdir() if f.is_dir()]
        fixed_count = 0
        skipped_count = 0
        fallback_count = 0  # ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢çš„æ•¸é‡
        failed_count = 0
        
        for folder in folders:
            # æª¢æŸ¥æ˜¯å¦å·²æœ‰å°é¢
            has_cover = any(list(folder.glob(f"cover.{ext}")) for ext in ['jpg', 'jpeg', 'png', 'gif', 'webp'])
            
            if has_cover:
                skipped_count += 1
                continue
            
            # å¾ metadata.json ç²å– gallery_id
            metadata_path = folder / "metadata.json"
            gallery_id = ""
            
            if metadata_path.exists():
                try:
                    with open(metadata_path, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                        # å¾ url æå– gallery_id
                        url = metadata.get('url', '')
                        match = re.search(r'/g/(\d+)', url)
                        if match:
                            gallery_id = match.group(1)
                except Exception as e:
                    logger.error(f"è®€å– metadata å¤±æ•— ({folder.name}): {e}")
            
            cover_success = False
            
            if gallery_id:
                # å˜—è©¦å¾ nhentai ä¸‹è¼‰å°é¢
                if download_nhentai_cover(gallery_id, folder):
                    fixed_count += 1
                    cover_success = True
                    logger.info(f"è£œå……å°é¢æˆåŠŸ (nhentai å°é¢): {folder.name}")
                else:
                    # å°é¢ä¸‹è¼‰å¤±æ•—ï¼Œå˜—è©¦ä¸‹è¼‰ç¬¬ä¸€é ä½œç‚ºå°é¢
                    await asyncio.sleep(0.3)  # çŸ­æš«å»¶é²é¿å…è«‹æ±‚å¤ªå¿«
                    if download_nhentai_first_page(gallery_id, folder):
                        fallback_count += 1
                        cover_success = True
                        logger.info(f"è£œå……å°é¢æˆåŠŸ (nhentai ç¬¬ä¸€é ): {folder.name}")
                # é¿å…è«‹æ±‚å¤ªé »ç¹
                await asyncio.sleep(0.5)
            
            # å¦‚æœå¾ nhentai éƒ½å¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨è³‡æ–™å¤¾å…§çš„ç¬¬ä¸€å¼µåœ–ç‰‡
            if not cover_success:
                first_image = get_first_image_as_cover(folder)
                if first_image:
                    fallback_count += 1
                    cover_success = True
                    logger.info(f"è£œå……å°é¢æˆåŠŸ (æœ¬åœ°åœ–ç‰‡): {folder.name}")
                else:
                    failed_count += 1
                    logger.warning(f"è£œå……å°é¢å¤±æ•— (æ‰€æœ‰æ–¹æ³•éƒ½å¤±æ•—): {folder.name}")
        
        msg = f"âœ… å®Œæˆï¼\n"
        msg += f"ğŸ“¥ å¾ nhentai å°é¢ä¸‹è¼‰äº† {fixed_count} å€‹\n"
        if fallback_count > 0:
            msg += f"ğŸ–¼ï¸ ä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ {fallback_count} å€‹\n"
        msg += f"â­ï¸ è·³é {skipped_count} å€‹å·²æœ‰å°é¢\n"
        if failed_count > 0:
            msg += f"âŒ å¤±æ•— {failed_count} å€‹"
        await interaction.channel.send(msg)
        
    except Exception as e:
        logger.error(f"è£œå……å°é¢å¤±æ•—: {e}")
        await interaction.channel.send(f"âŒ è£œå……å°é¢å¤±æ•—: {e}")


@bot.tree.command(name='cleanup', description='æ¸…é™¤ imported è³‡æ–™å¤¾ä¸­å·²å°å…¥ Eagle çš„é …ç›®')
async def cleanup_command(interaction: discord.Interaction):
    """æ¸…é™¤ imported è³‡æ–™å¤¾ä¸­å·²å°å…¥åˆ° Eagle çš„é …ç›®"""
    await interaction.response.defer()
    
    try:
        # imported è³‡æ–™å¤¾è·¯å¾‘
        imported_dir = Path(DOWNLOAD_DIR).parent / 'imported'
        
        if not imported_dir.exists():
            await interaction.followup.send("ğŸ“‚ imported è³‡æ–™å¤¾ä¸å­˜åœ¨")
            return
        
        # ç²å– Eagle ç´¢å¼•
        from eagle_library import EagleLibrary
        eagle = EagleLibrary()
        
        # å…ˆåŸ·è¡Œ reindex ç¢ºä¿ç´¢å¼•æœ€æ–°
        await interaction.followup.send("ğŸ”„ æ­£åœ¨æƒæä¸¦æ¯”å° Eagle Library...")
        eagle.rebuild_index()
        
        folders = [f for f in imported_dir.iterdir() if f.is_dir()]
        can_delete = []  # å¯ä»¥åˆªé™¤çš„è³‡æ–™å¤¾ (å·²åœ¨ Eagle ä¸­)
        not_in_eagle = []  # ä¸åœ¨ Eagle ä¸­çš„è³‡æ–™å¤¾
        
        for folder in folders:
            folder_name = folder.name
            
            # å˜—è©¦å¾è³‡æ–™å¤¾åç¨±æå– gallery_id
            gallery_id = None
            
            # æ–¹å¼ 1: ç´”æ•¸å­—è³‡æ–™å¤¾å
            if folder_name.isdigit():
                gallery_id = folder_name
            else:
                # æ–¹å¼ 2: å¾ metadata.json è®€å–
                metadata_path = folder / 'metadata.json'
                if metadata_path.exists():
                    try:
                        with open(metadata_path, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                            gallery_id = metadata.get('gallery_id') or metadata.get('nhentai_id')
                    except:
                        pass
            
            if gallery_id:
                # æª¢æŸ¥æ˜¯å¦åœ¨ Eagle ä¸­
                result = eagle.find_by_nhentai_id(str(gallery_id))
                if result:
                    can_delete.append((folder, gallery_id, result.get('title', '')[:30]))
                else:
                    not_in_eagle.append((folder, gallery_id))
            else:
                # æ²’æœ‰ ID çš„è³‡æ–™å¤¾ï¼Œç”¨æ¨™é¡Œæœå°‹
                results = eagle.find_by_title(folder_name[:50])
                if results:
                    can_delete.append((folder, None, folder_name[:30]))
                else:
                    not_in_eagle.append((folder, None))
        
        if not can_delete:
            msg = f"âœ… æ²’æœ‰å¯æ¸…é™¤çš„é …ç›®\n"
            msg += f"ğŸ“ imported è³‡æ–™å¤¾å…± {len(folders)} å€‹é …ç›®\n"
            msg += f"âš ï¸ å…¶ä¸­ {len(not_in_eagle)} å€‹å°šæœªå°å…¥ Eagle"
            await interaction.channel.send(msg)
            return
        
        # é¡¯ç¤ºå°‡è¦åˆªé™¤çš„è³‡æ–™å¤¾
        msg = f"ğŸ” ç™¼ç¾ **{len(can_delete)}** å€‹å·²å°å…¥ Eagle çš„é …ç›®å¯æ¸…é™¤ï¼š\n\n"
        for folder, gid, title in can_delete[:10]:
            if gid:
                msg += f"â€¢ `#{gid}` {title}\n"
            else:
                msg += f"â€¢ {title}\n"
        if len(can_delete) > 10:
            msg += f"... é‚„æœ‰ {len(can_delete) - 10} å€‹\n"
        
        msg += f"\nğŸ“Š çµ±è¨ˆï¼šå·²å°å…¥ {len(can_delete)} å€‹ï¼Œæœªå°å…¥ {len(not_in_eagle)} å€‹"
        msg += "\n\nâš ï¸ **æ³¨æ„ï¼šåªæœƒåˆªé™¤å·²ç¢ºèªå°å…¥ Eagle çš„é …ç›®**"
        msg += "\nğŸ’¡ æœªå°å…¥çš„é …ç›®æœƒè¢«ä¿ç•™"
        
        # ä½¿ç”¨æŒ‰éˆ•ç¢ºèª
        from bot.views import CleanupConfirmView
        view = CleanupConfirmView(
            can_delete=can_delete,
            not_in_eagle=not_in_eagle,
            user_id=interaction.user.id
        )
        
        await interaction.channel.send(msg, view=view)
        
    except Exception as e:
        logger.error(f"æ¸…é™¤é‡è¤‡å¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ æ¸…é™¤å¤±æ•—: {e}")


# ==================== Eagle Library æœå°‹æŒ‡ä»¤ ====================

@bot.tree.command(name='search', description='æœå°‹æœ¬å­ (Eagle Library + ä¸‹è¼‰è³‡æ–™å¤¾)')
@app_commands.describe(
    query='æœå°‹é—œéµå­—æˆ– nhentai ID',
    source='æœå°‹ä¾†æº (é è¨­: all)'
)
@app_commands.choices(source=[
    app_commands.Choice(name="å…¨éƒ¨", value="all"),
    app_commands.Choice(name="Eagle Library", value="eagle"),
    app_commands.Choice(name="ä¸‹è¼‰è³‡æ–™å¤¾", value="downloads"),
])
async def search_command(
    interaction: discord.Interaction, 
    query: str,
    source: str = "all"
):
    """æœå°‹æœ¬å­ (æ”¯æ´é›™ä¾†æº)"""
    await interaction.response.defer()
    
    try:
        query = query.strip()
        results = []
        
        # æœå°‹ Eagle Library
        if source in ['all', 'eagle']:
            try:
                from eagle_library import EagleLibrary
                eagle = EagleLibrary()
                
                if query.isdigit():
                    result = eagle.find_by_nhentai_id(query)
                    if result:
                        result['source'] = 'eagle'
                        results.append(result)
                else:
                    eagle_results = eagle.find_by_title(query)
                    for r in eagle_results:
                        r['source'] = 'eagle'
                        results.append(r)
            except Exception as e:
                logger.debug(f"Eagle æœå°‹éŒ¯èª¤: {e}")
        
        # æœå°‹ downloads è³‡æ–™å¤¾
        if source in ['all', 'downloads']:
            if query.isdigit():
                # ç”¨ ID æœå°‹
                for item in get_all_downloads_items():
                    if item.get('nhentai_id') == query:
                        # é¿å…é‡è¤‡ï¼ˆEagle å·²ç¶“æœ‰é€™å€‹ IDï¼‰
                        if not any(r.get('nhentai_id') == query and r.get('source') == 'eagle' for r in results):
                            results.append(item)
            else:
                # ç”¨é—œéµå­—æœå°‹
                download_results = search_in_downloads(query)
                for item in download_results:
                    # é¿å… ID é‡è¤‡
                    item_id = item.get('nhentai_id')
                    if not any(r.get('nhentai_id') == item_id for r in results):
                        results.append(item)
        
        # é¡¯ç¤ºæœå°‹é¡å‹
        if query.isdigit():
            search_type = f"ID `{query}`"
        else:
            search_type = f"`{query}`"
        
        source_label = {"all": "å…¨éƒ¨", "eagle": "Eagle", "downloads": "ä¸‹è¼‰å€"}.get(source, source)
        
        if not results:
            await interaction.followup.send(f"ğŸ” åœ¨ **{source_label}** ä¸­æ‰¾ä¸åˆ°ç¬¦åˆ {search_type} çš„çµæœ")
            return
        
        total = len(results)
        display_results = results[:10]
        
        # åˆ¤æ–·æ˜¯å¦ä½¿ç”¨ç²¾ç°¡æ¨¡å¼ (è¶…é 5 å€‹çµæœ)
        compact_mode = total > 5
        
        if compact_mode:
            # ç²¾ç°¡æ¨¡å¼ï¼šä½¿ç”¨åˆ†é  embed
            from bot.views import SearchResultView
            
            # å‚³å…¥å…¨éƒ¨çµæœï¼ŒView æœƒè™•ç†åˆ†é 
            view = SearchResultView(results, query, source, search_type="keyword")
            await interaction.followup.send(embed=view.get_embed(), view=view)
        else:
            # è©³ç´°æ¨¡å¼ï¼šé¡ä¼¼ random çš„é¡¯ç¤ºæ–¹å¼
            await interaction.followup.send(f"ğŸ” **{source_label}** ä¸­æ‰¾åˆ° {total} å€‹çµæœ - {search_type}")
            
            for item in display_results:
                title = item.get('title', 'æœªçŸ¥')
                gallery_id = item.get('nhentai_id', 'æœªçŸ¥')
                web_url = item.get('web_url', '')
                tags = item.get('tags', [])
                folder_path = item.get('folder_path', '')
                item_source = item.get('source', 'eagle')
                
                # è§£æ tags
                artists = [tag.replace('artist:', '') for tag in tags if isinstance(tag, str) and tag.startswith('artist:')]
                parodies = [tag.replace('parody:', '') for tag in tags if isinstance(tag, str) and tag.startswith('parody:')]
                
                # è¨ˆç®—æª”æ¡ˆå¤§å°å’Œé æ•¸
                file_size_str = ""
                page_count = 0
                if folder_path:
                    try:
                        folder = Path(folder_path)
                        # è¨ˆç®— PDF æª”æ¡ˆå¤§å°
                        pdf_files = list(folder.glob('*.pdf'))
                        if pdf_files:
                            pdf_size = pdf_files[0].stat().st_size
                            if pdf_size > 1024 * 1024:
                                file_size_str = f"{pdf_size / (1024*1024):.1f} MB"
                            else:
                                file_size_str = f"{pdf_size / 1024:.0f} KB"
                        
                        # è¨ˆç®—é æ•¸ (åœ–ç‰‡æ•¸é‡)
                        image_exts = ['*.jpg', '*.jpeg', '*.png', '*.webp', '*.gif']
                        for ext in image_exts:
                            page_count += len(list(folder.glob(ext)))
                    except Exception as e:
                        logger.debug(f"è¨ˆç®—æª”æ¡ˆè³‡è¨Šå¤±æ•—: {e}")
                
                # ç™¼é€å°é¢
                cover_sent = False
                if folder_path:
                    try:
                        folder = Path(folder_path)
                        for cover_name in ['cover.jpg', 'cover.png', 'cover.webp', 'thumbnail.png']:
                            cover_path = folder / cover_name
                            if cover_path.exists():
                                file = discord.File(str(cover_path), filename=cover_name)
                                await interaction.channel.send(file=file)
                                cover_sent = True
                                break
                        
                        if not cover_sent:
                            for ext in ['*.jpg', '*.jpeg', '*.png', '*.webp']:
                                images = list(folder.glob(ext))
                                if images:
                                    images.sort(key=lambda x: x.name)
                                    file = discord.File(str(images[0]), filename=images[0].name)
                                    await interaction.channel.send(file=file)
                                    cover_sent = True
                                    break
                    except Exception as e:
                        logger.debug(f"å°é¢ç™¼é€å¤±æ•—: {e}")
                
                # ç™¼é€è³‡è¨Š
                msg_lines = []
                source_emoji = "ğŸ¦…" if item_source == 'eagle' else "ğŸ“"
                msg_lines.append(f"{source_emoji} **#{gallery_id}**")
                
                # æ¨™é¡Œé€£çµ
                if item_source == 'eagle' and web_url:
                    msg_lines.append(f"ğŸ“– [{title}]({web_url})")
                elif item_source == 'downloads' and gallery_id:
                    pdf_url = f"{PDF_WEB_BASE_URL}/{quote(str(gallery_id))}/{quote(str(gallery_id))}.pdf"
                    msg_lines.append(f"ğŸ“– [{title}]({pdf_url})")
                else:
                    msg_lines.append(f"ğŸ“– **{title}**")
                
                if artists:
                    msg_lines.append(f"âœï¸ {', '.join(artists)}")
                if parodies:
                    msg_lines.append(f"ğŸ¬ {', '.join(parodies)}")
                
                # åŠ å…¥æª”æ¡ˆå¤§å°å’Œé æ•¸
                info_parts = []
                if page_count > 0:
                    info_parts.append(f"ğŸ“„ {page_count} é ")
                if file_size_str:
                    info_parts.append(f"ğŸ’¾ {file_size_str}")
                if info_parts:
                    msg_lines.append(" | ".join(info_parts))
                
                await interaction.channel.send("\n".join(msg_lines))
        
    except Exception as e:
        logger.error(f"æœå°‹å¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ æœå°‹å¤±æ•—: {e}")


@bot.tree.command(name='read', description='å–å¾—æœ¬å­çš„ PDF é€£çµ (æ”¯æ´ Eagle + ä¸‹è¼‰å€)')
@app_commands.describe(nhentai_id='nhentai ID æˆ–ç¶²å€')
async def read_command(interaction: discord.Interaction, nhentai_id: str):
    """å–å¾—æœ¬å­çš„ PDF é€£çµ (æ”¯æ´é›™ä¾†æº)"""
    await interaction.response.defer()
    
    # æ¸…ç†è¼¸å…¥
    nhentai_id = nhentai_id.strip()
    if not nhentai_id.isdigit():
        # å˜—è©¦å¾ç¶²å€æå–
        match = re.search(r'/g/(\d+)', nhentai_id)
        if match:
            nhentai_id = match.group(1)
        else:
            await interaction.followup.send("âŒ è«‹æä¾›æœ‰æ•ˆçš„ nhentai ID æˆ–ç¶²å€")
            return
    
    try:
        # ä½¿ç”¨é›™ä¾†æºæŸ¥è©¢
        result = find_item_by_id(nhentai_id)
        
        if not result:
            await interaction.followup.send(
                f"ğŸ” æ‰¾ä¸åˆ° ID `{nhentai_id}` çš„æœ¬å­\n"
                f"ğŸ’¡ å¯èƒ½å°šæœªä¸‹è¼‰ï¼Œè«‹ä½¿ç”¨ `/dl {nhentai_id}` ä¸‹è¼‰"
            )
            return
        
        title = result.get('title', 'æœªçŸ¥')
        web_url = result.get('web_url', '')
        tags = result.get('tags', [])
        folder_path = result.get('folder_path', '')
        item_source = result.get('source', 'eagle')
        annotation = result.get('annotation', '')
        
        # è§£æ tags
        artists = [tag.replace('artist:', '') for tag in tags if isinstance(tag, str) and tag.startswith('artist:')]
        parodies = [tag.replace('parody:', '') for tag in tags if isinstance(tag, str) and tag.startswith('parody:')]
        groups = [tag.replace('group:', '') for tag in tags if isinstance(tag, str) and tag.startswith('group:')]
        languages = [tag.replace('language:', '') for tag in tags if isinstance(tag, str) and tag.startswith('language:')]
        characters = [tag.replace('character:', '') for tag in tags if isinstance(tag, str) and tag.startswith('character:')]
        types = [tag.replace('type:', '') for tag in tags if isinstance(tag, str) and tag.startswith('type:')]
        other_tags = [tag for tag in tags if isinstance(tag, str) and not any(tag.startswith(prefix) for prefix in ['artist:', 'parody:', 'group:', 'language:', 'character:', 'type:'])]
        
        # ç™¼é€å°é¢
        cover_sent = False
        if folder_path:
            try:
                folder = Path(folder_path)
                for cover_name in ['cover.jpg', 'cover.png', 'cover.webp', 'thumbnail.png']:
                    cover_path = folder / cover_name
                    if cover_path.exists():
                        file = discord.File(str(cover_path), filename=cover_name)
                        await interaction.followup.send(file=file)
                        cover_sent = True
                        break
                
                if not cover_sent:
                    for ext in ['*.jpg', '*.jpeg', '*.png', '*.webp']:
                        images = list(folder.glob(ext))
                        if images:
                            images.sort(key=lambda x: x.name)
                            file = discord.File(str(images[0]), filename=images[0].name)
                            await interaction.followup.send(file=file)
                            cover_sent = True
                            break
            except Exception as e:
                logger.debug(f"å°é¢ç™¼é€å¤±æ•—: {e}")
        
        # å»ºç«‹è³‡è¨Šè¨Šæ¯
        msg_lines = []
        source_emoji = "ğŸ¦…" if item_source == 'eagle' else "ğŸ“"
        
        msg_lines.append(f"{source_emoji} **#{nhentai_id}**")
        
        # æ¨™é¡Œé€£çµ
        if item_source == 'eagle' and web_url:
            msg_lines.append(f"ğŸ“– [{title}]({web_url})")
        elif item_source == 'downloads':
            pdf_url = f"{PDF_WEB_BASE_URL}/{quote(nhentai_id)}/{quote(nhentai_id)}.pdf"
            msg_lines.append(f"ğŸ“– [{title}]({pdf_url})")
        else:
            msg_lines.append(f"ğŸ“– **{title}**")
        
        msg_lines.append("")
        
        # ä¾†æº
        msg_lines.append(f"ğŸ“¦ ä¾†æº: {'Eagle Library' if item_source == 'eagle' else 'ä¸‹è¼‰è³‡æ–™å¤¾'}")
        
        # åŸºæœ¬è³‡è¨Š
        if artists:
            msg_lines.append(f"âœï¸ ä½œè€…: {', '.join(artists)}")
        if groups:
            msg_lines.append(f"ğŸ‘¥ ç¤¾åœ˜: {', '.join(groups)}")
        if parodies:
            msg_lines.append(f"ğŸ¬ åŸä½œ: {', '.join(parodies)}")
        if languages:
            msg_lines.append(f"ğŸŒ èªè¨€: {', '.join(languages)}")
        if characters:
            msg_lines.append(f"ğŸ‘¤ è§’è‰²: {', '.join(characters)}")
        if types:
            msg_lines.append(f"ğŸ“ é¡å‹: {', '.join(types)}")
        
        # ä½¿ç”¨è€…è©•è«– (é¡¯ç¤ºå…¨éƒ¨)
        if annotation:
            comments = parse_annotation_comments(annotation)
            if comments:
                msg_lines.append("")
                msg_lines.append("ğŸ’¬ è©•è«–:")
                for c in comments:
                    msg_lines.append(f"  **{c['user']}**")
                    if c['content']:
                        msg_lines.append(f"  {c['content']}")
        
        # æ¨™ç±¤ (é¡¯ç¤ºå…¨éƒ¨)
        if other_tags:
            msg_lines.append("")
            msg_lines.append(f"ğŸ·ï¸ æ¨™ç±¤: {', '.join([f'`{tag}`' for tag in other_tags])}")
        
        # ç™¼é€è³‡è¨Š
        final_msg = "\n".join(msg_lines)
        if len(final_msg) > 1900:
            final_msg = final_msg[:1900] + "..."
        
        # å»ºç«‹è©³æƒ…é äº’å‹•è¦–åœ–
        from bot.views import ReadDetailView
        view = ReadDetailView(
            gallery_id=nhentai_id,
            title=title,
            item_source=item_source,
            web_url=web_url,
            artists=artists,
            parodies=parodies,
            other_tags=other_tags
        )
        
        if cover_sent:
            await interaction.channel.send(final_msg, view=view)
        else:
            await interaction.followup.send(final_msg, view=view)
        
    except Exception as e:
        logger.error(f"è®€å–å¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ è®€å–å¤±æ•—: {e}")


@bot.tree.command(name='eagle', description='é¡¯ç¤º Eagle Library çµ±è¨ˆ')
async def eagle_stats_command(interaction: discord.Interaction):
    """é¡¯ç¤º Eagle Library çµ±è¨ˆ"""
    await interaction.response.defer()
    
    try:
        from eagle_library import EagleLibrary
        eagle = EagleLibrary()
        
        stats = eagle.get_stats()
        
        embed = discord.Embed(
            title="ğŸ¦… Eagle Library çµ±è¨ˆ",
            color=discord.Color.gold()
        )
        
        embed.add_field(name="ğŸ“š å·²åŒ¯å…¥", value=f"`{stats['total_count']}` æœ¬", inline=True)
        embed.add_field(name="ğŸ”¢ æœ‰ ID", value=f"`{stats['with_nhentai_id']}` æœ¬", inline=True)
        
        if stats.get('last_updated'):
            from datetime import datetime
            try:
                dt = datetime.fromisoformat(stats['last_updated'].replace('Z', '+00:00'))
                embed.add_field(
                    name="ğŸ• æœ€å¾Œæ›´æ–°",
                    value=dt.strftime("%Y-%m-%d %H:%M"),
                    inline=True
                )
            except:
                pass
        
        embed.set_footer(text="ä½¿ç”¨ /search <é—œéµå­—> æœå°‹ | /read <ID> å–å¾—é€£çµ | /reindex é‡å»ºç´¢å¼•")
        
        await interaction.followup.send(embed=embed)
        
    except ImportError:
        await interaction.followup.send("âŒ Eagle Library æ¨¡çµ„æœªå®‰è£")
    except Exception as e:
        logger.error(f"çµ±è¨ˆå¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ çµ±è¨ˆå¤±æ•—: {e}")


@bot.tree.command(name='reindex', description='é‡å»º Eagle Library ç´¢å¼•')
async def reindex_command(interaction: discord.Interaction):
    """é‡å»º Eagle Library ç´¢å¼•"""
    await interaction.response.defer()
    
    try:
        from eagle_library import EagleLibrary
        eagle = EagleLibrary()
        
        await interaction.followup.send("ğŸ”„ æ­£åœ¨æƒæ Eagle Library...")
        
        added = eagle.rebuild_index()
        stats = eagle.get_stats()
        
        if added > 0:
            await interaction.channel.send(f"âœ… ç´¢å¼•é‡å»ºå®Œæˆï¼\nğŸ“¥ æ–°å¢ `{added}` å€‹é …ç›®\nğŸ“š ç¸½è¨ˆ `{stats['total_count']}` æœ¬")
        else:
            await interaction.channel.send(f"âœ… ç´¢å¼•å·²æ˜¯æœ€æ–°ï¼\nğŸ“š ç¸½è¨ˆ `{stats['total_count']}` æœ¬")
        
    except ImportError:
        await interaction.followup.send("âŒ Eagle Library æ¨¡çµ„æœªå®‰è£")
    except Exception as e:
        logger.error(f"é‡å»ºç´¢å¼•å¤±æ•—: {e}")
        await interaction.followup.send(f"âŒ é‡å»ºç´¢å¼•å¤±æ•—: {e}")


@bot.tree.command(name='help', description='é¡¯ç¤ºä½¿ç”¨èªªæ˜')
async def help_command(interaction: discord.Interaction):
    """é¡¯ç¤ºèªªæ˜"""
    embed = discord.Embed(
        title="ğŸ“– HentaiFetcher ä½¿ç”¨èªªæ˜",
        description="è‡ªå‹•ä¸‹è¼‰æ¼«ç•«ä¸¦è½‰æ›ç‚º PDFï¼Œç”Ÿæˆ Eagle ç›¸å®¹ metadata",
        color=discord.Color.green()
    )
    
    # æª¢æŸ¥æ˜¯å¦åœ¨å°ˆç”¨é »é“
    is_dedicated = (
        interaction.channel.name.lower() in [n.lower() for n in DEDICATED_CHANNEL_NAMES] or
        interaction.channel_id in DEDICATED_CHANNEL_IDS
    )
    
    if is_dedicated:
        embed.add_field(
            name="ğŸ¯ å°ˆç”¨é »é“æ¨¡å¼ï¼ˆæ­¤é »é“ï¼‰",
            value="**æ‰€æœ‰æŒ‡ä»¤éƒ½ä¸éœ€è¦å‰ç¶´ï¼Œç›´æ¥è¼¸å…¥ï¼**\n"
                  "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                  "**ğŸ“¥ ä¸‹è¼‰** - ç›´æ¥è²¼ç¶²å€æˆ–è™Ÿç¢¼ï¼š\n"
                  "```\n"
                  "421633\n"
                  "https://nhentai.net/g/607769/\n"
                  "```\n"
                  "**ğŸ§ª å¼·åˆ¶é‡æ–°ä¸‹è¼‰**ï¼š`test <è™Ÿç¢¼>`\n",
            inline=False
        )
    
    embed.add_field(
        name="ğŸ“Š æ–œç·šæŒ‡ä»¤",
        value="`/queue` - æŸ¥çœ‹ä½‡åˆ—\n"
              "`/status` - Bot ç‹€æ…‹\n"
              "`/list` - åˆ—å‡ºå…¨éƒ¨æœ¬å­\n"
              "`/random [æ•¸é‡] [ä¾†æº]` - éš¨æ©ŸæŠ½\n"
              "`/fixcover` - è£œå……å°é¢\n"
              "`/cleanup` - æ¸…é™¤å·²å°å…¥é …ç›®",
        inline=True
    )
    
    embed.add_field(
        name="ğŸ¦… Eagle + ä¸‹è¼‰å€",
        value="`/search <é—œéµå­—> [ä¾†æº]` - æœå°‹\n"
              "`/read <ID>` - å–å¾— PDF é€£çµ\n"
              "`/eagle` - Library çµ±è¨ˆ\n"
              "`/reindex` - é‡å»ºç´¢å¼•\n"
              "â”â”â”â”â”â”â”â”â”â”â”â”\n"
              "ğŸ® **äº’å‹•æŒ‰éˆ•**: æœå°‹/è©³æƒ…é æ”¯æ´é»æ“Šæ“ä½œ",
        inline=True
    )
    
    embed.add_field(
        name="â„¹ï¸ ç³»çµ±",
        value="`/ping` - æ¸¬è©¦é€£ç·š\n"
              "`/version` - ç‰ˆæœ¬è™Ÿ\n"
              "`/sync` - åŒæ­¥æŒ‡ä»¤ (ç®¡ç†å“¡)\n"
              "`/help` - é¡¯ç¤ºæ­¤èªªæ˜",
        inline=True
    )
    
    embed.add_field(
        name="ğŸ“ è¼¸å‡ºçµæœ",
        value="ä¸‹è¼‰å®Œæˆå¾Œæœƒç”Ÿæˆï¼š\n"
              "```\n"
              "downloads/[Gallery_ID]/\n"
              "â”œâ”€â”€ [Gallery_ID].pdf\n"
              "â”œâ”€â”€ cover.jpg\n"
              "â””â”€â”€ metadata.json\n"
              "```",
        inline=False
    )
    
    if is_dedicated:
        embed.set_footer(text="ğŸ¯ å°ˆç”¨é »é“ï¼šå¯ç›´æ¥è²¼è™Ÿç¢¼ä¸‹è¼‰ï¼")
    else:
        embed.set_footer(text="ğŸ’¡ ä½¿ç”¨æ–œç·šæŒ‡ä»¤ / é–‹å§‹")
    
    await interaction.response.send_message(embed=embed)


# ==================== ä¸»ç¨‹å¼å…¥å£ ====================

def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    # å–å¾— Discord Token
    token = os.environ.get('DISCORD_TOKEN')
    
    if not token:
        logger.error("éŒ¯èª¤: æœªè¨­å®š DISCORD_TOKEN ç’°å¢ƒè®Šæ•¸")
        logger.error("è«‹åœ¨ docker-compose.yml ä¸­è¨­å®š DISCORD_TOKEN")
        sys.exit(1)
    
    try:
        logger.info("æ­£åœ¨å•Ÿå‹• HentaiFetcher Bot...")
        bot.run(token)
    except discord.LoginFailure:
        logger.error("Discord ç™»å…¥å¤±æ•—: Token ç„¡æ•ˆ")
        sys.exit(1)
    except Exception as e:
        logger.exception(f"Bot åŸ·è¡ŒéŒ¯èª¤: {e}")
        sys.exit(1)
    finally:
        # åœæ­¢å·¥ä½œåŸ·è¡Œç·’
        if bot.worker:
            bot.worker.stop()


if __name__ == '__main__':
    main()
