#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HentaiFetcher - Discord Bot è‡ªå‹•åŒ–æ¼«ç•«ä¸‹è¼‰å™¨
==============================================
ç‰ˆæœ¬: 2.0.1 - 2024-12-30 å¤šè¡Œè¼¸å…¥ä¿®å¾©ç‰ˆ
åŠŸèƒ½ï¼š
1. Discord Bot ç›£è¯ !dl æŒ‡ä»¤ï¼ˆæ”¯æ´å¤šå€‹ç¶²å€æˆ–è™Ÿç¢¼ï¼‰
2. ä½¿ç”¨ gallery-dl ä¸‹è¼‰åœ–ç‰‡èˆ‡ metadata
3. ä½¿ç”¨ img2pdf è½‰æ›ç‚ºç„¡æ PDF
4. ç”Ÿæˆ Eagle ç›¸å®¹çš„ metadata.json
5. è‡ªå‹•æ¸…ç†åŸå§‹åœ–ç‰‡æª”æ¡ˆ
"""

# ç‰ˆæœ¬è™Ÿ - ç”¨ä¾†ç¢ºèªå®¹å™¨æ˜¯å¦æ›´æ–°
VERSION = "2.8.0"

print(f"[STARTUP] HentaiFetcher ç‰ˆæœ¬ {VERSION} æ­£åœ¨è¼‰å…¥...", flush=True)

import os
import sys
import json
import time
import shutil
import asyncio
import logging
import subprocess
import threading
import re
import requests
from queue import Queue, Empty
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, Any, List

import discord
from discord.ext import commands

# è¼‰å…¥ .env æª”æ¡ˆï¼ˆæœ¬åœ°æ¸¬è©¦ç”¨ï¼‰
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("[STARTUP] å·²è¼‰å…¥ .env æª”æ¡ˆ", flush=True)
except ImportError:
    pass  # Docker ç’°å¢ƒä¸éœ€è¦ dotenv

print(f"[STARTUP] æ¨¡çµ„è¼‰å…¥å®Œæˆ", flush=True)

# ==================== è¨­å®šå€å¡Š ====================

# åˆ¤æ–·é‹è¡Œç’°å¢ƒï¼ˆDocker æˆ–æœ¬åœ°ï¼‰
import platform
IS_DOCKER = platform.system() == 'Linux' and os.path.exists('/app')

if IS_DOCKER:
    # Docker ç’°å¢ƒ - ä½¿ç”¨å®¹å™¨å…§è·¯å¾‘
    BASE_DIR = Path('/app')
    print("[STARTUP] é‹è¡Œç’°å¢ƒ: Docker", flush=True)
else:
    # æœ¬åœ°æ¸¬è©¦ç’°å¢ƒ - ä½¿ç”¨å°ˆæ¡ˆè³‡æ–™å¤¾
    BASE_DIR = Path(__file__).parent.resolve()
    print(f"[STARTUP] é‹è¡Œç’°å¢ƒ: æœ¬åœ° ({BASE_DIR})", flush=True)

# çµ±ä¸€ä½¿ç”¨ç›¸åŒçš„å­è³‡æ–™å¤¾
CONFIG_DIR = BASE_DIR / 'config'
DOWNLOAD_DIR = BASE_DIR / 'downloads'
TEMP_DIR = BASE_DIR / 'temp'

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
CONFIG_DIR.mkdir(parents=True, exist_ok=True)
DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)
TEMP_DIR.mkdir(parents=True, exist_ok=True)

# æ—¥èªŒè¨­å®š
log_file = CONFIG_DIR / 'bot.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(str(log_file), encoding='utf-8')
    ]
)
logger = logging.getLogger('HentaiFetcher')

# ä¸‹è¼‰ä½‡åˆ— - çµæ§‹: (url, channel_id, status_message_id)
download_queue: Queue = Queue()

# é€²åº¦æ¢è¨­å®š
PROGRESS_UPDATE_INTERVAL = 3  # æ¯ 3 ç§’æ›´æ–°ä¸€æ¬¡é€²åº¦
SECONDS_PER_PAGE = 3.6  # é ä¼°æ¯é ä¸‹è¼‰æ™‚é–“ï¼ˆå¯¦æ¸¬å¹³å‡å€¼ï¼‰
PROGRESS_BAR_WIDTH = 15  # é€²åº¦æ¢å¯¬åº¦ï¼ˆæ ¼æ•¸ï¼‰

# PDF Web å­˜å–è¨­å®š
PDF_WEB_BASE_URL = "http://192.168.0.32:8888"  # Web Station åŸºç¤ URL


def create_progress_bar(current: int, total: int, width: int = PROGRESS_BAR_WIDTH) -> str:
    """
    å‰µå»º emoji é€²åº¦æ¢
    
    Args:
        current: ç›®å‰å®Œæˆæ•¸é‡
        total: ç¸½æ•¸é‡
        width: é€²åº¦æ¢å¯¬åº¦ï¼ˆæ ¼æ•¸ï¼‰
    
    Returns:
        é€²åº¦æ¢å­—ä¸²ï¼Œä¾‹å¦‚ï¼šğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©â¬œâ¬œâ¬œâ¬œâ¬œ 50%
    """
    if total <= 0:
        return "â¬œ" * width + " 0%"
    
    percentage = min(current / total, 1.0)
    filled = int(percentage * width)
    empty = width - filled
    
    bar = "ğŸŸ©" * filled + "â¬œ" * empty
    percent_text = f"{int(percentage * 100)}%"
    
    return f"{bar} {percent_text}"


# è¨Šæ¯å»é‡ï¼ˆé¿å…é‡è¤‡è™•ç†åŒä¸€è¨Šæ¯ï¼‰
processed_messages: set = set()

# å°ˆç”¨é »é“è¨­å®š - åœ¨é€™äº›é »é“ä¸­ä¸éœ€è¦ !dl å‰ç¶´
# å¯è¨­å®šé »é“åç¨±æˆ–é »é“ IDï¼ˆè¨­å®šåç¨±æ›´æ–¹ä¾¿ï¼‰
DEDICATED_CHANNEL_NAMES = ['hentaifetcher', 'hentai-fetcher', 'nhentai']  # é »é“åç¨±
DEDICATED_CHANNEL_IDS = []  # æˆ–ç›´æ¥è¨­å®šé »é“ ID
MAX_PROCESSED_MESSAGES = 1000  # æœ€å¤šä¿ç•™ 1000 ç­†è¨˜éŒ„

def is_message_processed(message_id: int) -> bool:
    """æª¢æŸ¥è¨Šæ¯æ˜¯å¦å·²è™•ç†é"""
    global processed_messages
    if message_id in processed_messages:
        return True
    
    # æ¸…ç†éèˆŠçš„è¨˜éŒ„
    if len(processed_messages) >= MAX_PROCESSED_MESSAGES:
        # æ¸…é™¤ä¸€åŠçš„è¨˜éŒ„
        processed_messages = set(list(processed_messages)[MAX_PROCESSED_MESSAGES // 2:])
    
    processed_messages.add(message_id)
    return False

# ==================== å·¥å…·å‡½å¼ ====================

def parse_input_to_urls(input_text: str) -> List[str]:
    """
    è§£æä½¿ç”¨è€…è¼¸å…¥ï¼Œæ”¯æ´å¤šç¨®æ ¼å¼ï¼š
    - å®Œæ•´ç¶²å€: https://nhentai.net/g/123456/
    - ç´”æ•¸å­—: 123456
    - å¤šå€‹è¼¸å…¥ï¼ˆç©ºç™½ã€é€—è™Ÿã€æ›è¡Œåˆ†éš”ï¼‰
    - æ··åˆè¼¸å…¥: 421633 https://nhentai.net/g/607769/ 613358
    
    Args:
        input_text: ä½¿ç”¨è€…è¼¸å…¥çš„æ–‡å­—
    
    Returns:
        è§£æå¾Œçš„å®Œæ•´ URL åˆ—è¡¨
    """
    urls = []
    
    # æ¨™æº–åŒ–æ›è¡Œç¬¦è™Ÿï¼ˆè™•ç† Windows/Mac/Linux ä¸åŒçš„æ›è¡Œï¼‰
    normalized_text = input_text.replace('\r\n', '\n').replace('\r', '\n')
    
    # Debug æ—¥èªŒ
    logger.debug(f"åŸå§‹è¼¸å…¥: {repr(input_text)}")
    logger.debug(f"æ¨™æº–åŒ–å¾Œ: {repr(normalized_text)}")
    
    # æŒ‰è¡Œåˆ†å‰²è™•ç†
    lines = normalized_text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # æ¯è¡Œå¯èƒ½æœ‰å¤šå€‹é …ç›®ï¼ˆç©ºç™½æˆ–é€—è™Ÿåˆ†éš”ï¼‰
        parts = re.split(r'[\s,;]+', line)
        
        for part in parts:
            part = part.strip()
            if not part:
                continue
            
            # å¦‚æœæ˜¯å®Œæ•´ URL
            if part.startswith(('http://', 'https://')):
                # æ¸…ç† URL çµå°¾å¯èƒ½çš„æ¨™é»ç¬¦è™Ÿ
                url = part.rstrip('.,;')
                urls.append(url)
            # å¦‚æœæ˜¯ç´”æ•¸å­—
            elif part.isdigit():
                urls.append(f"https://nhentai.net/g/{part}/")
            # å˜—è©¦æå–æ•¸å­—ï¼ˆä¾‹å¦‚: g/123456 æˆ– #123456ï¼‰
            else:
                match = re.search(r'(\d{4,7})', part)
                if match:
                    urls.append(f"https://nhentai.net/g/{match.group(1)}/")
    
    # å»é™¤é‡è¤‡ä¸¦ä¿æŒé †åº
    seen = set()
    unique_urls = []
    for url in urls:
        if url not in seen:
            seen.add(url)
            unique_urls.append(url)
    
    logger.info(f"è§£æåˆ° {len(unique_urls)} å€‹ URL")
    return unique_urls


def sanitize_filename(name: str, max_length: int = 200) -> str:
    """
    æ¸…ç†æª”æ¡ˆåç¨±ï¼Œç§»é™¤ä¸åˆæ³•å­—å…ƒ
    
    Args:
        name: åŸå§‹åç¨±
        max_length: æœ€å¤§é•·åº¦é™åˆ¶ï¼ˆé è¨­ 200ï¼Œä¿ç•™å®Œæ•´æ¨™é¡Œï¼‰
    
    Returns:
        æ¸…ç†å¾Œçš„å®‰å…¨æª”æ¡ˆåç¨±
    """
    # ç§»é™¤æˆ–æ›¿æ›ä¸åˆæ³•çš„æª”æ¡ˆåç¨±å­—å…ƒ
    invalid_chars = r'[<>:"/\\|?*\x00-\x1f]'
    sanitized = re.sub(invalid_chars, '_', name)
    
    # ç§»é™¤å‰å¾Œç©ºç™½å’Œé»
    sanitized = sanitized.strip(' .')
    
    # åªåœ¨è¶…éç³»çµ±é™åˆ¶æ™‚æ‰æˆªæ–·ï¼ˆLinux æª”åä¸Šé™ 255ï¼‰
    if max_length and len(sanitized) > max_length:
        sanitized = sanitized[:max_length].strip(' .')
    
    # å¦‚æœçµæœç‚ºç©ºï¼Œä½¿ç”¨é è¨­åç¨±
    if not sanitized:
        sanitized = f"download_{int(time.time())}"
    
    return sanitized


def generate_eagle_id() -> str:
    """
    ç”Ÿæˆ Eagle ç›¸å®¹çš„å”¯ä¸€ ID (åŸºæ–¼æ™‚é–“æˆ³)
    
    Returns:
        å”¯ä¸€è­˜åˆ¥ç¢¼å­—ä¸²
    """
    return f"L{int(datetime.now().timestamp() * 1000)}"


def verify_nhentai_url(gallery_id: str) -> tuple[bool, str]:
    """
    é©—è­‰ nhentai gallery æ˜¯å¦å­˜åœ¨ä¸”å¯è¨ªå•
    
    Args:
        gallery_id: Gallery ID
    
    Returns:
        (æ˜¯å¦æœ‰æ•ˆ, æ¨™é¡Œæˆ–éŒ¯èª¤è¨Šæ¯)
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            title = data.get('title', {}).get('english', '') or data.get('title', {}).get('japanese', '')
            return True, title[:50] + '...' if len(title) > 50 else title
        elif response.status_code == 404:
            return False, "Gallery ä¸å­˜åœ¨"
        else:
            return False, f"HTTP {response.status_code}"
    except requests.Timeout:
        return False, "é€£ç·šé€¾æ™‚"
    except Exception as e:
        return False, str(e)


def get_nhentai_page_count(gallery_id: str) -> tuple[int, str, str]:
    """
    å¾ nhentai API ç²å–é æ•¸ã€æ¨™é¡Œå’Œ media_id
    
    Args:
        gallery_id: Gallery ID
    
    Returns:
        (é æ•¸, æ¨™é¡Œ, media_id) - å¤±æ•—æ™‚é æ•¸ç‚º 0
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            data = response.json()
            pages = data.get('num_pages', 0)
            title = data.get('title', {}).get('japanese', '') or data.get('title', {}).get('english', '')
            media_id = str(data.get('media_id', ''))
            return pages, title[:40] + '...' if len(title) > 40 else title, media_id
    except:
        pass
    
    return 0, "", ""


def fetch_nhentai_extra_info(gallery_id: str) -> Dict[str, Any]:
    """
    å¾ nhentai API ç²å–é¡å¤–è³‡è¨Šï¼ˆæ”¶è—æ•¸ã€è©•è«–ç­‰ï¼‰
    
    Args:
        gallery_id: Gallery ID
    
    Returns:
        åŒ…å« favorites å’Œ comments çš„å­—å…¸
    """
    result = {
        'favorites': 0,
        'comments': []
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    # ç²å–æ”¶è—æ•¸
    try:
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=30)
        if response.status_code == 200:
            data = response.json()
            result['favorites'] = data.get('num_favorites', 0)
            logger.info(f"ç²å–æ”¶è—æ•¸: {result['favorites']}")
    except Exception as e:
        logger.warning(f"ç²å–æ”¶è—æ•¸å¤±æ•—: {e}")
    
    # ç²å–è©•è«–
    try:
        comments_url = f"https://nhentai.net/api/gallery/{gallery_id}/comments"
        response = requests.get(comments_url, headers=headers, timeout=30)
        if response.status_code == 200:
            result['comments'] = response.json()
            logger.info(f"ç²å–è©•è«–æ•¸: {len(result['comments'])}")
    except Exception as e:
        logger.warning(f"ç²å–è©•è«–å¤±æ•—: {e}")
    
    return result


def download_nhentai_cover(gallery_id: str, save_path: Path) -> bool:
    """
    å¾ nhentai ä¸‹è¼‰å°é¢åœ–ç‰‡
    
    Args:
        gallery_id: Gallery ID
        save_path: ä¿å­˜è·¯å¾‘ï¼ˆè³‡æ–™å¤¾ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        # ç²å– gallery è³‡è¨Š
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=30)
        if response.status_code != 200:
            logger.warning(f"ç„¡æ³•ç²å– gallery è³‡è¨Š: {gallery_id}")
            return False
        
        data = response.json()
        media_id = data.get('media_id', '')
        if not media_id:
            logger.warning(f"æ‰¾ä¸åˆ° media_id: {gallery_id}")
            return False
        
        # ç²å–å°é¢æ ¼å¼
        images = data.get('images', {})
        cover = images.get('cover', {})
        cover_type = cover.get('t', 'j')  # j=jpg, p=png, g=gif
        
        ext_map = {'j': 'jpg', 'p': 'png', 'g': 'gif'}
        ext = ext_map.get(cover_type, 'jpg')
        
        # å˜—è©¦å¤šå€‹ URL æ ¼å¼ä¸‹è¼‰å°é¢
        cover_urls = [
            f"https://t.nhentai.net/galleries/{media_id}/cover.{ext}",
            f"https://t3.nhentai.net/galleries/{media_id}/cover.{ext}",
            f"https://i.nhentai.net/galleries/{media_id}/cover.{ext}",
            f"https://i5.nhentai.net/galleries/{media_id}/cover.{ext}",
        ]
        
        for cover_url in cover_urls:
            try:
                logger.info(f"å˜—è©¦ä¸‹è¼‰å°é¢: {cover_url}")
                response = requests.get(cover_url, headers=headers, timeout=30)
                if response.status_code == 200:
                    cover_path = save_path / f"cover.{ext}"
                    with open(cover_path, 'wb') as f:
                        f.write(response.content)
                    logger.info(f"å°é¢å·²ä¿å­˜: {cover_path}")
                    return True
            except Exception as e:
                logger.debug(f"å˜—è©¦ {cover_url} å¤±æ•—: {e}")
                continue
        
        logger.warning(f"æ‰€æœ‰å°é¢ URL éƒ½å¤±æ•—")
        return False
            
    except Exception as e:
        logger.error(f"ä¸‹è¼‰å°é¢éŒ¯èª¤: {e}")
        return False


def download_nhentai_first_page(gallery_id: str, save_path: Path) -> bool:
    """
    å¾ nhentai ä¸‹è¼‰ç¬¬ä¸€é åœ–ç‰‡ä½œç‚ºå°é¢ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
    
    Args:
        gallery_id: Gallery ID
        save_path: ä¿å­˜è·¯å¾‘ï¼ˆè³‡æ–™å¤¾ï¼‰
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        # ç²å– gallery è³‡è¨Š
        api_url = f"https://nhentai.net/api/gallery/{gallery_id}"
        response = requests.get(api_url, headers=headers, timeout=30)
        if response.status_code != 200:
            logger.warning(f"ç„¡æ³•ç²å– gallery è³‡è¨Š: {gallery_id}")
            return False
        
        data = response.json()
        media_id = data.get('media_id', '')
        if not media_id:
            logger.warning(f"æ‰¾ä¸åˆ° media_id: {gallery_id}")
            return False
        
        # ç²å–ç¬¬ä¸€é æ ¼å¼
        images = data.get('images', {})
        pages = images.get('pages', [])
        if not pages:
            logger.warning(f"æ‰¾ä¸åˆ°é é¢è³‡è¨Š: {gallery_id}")
            return False
        
        first_page = pages[0]
        page_type = first_page.get('t', 'j')  # j=jpg, p=png, g=gif, w=webp
        
        ext_map = {'j': 'jpg', 'p': 'png', 'g': 'gif', 'w': 'webp'}
        ext = ext_map.get(page_type, 'jpg')
        
        # å˜—è©¦å¤šå€‹ URL æ ¼å¼ä¸‹è¼‰ç¬¬ä¸€é 
        first_page_urls = [
            f"https://i.nhentai.net/galleries/{media_id}/1.{ext}",
            f"https://i2.nhentai.net/galleries/{media_id}/1.{ext}",
            f"https://i5.nhentai.net/galleries/{media_id}/1.{ext}",
            f"https://i7.nhentai.net/galleries/{media_id}/1.{ext}",
        ]
        
        for page_url in first_page_urls:
            try:
                logger.info(f"å˜—è©¦ä¸‹è¼‰ç¬¬ä¸€é ä½œç‚ºå°é¢: {page_url}")
                response = requests.get(page_url, headers=headers, timeout=30)
                if response.status_code == 200:
                    cover_path = save_path / f"cover.{ext}"
                    with open(cover_path, 'wb') as f:
                        f.write(response.content)
                    logger.info(f"ç¬¬ä¸€é å·²ä¿å­˜ç‚ºå°é¢: {cover_path}")
                    return True
            except Exception as e:
                logger.debug(f"å˜—è©¦ {page_url} å¤±æ•—: {e}")
                continue
        
        logger.warning(f"æ‰€æœ‰ç¬¬ä¸€é  URL éƒ½å¤±æ•—")
        return False
            
    except Exception as e:
        logger.error(f"ä¸‹è¼‰ç¬¬ä¸€é éŒ¯èª¤: {e}")
        return False


def get_first_image_as_cover(folder_path: Path) -> bool:
    """
    ä½¿ç”¨è³‡æ–™å¤¾å…§çš„ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢
    
    Args:
        folder_path: è³‡æ–™å¤¾è·¯å¾‘
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    try:
        # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp'}
        
        # æ‰¾åˆ°æ‰€æœ‰åœ–ç‰‡ï¼ˆæ’é™¤å·²æœ‰çš„ cover é–‹é ­æª”æ¡ˆï¼‰
        images = []
        for file in folder_path.iterdir():
            if file.is_file() and file.suffix.lower() in image_extensions:
                # æ’é™¤å°é¢æª”æ¡ˆ
                if not file.stem.lower().startswith('cover'):
                    images.append(file)
        
        if not images:
            logger.warning(f"è³‡æ–™å¤¾å…§æ²’æœ‰å¯ç”¨çš„åœ–ç‰‡: {folder_path}")
            return False
        
        # æŒ‰æª”åè‡ªç„¶æ’åºï¼Œå–ç¬¬ä¸€å¼µ
        images.sort(key=lambda x: natural_sort_key(x.name))
        first_image = images[0]
        
        # è¤‡è£½ç‚ºå°é¢
        cover_ext = first_image.suffix.lower()
        cover_path = folder_path / f"cover{cover_ext}"
        
        import shutil
        shutil.copy2(first_image, cover_path)
        logger.info(f"å·²ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢: {first_image.name} -> cover{cover_ext}")
        return True
        
    except Exception as e:
        logger.error(f"ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢å¤±æ•—: {e}")
        return False


def format_comment_time(timestamp: int) -> str:
    """æ ¼å¼åŒ–è©•è«–æ™‚é–“ç‚ºç›¸å°æ™‚é–“"""
    dt = datetime.fromtimestamp(timestamp)
    now = datetime.now()
    diff = now - dt
    
    if diff.days > 30:
        months = diff.days // 30
        weeks = (diff.days % 30) // 7
        if weeks > 0:
            return f"{months} å€‹æœˆ, {weeks} é€±å‰"
        return f"{months} å€‹æœˆå‰"
    elif diff.days > 7:
        weeks = diff.days // 7
        return f"{weeks} é€±å‰"
    elif diff.days > 0:
        return f"{diff.days} å¤©å‰"
    elif diff.seconds > 3600:
        return f"{diff.seconds // 3600} å°æ™‚å‰"
    else:
        return f"{diff.seconds // 60} åˆ†é˜å‰"


def format_comments_for_annotation(comments: list, max_comments: int = 5) -> str:
    """
    æ ¼å¼åŒ–è©•è«–ç”¨æ–¼ annotation
    
    Args:
        comments: è©•è«–åˆ—è¡¨
        max_comments: æœ€å¤§é¡¯ç¤ºè©•è«–æ•¸
    
    Returns:
        æ ¼å¼åŒ–çš„è©•è«–å­—ä¸²
    """
    if not comments:
        return ""
    
    lines = ["\nğŸ’¬ ç”¨æˆ¶è©•è«–:"]
    
    for i, comment in enumerate(comments[:max_comments]):
        username = comment.get('poster', {}).get('username', 'åŒ¿å')
        body = comment.get('body', '')
        post_date = comment.get('post_date', 0)
        time_str = format_comment_time(post_date) if post_date else ''
        
        lines.append(f"  [{username}] ({time_str})")
        lines.append(f"  {body}")
        if i < len(comments[:max_comments]) - 1:
            lines.append("")
    
    if len(comments) > max_comments:
        lines.append(f"  ... é‚„æœ‰ {len(comments) - max_comments} å‰‡è©•è«–")
    
    return "\n".join(lines)


def parse_gallery_dl_info(info_path: Path) -> Optional[Dict[str, Any]]:
    """
    è§£æ gallery-dl ç”Ÿæˆçš„ info.json æˆ– gallery_metadata.json
    
    gallery-dl --dump-json è¼¸å‡ºæ ¼å¼:
    {
        "title": "...",
        "title_en": "...",
        "title_ja": "...",
        "gallery_id": 123456,
        "count": 34,
        "type": "doujinshi",
        "artist": ["name"],
        "group": ["name"],
        "parody": ["name"],
        "characters": [],
        "language": "Chinese",
        "tags": ["tag1", "tag2", ...]
    }
    
    Args:
        info_path: info.json æª”æ¡ˆè·¯å¾‘
    
    Returns:
        è§£æå¾Œçš„ metadata å­—å…¸ï¼Œå¤±æ•—å‰‡è¿”å› None
    """
    try:
        with open(info_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # åˆå§‹åŒ–çµæœçµæ§‹ï¼ˆæ“´å±•ç‰ˆï¼‰
        result = {
            'title': '',
            'title_japanese': '',  # æ—¥æ–‡å‰¯æ¨™é¡Œ
            'title_pretty': '',    # ç°¡çŸ­æ¨™é¡Œ
            'tags': [],
            'url': '',
            'gallery_id': '',
            'pages': 0,
            'favorites': 0,
            'category': '',
            'type': '',
            'artist': [],
            'group': [],
            'parody': [],
            'character': [],
            'language': '',
        }
        
        # è™•ç† gallery-dl è¼¸å‡ºæ ¼å¼
        if isinstance(data, dict):
            # ===== æ¨™é¡Œè™•ç† =====
            # gallery-dl æ ¼å¼: title, title_en, title_ja éƒ½æ˜¯å­—ä¸²
            if 'title' in data:
                if isinstance(data['title'], dict):
                    # èˆŠç‰ˆ nhentai API æ ¼å¼: {"english": "...", "japanese": "...", "pretty": "..."}
                    result['title'] = (
                        data['title'].get('english') or 
                        data['title'].get('pretty') or 
                        data['title'].get('japanese') or 
                        ''
                    )
                    result['title_japanese'] = data['title'].get('japanese', '')
                    result['title_pretty'] = data['title'].get('pretty', '')
                else:
                    result['title'] = str(data['title'])
            
            # gallery-dl ä½¿ç”¨ title_en å’Œ title_ja
            if 'title_en' in data:
                if not result['title']:
                    result['title'] = data['title_en']
            
            if 'title_ja' in data:
                result['title_japanese'] = data['title_ja']
            
            # ===== Gallery ID =====
            if 'gallery_id' in data:
                result['gallery_id'] = str(data['gallery_id'])
            elif 'id' in data:
                result['gallery_id'] = str(data['id'])
            
            # ===== é æ•¸ =====
            # gallery-dl ä½¿ç”¨ countï¼Œnhentai API ä½¿ç”¨ num_pages
            if 'count' in data:
                result['pages'] = int(data['count'])
            elif 'num_pages' in data:
                result['pages'] = int(data['num_pages'])
            
            # ===== æ”¶è—æ•¸ =====
            if 'num_favorites' in data:
                result['favorites'] = int(data['num_favorites'])
            
            # ===== é¡å‹ (doujinshi, manga, etc.) =====
            if 'type' in data:
                result['type'] = data['type']
                result['category'] = data['type']  # å…¼å®¹èˆŠæ ¼å¼
            
            # ===== ä½œè€…åˆ—è¡¨ =====
            if 'artist' in data:
                if isinstance(data['artist'], list):
                    result['artist'] = data['artist']
                    for artist in data['artist']:
                        result['tags'].append(f"artist:{artist}")
                elif isinstance(data['artist'], str):
                    result['artist'] = [data['artist']]
                    result['tags'].append(f"artist:{data['artist']}")
            
            # ===== ç¤¾åœ˜åˆ—è¡¨ =====
            if 'group' in data:
                if isinstance(data['group'], list):
                    result['group'] = data['group']
                    for group in data['group']:
                        result['tags'].append(f"group:{group}")
                elif isinstance(data['group'], str):
                    result['group'] = [data['group']]
                    result['tags'].append(f"group:{data['group']}")
            
            # ===== åŸä½œåˆ—è¡¨ =====
            if 'parody' in data:
                if isinstance(data['parody'], list):
                    result['parody'] = data['parody']
                    for parody in data['parody']:
                        result['tags'].append(f"parody:{parody}")
                elif isinstance(data['parody'], str):
                    result['parody'] = [data['parody']]
                    result['tags'].append(f"parody:{data['parody']}")
            
            # ===== è§’è‰²åˆ—è¡¨ =====
            # gallery-dl ä½¿ç”¨ characters (è¤‡æ•¸)
            if 'characters' in data:
                if isinstance(data['characters'], list):
                    result['character'] = data['characters']
                    for char in data['characters']:
                        result['tags'].append(f"character:{char}")
            elif 'character' in data:
                if isinstance(data['character'], list):
                    result['character'] = data['character']
                    for char in data['character']:
                        result['tags'].append(f"character:{char}")
            
            # ===== èªè¨€ =====
            if 'language' in data:
                result['language'] = data['language']
                result['tags'].append(f"language:{data['language']}")
            
            # ===== æ¨™ç±¤è™•ç† =====
            if 'tags' in data:
                tags = data['tags']
                if isinstance(tags, list):
                    for tag in tags:
                        if isinstance(tag, dict):
                            # èˆŠç‰ˆ nhentai API æ ¼å¼: {type, name}
                            tag_name = tag.get('name', '')
                            tag_type = tag.get('type', '')
                            if tag_name:
                                if tag_type == 'category':
                                    result['category'] = tag_name
                                    result['tags'].append(f"category:{tag_name}")
                                elif tag_type == 'artist':
                                    if tag_name not in result['artist']:
                                        result['artist'].append(tag_name)
                                        result['tags'].append(f"artist:{tag_name}")
                                elif tag_type == 'group':
                                    if tag_name not in result['group']:
                                        result['group'].append(tag_name)
                                        result['tags'].append(f"group:{tag_name}")
                                elif tag_type == 'parody':
                                    if tag_name not in result['parody']:
                                        result['parody'].append(tag_name)
                                        result['tags'].append(f"parody:{tag_name}")
                                elif tag_type == 'character':
                                    if tag_name not in result['character']:
                                        result['character'].append(tag_name)
                                        result['tags'].append(f"character:{tag_name}")
                                elif tag_type == 'language':
                                    result['language'] = tag_name
                                    result['tags'].append(f"language:{tag_name}")
                                elif tag_type in ['tag', '']:
                                    result['tags'].append(tag_name)
                                else:
                                    result['tags'].append(f"{tag_type}:{tag_name}")
                        elif isinstance(tag, str):
                            # gallery-dl æ ¼å¼: ç›´æ¥å­—ä¸²é™£åˆ—
                            result['tags'].append(tag)
                elif isinstance(tags, str):
                    result['tags'] = [t.strip() for t in tags.split(',') if t.strip()]
            
            # ===== é¡å‹æ¨™ç±¤ =====
            if result['type']:
                result['tags'].append(f"type:{result['type']}")
            
            # ===== URL è™•ç† =====
            if 'gallery_url' in data:
                result['url'] = data['gallery_url']
            elif 'url' in data:
                result['url'] = data['url']
            
            # å˜—è©¦å¾ gallery_id æ§‹å»º URL
            if not result['url'] and result['gallery_id']:
                result['url'] = f"https://nhentai.net/g/{result['gallery_id']}/"
        
        # å»é™¤é‡è¤‡æ¨™ç±¤
        result['tags'] = list(dict.fromkeys(result['tags']))
        
        logger.info(f"è§£æåˆ°æ¨™é¡Œ: {result['title']}")
        logger.info(f"  æ—¥æ–‡æ¨™é¡Œ: {result['title_japanese']}")
        logger.info(f"  Gallery ID: {result['gallery_id']}, é æ•¸: {result['pages']}")
        logger.info(f"  ä½œè€…: {result['artist']}, ç¤¾åœ˜: {result['group']}")
        logger.info(f"  é¡å‹: {result['type']}, èªè¨€: {result['language']}")
        logger.info(f"  æ¨™ç±¤æ•¸: {len(result['tags'])}")
        return result
        
    except json.JSONDecodeError as e:
        logger.error(f"JSON è§£æéŒ¯èª¤: {e}")
        return None
    except Exception as e:
        logger.error(f"è§£æ info.json æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def create_eagle_metadata(
    title: str,
    url: str,
    tags: List[str],
    annotation: str = "",
    extra_info: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    å»ºç«‹ Eagle ç›¸å®¹çš„ metadata.json å…§å®¹
    
    Eagle æ¨™æº–æ¬„ä½ï¼š
    - id: å”¯ä¸€è­˜åˆ¥ç¢¼
    - name: åç¨±
    - tags: æ¨™ç±¤åˆ—è¡¨ (Array)
    - url / website: ä¾†æºç¶²å€
    - annotation: è¨»é‡‹/å‚™è¨» (å†—é•·è³‡è¨Šæ”¾é€™è£¡)
    
    Args:
        title: æ¼«ç•«æ¨™é¡Œ
        url: ä¾†æºç¶²å€
        tags: æ¨™ç±¤åˆ—è¡¨
        annotation: åŸºæœ¬å‚™è¨»
        extra_info: é¡å¤–è³‡è¨Šï¼ˆå‰¯æ¨™é¡Œã€é æ•¸ã€æ”¶è—æ•¸ç­‰ï¼‰
    
    Returns:
        Eagle metadata å­—å…¸
    """
    # å»ºç«‹å®Œæ•´çš„ tags åˆ—è¡¨
    all_tags = list(tags)  # è¤‡è£½åŸæœ‰æ¨™ç±¤
    
    # å»ºç«‹ annotation å…§å®¹
    annotation_lines = []
    
    if extra_info:
        # ===== åŠ å…¥é¡å¤–æ¨™ç±¤ =====
        # é¡å‹æ¨™ç±¤
        if extra_info.get('type'):
            type_tag = f"type:{extra_info['type']}"
            if type_tag not in all_tags:
                all_tags.append(type_tag)
        
        # èªè¨€æ¨™ç±¤
        if extra_info.get('language'):
            lang_tag = f"language:{extra_info['language']}"
            if lang_tag not in all_tags:
                all_tags.append(lang_tag)
        
        # ä½œè€…æ¨™ç±¤
        if extra_info.get('artist'):
            for artist in extra_info['artist']:
                artist_tag = f"artist:{artist}"
                if artist_tag not in all_tags:
                    all_tags.append(artist_tag)
        
        # ç¤¾åœ˜æ¨™ç±¤
        if extra_info.get('group'):
            for group in extra_info['group']:
                group_tag = f"group:{group}"
                if group_tag not in all_tags:
                    all_tags.append(group_tag)
        
        # åŸä½œæ¨™ç±¤
        if extra_info.get('parody'):
            for parody in extra_info['parody']:
                parody_tag = f"parody:{parody}"
                if parody_tag not in all_tags:
                    all_tags.append(parody_tag)
        
        # è§’è‰²æ¨™ç±¤
        if extra_info.get('character'):
            for char in extra_info['character']:
                char_tag = f"character:{char}"
                if char_tag not in all_tags:
                    all_tags.append(char_tag)
        
        # ===== å»ºç«‹ annotation å…§å®¹ =====
        # è‹±æ–‡æ¨™é¡Œï¼ˆå¦‚æœä¸»æ¨™é¡Œæ˜¯æ—¥æ–‡ï¼Œé¡¯ç¤ºè‹±æ–‡æ¨™é¡Œä½œç‚ºåƒè€ƒï¼‰
        if extra_info.get('title_english'):
            annotation_lines.append(f"ğŸ“– è‹±æ–‡æ¨™é¡Œ: {extra_info['title_english']}")
        
        # é æ•¸
        if extra_info.get('pages'):
            annotation_lines.append(f"ğŸ“„ é æ•¸: {extra_info['pages']}")
        
        # æ”¶è—æ•¸
        if extra_info.get('favorites') and extra_info['favorites'] > 0:
            annotation_lines.append(f"â¤ï¸ æ”¶è—æ•¸: {extra_info['favorites']}")
        
        # é¡å‹
        if extra_info.get('type'):
            annotation_lines.append(f"ğŸ“ é¡å‹: {extra_info['type']}")
        
        # èªè¨€
        if extra_info.get('language'):
            annotation_lines.append(f"ğŸŒ èªè¨€: {extra_info['language']}")
        
        # ä½œè€…
        if extra_info.get('artist'):
            annotation_lines.append(f"ğŸ¨ ä½œè€…: {', '.join(extra_info['artist'])}")
        
        # ç¤¾åœ˜
        if extra_info.get('group'):
            annotation_lines.append(f"ğŸ‘¥ ç¤¾åœ˜: {', '.join(extra_info['group'])}")
        
        # åŸä½œ
        if extra_info.get('parody'):
            annotation_lines.append(f"ğŸ¬ åŸä½œ: {', '.join(extra_info['parody'])}")
        
        # è§’è‰²
        if extra_info.get('character') and len(extra_info['character']) > 0:
            annotation_lines.append(f"ğŸ‘¤ è§’è‰²: {', '.join(extra_info['character'])}")
        
        # ID (æ”¾åœ¨è¼ƒä¸‹é¢)
        if extra_info.get('gallery_id'):
            annotation_lines.append(f"ğŸ“” ID: {extra_info['gallery_id']}")
        
        # ç”¨æˆ¶è©•è«–
        if extra_info.get('comments'):
            comments_text = format_comments_for_annotation(extra_info['comments'])
            if comments_text:
                annotation_lines.append(comments_text)
    
    # åŠ å…¥ä¸‹è¼‰æ™‚é–“
    annotation_lines.append(f"\nâ° ä¸‹è¼‰æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    annotation_lines.append("ğŸ“¥ Downloaded via HentaiFetcher Bot")
    
    # å¦‚æœæœ‰é¡å¤–çš„åŸºæœ¬å‚™è¨»ï¼ŒåŠ åœ¨æœ€å¾Œ
    if annotation and annotation != "Downloaded via HentaiFetcher Bot":
        annotation_lines.append(f"\n{annotation}")
    
    # å»é™¤é‡è¤‡æ¨™ç±¤
    all_tags = list(dict.fromkeys(all_tags))
    
    # å»ºç«‹æœ€çµ‚ metadata
    metadata = {
        "id": generate_eagle_id(),
        "name": title,
        "url": url,
        "tags": all_tags,
        "annotation": "\n".join(annotation_lines)
    }
    
    return metadata


def find_info_json(directory: Path) -> Optional[Path]:
    """
    éè¿´æœå°‹ info.json æª”æ¡ˆ
    
    Args:
        directory: æœå°‹èµ·å§‹ç›®éŒ„
    
    Returns:
        æ‰¾åˆ°çš„ info.json è·¯å¾‘ï¼Œæœªæ‰¾åˆ°å‰‡è¿”å› None
    """
    # å„ªå…ˆæœå°‹æˆ‘å€‘è‡ªå·±ç”Ÿæˆçš„ metadata æª”æ¡ˆ
    our_metadata = directory / "gallery_metadata.json"
    if our_metadata.exists():
        return our_metadata
    
    # ç›´æ¥åœ¨ç›®éŒ„ä¸‹æœå°‹
    for json_file in directory.rglob('*.json'):
        if json_file.name == 'info.json' or 'info' in json_file.name.lower():
            return json_file
    
    # ä¹Ÿå˜—è©¦æœå°‹å…¶ä»–å¯èƒ½çš„ metadata æª”æ¡ˆ
    for json_file in directory.rglob('*.json'):
        return json_file  # è¿”å›ç¬¬ä¸€å€‹æ‰¾åˆ°çš„ JSON
    
    return None


def find_images(directory: Path) -> List[Path]:
    """
    æœå°‹ç›®éŒ„ä¸‹çš„æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ
    
    Args:
        directory: æœå°‹ç›®éŒ„
    
    Returns:
        åœ–ç‰‡æª”æ¡ˆè·¯å¾‘åˆ—è¡¨ï¼ˆå·²æ’åºï¼‰
    """
    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp'}
    images = []
    
    for file in directory.rglob('*'):
        # æ’é™¤ .part æª”æ¡ˆï¼ˆæœªå®Œæˆçš„ä¸‹è¼‰ï¼‰
        if file.suffix.lower() in image_extensions and not file.name.endswith('.part'):
            images.append(file)
    
    # æŒ‰æª”åè‡ªç„¶æ’åº
    def natural_sort_key(path: Path):
        # æå–æ•¸å­—é€²è¡Œè‡ªç„¶æ’åº
        numbers = re.findall(r'\d+', path.stem)
        return [int(n) for n in numbers] if numbers else [path.stem]
    
    images.sort(key=natural_sort_key)
    return images


# ==================== ä¸‹è¼‰è™•ç†é¡åˆ¥ ====================

class DownloadProcessor:
    """
    ä¸‹è¼‰è™•ç†å™¨ï¼šè² è²¬åŸ·è¡Œ gallery-dlã€è½‰æ› PDF ä¸¦ç”Ÿæˆ metadata
    """
    
    def __init__(self, url: str, total_pages: int = 0, message_callback=None):
        """
        åˆå§‹åŒ–ä¸‹è¼‰è™•ç†å™¨
        
        Args:
            url: è¦ä¸‹è¼‰çš„ç¶²å€
            total_pages: é æœŸç¸½é æ•¸ï¼ˆç”¨æ–¼é€²åº¦è¨ˆç®—ï¼‰
            message_callback: ç‹€æ…‹æ›´æ–°å›èª¿å‡½å¼
        """
        self.url = url
        self.total_pages = total_pages
        self.message_callback = message_callback
        self.temp_path: Optional[Path] = None
        self.output_path: Optional[Path] = None
        self.last_error: str = ""
        self.download_complete = False  # ä¸‹è¼‰æ˜¯å¦å®Œæˆ
        self.pdf_progress = 0  # PDF è½‰æ›é€²åº¦ (0-100)
        self.pdf_converting = False  # æ˜¯å¦æ­£åœ¨è½‰æ› PDF
        
    def get_downloaded_count(self) -> int:
        """ç²å–å·²ä¸‹è¼‰çš„åœ–ç‰‡æ•¸é‡"""
        if not self.temp_path or not self.temp_path.exists():
            return 0
        return len(find_images(self.temp_path))
    
    def get_first_image_path(self) -> Path:
        """ç²å–ç¬¬ä¸€å¼µå·²ä¸‹è¼‰åœ–ç‰‡çš„è·¯å¾‘"""
        if not self.temp_path or not self.temp_path.exists():
            return None
        images = find_images(self.temp_path)
        if images:
            # æŒ‰æª”åæ’åºå–ç¬¬ä¸€å¼µ
            images.sort(key=lambda x: x.name)
            return images[0]
        return None
        
    async def send_status(self, message: str):
        """ç™¼é€ç‹€æ…‹è¨Šæ¯"""
        logger.info(message)
        if self.message_callback:
            try:
                await self.message_callback(message)
            except Exception as e:
                logger.warning(f"ç„¡æ³•ç™¼é€ç‹€æ…‹è¨Šæ¯: {e}")
    
    def download_with_gallery_dl(self) -> bool:
        """
        ä½¿ç”¨ gallery-dl ä¸‹è¼‰åœ–ç‰‡å’Œ metadata
        
        Returns:
            æˆåŠŸè¿”å› Trueï¼Œå¤±æ•—è¿”å› False
        """
        try:
            # å»ºç«‹å”¯ä¸€çš„æš«å­˜ç›®éŒ„ï¼ˆçµ±ä¸€ä½¿ç”¨ TEMP_DIRï¼‰
            self.temp_path = TEMP_DIR / f"dl_{int(time.time() * 1000)}"
            self.temp_path.mkdir(parents=True, exist_ok=True)
            
            print(f"[GALLERY-DL] ä¸‹è¼‰ç›®éŒ„: {self.temp_path}", flush=True)
            
            # æ ¹æ“šç’°å¢ƒé¸æ“‡ gallery-dl åŸ·è¡Œæ–¹å¼èˆ‡åƒæ•¸
            if IS_DOCKER:
                # Docker ç’°å¢ƒï¼šå…©éšæ®µä¸‹è¼‰
                # éšæ®µ 1: ä½¿ç”¨ gallery-dl --dump-json ç²å– metadata
                print(f"[GALLERY-DL] éšæ®µ1: ç²å– metadata...", flush=True)
                metadata_cmd = [
                    'gallery-dl',
                    '--dump-json',
                    '--user-agent', 'Mozilla/5.0',
                    self.url
                ]
                
                metadata_result = subprocess.run(
                    metadata_cmd,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                # è§£æä¸¦å„²å­˜ metadata
                if metadata_result.returncode == 0 and metadata_result.stdout.strip():
                    try:
                        # gallery-dl --dump-json è¼¸å‡ºçš„æ˜¯ JSON é™£åˆ—
                        metadata_list = json.loads(metadata_result.stdout)
                        if metadata_list and len(metadata_list) > 0:
                            # å–ç¬¬ä¸€å€‹å…ƒç´ çš„ metadataï¼ˆé€šå¸¸åŒ…å« gallery infoï¼‰
                            first_item = metadata_list[0]
                            if isinstance(first_item, list) and len(first_item) >= 2:
                                gallery_metadata = first_item[1]  # [url, metadata] æ ¼å¼
                            else:
                                gallery_metadata = first_item
                            
                            # å„²å­˜ metadata åˆ°æš«å­˜ç›®éŒ„
                            metadata_file = self.temp_path / "gallery_metadata.json"
                            with open(metadata_file, 'w', encoding='utf-8') as f:
                                json.dump(gallery_metadata, f, ensure_ascii=False, indent=2)
                            print(f"[GALLERY-DL] Metadata å·²å„²å­˜: {metadata_file}", flush=True)
                    except json.JSONDecodeError as e:
                        print(f"[GALLERY-DL] Metadata è§£æå¤±æ•—: {e}", flush=True)
                
                # éšæ®µ 2: ä½¿ç”¨ gallery-dl -g + aria2c å¤šç·šç¨‹ä¸‹è¼‰åœ–ç‰‡
                print(f"[GALLERY-DL] éšæ®µ2: å¤šç·šç¨‹ä¸‹è¼‰åœ–ç‰‡...", flush=True)
                cmd = (
                    f'gallery-dl --user-agent "Mozilla/5.0" -g "{self.url}" | '
                    f'aria2c -i - -x 8 -s 8 --user-agent="Mozilla/5.0" -d "{self.temp_path}"'
                )
                
                logger.info(f"åŸ·è¡ŒæŒ‡ä»¤: {cmd}")
                print(f"[GALLERY-DL+ARIA2] å‘½ä»¤: {cmd}", flush=True)
                
                # ä½¿ç”¨ shell=True åŸ·è¡Œç®¡é“å‘½ä»¤
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=900
                )
            else:
                # Windows ç’°å¢ƒï¼šå…©éšæ®µä¸‹è¼‰
                # éšæ®µ 1: ä½¿ç”¨ gallery-dl --dump-json ç²å– metadata
                print(f"[GALLERY-DL] éšæ®µ1: ç²å– metadata...", flush=True)
                metadata_cmd = [
                    sys.executable,
                    '-m', 'gallery_dl',
                    '--dump-json',
                    self.url
                ]
                
                metadata_result = subprocess.run(
                    metadata_cmd,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                # è§£æä¸¦å„²å­˜ metadata
                if metadata_result.returncode == 0 and metadata_result.stdout.strip():
                    try:
                        metadata_list = json.loads(metadata_result.stdout)
                        if metadata_list and len(metadata_list) > 0:
                            first_item = metadata_list[0]
                            if isinstance(first_item, list) and len(first_item) >= 2:
                                gallery_metadata = first_item[1]
                            else:
                                gallery_metadata = first_item
                            
                            metadata_file = self.temp_path / "gallery_metadata.json"
                            with open(metadata_file, 'w', encoding='utf-8') as f:
                                json.dump(gallery_metadata, f, ensure_ascii=False, indent=2)
                            print(f"[GALLERY-DL] Metadata å·²å„²å­˜: {metadata_file}", flush=True)
                    except json.JSONDecodeError as e:
                        print(f"[GALLERY-DL] Metadata è§£æå¤±æ•—: {e}", flush=True)
                
                # éšæ®µ 2: ä¸‹è¼‰åœ–ç‰‡
                print(f"[GALLERY-DL] éšæ®µ2: ä¸‹è¼‰åœ–ç‰‡...", flush=True)
                cmd = [
                    sys.executable,
                    '-m', 'gallery_dl',
                    '--dest', str(self.temp_path),
                    '--write-metadata',
                    self.url
                ]
                
                logger.info(f"åŸ·è¡ŒæŒ‡ä»¤: {' '.join(cmd)}")
                print(f"[GALLERY-DL] å‘½ä»¤: {cmd}", flush=True)
                
                # åŸ·è¡Œ gallery-dl å‘½ä»¤
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=900
                )
            print(f"[GALLERY-DL] åŸ·è¡Œå®Œæˆ", flush=True)
            
            # å¼·åˆ¶è¼¸å‡ºæ‰€æœ‰ gallery-dl æ—¥èªŒï¼ˆç”¨æ–¼é™¤éŒ¯ï¼‰
            print(f"[GALLERY-DL] URL: {self.url}", flush=True)
            print(f"[GALLERY-DL] è¿”å›ç¢¼: {result.returncode}", flush=True)
            print(f"[GALLERY-DL] STDOUT: {result.stdout[:2000] if result.stdout else '(ç©º)'}", flush=True)
            print(f"[GALLERY-DL] STDERR: {result.stderr[:2000] if result.stderr else '(ç©º)'}", flush=True)
            
            if result.returncode != 0:
                logger.error(f"gallery-dl è¿”å›ç¢¼: {result.returncode}")
                logger.error(f"gallery-dl STDERR: {result.stderr}")
                logger.error(f"gallery-dl STDOUT: {result.stdout}")
                
                # å„²å­˜è©³ç´°éŒ¯èª¤è¨Šæ¯ä¾› Discord å›å ±
                # cmd åœ¨ Docker ç’°å¢ƒæ˜¯å­—ä¸²ï¼ŒWindows ç’°å¢ƒæ˜¯åˆ—è¡¨
                cmd_str = cmd if isinstance(cmd, str) else ' '.join(cmd)
                error_lines = [
                    f"\u26a0\ufe0f **Debug è³‡è¨Š**",
                    f"\ud83d\udce6 ç‰ˆæœ¬: {VERSION}",
                    f"\ud83d\udcbb ç’°å¢ƒ: {'Docker' if IS_DOCKER else 'Windows'}",
                    f"\ud83d\udcc2 ä¸‹è¼‰ç›®éŒ„: `{self.temp_path}`",
                    f"\ud83d\udd27 åŸ·è¡Œå‘½ä»¤: `{cmd_str}`",
                    f"\ud83d\udd34 è¿”å›ç¢¼: {result.returncode}",
                ]
                
                if result.stderr:
                    error_lines.append(f"\n**STDERR:**\n```\n{result.stderr[:800]}\n```")
                if result.stdout:
                    error_lines.append(f"\n**STDOUT:**\n```\n{result.stdout[:800]}\n```")
                
                self.last_error = "\n".join(error_lines)
                return False
            
            logger.info(f"gallery-dl è¼¸å‡º: {result.stdout}")
            return True
            
        except subprocess.TimeoutExpired:
            logger.error("gallery-dl åŸ·è¡Œè¶…æ™‚")
            return False
        except Exception as e:
            logger.error(f"gallery-dl åŸ·è¡ŒéŒ¯èª¤: {e}")
            return False
    
    def convert_to_pdf(self, images: List[Path], output_pdf: Path) -> bool:
        """
        ä½¿ç”¨ Pillow å°‡åœ–ç‰‡è½‰æ›ç‚ºç­‰å¯¬ PDFï¼ˆæ”¯æ´é€²åº¦å›å ±ï¼‰
        
        æ‰€æœ‰åœ–ç‰‡æœƒè¢«èª¿æ•´ç‚ºçµ±ä¸€å¯¬åº¦ï¼ˆä½¿ç”¨æœ€å¤§å¯¬åº¦ï¼‰ï¼Œé«˜åº¦æŒ‰æ¯”ä¾‹ç¸®æ”¾ï¼Œ
        ç¢ºä¿ PDF æ¯ä¸€é éƒ½æ˜¯ 100% å¯¬åº¦å°é½Šã€‚
        
        Args:
            images: åœ–ç‰‡æª”æ¡ˆåˆ—è¡¨
            output_pdf: è¼¸å‡º PDF è·¯å¾‘
        
        Returns:
            æˆåŠŸè¿”å› Trueï¼Œå¤±æ•—è¿”å› False
        """
        if not images:
            logger.error("æ²’æœ‰åœ–ç‰‡å¯ä¾›è½‰æ›")
            return False
        
        try:
            from PIL import Image
            
            self.pdf_converting = True
            self.pdf_progress = 0
            
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
            output_pdf.parent.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"è½‰æ› {len(images)} å¼µåœ–ç‰‡ç‚ºç­‰å¯¬ PDF")
            
            total = len(images)
            
            # éšæ®µ 1: è®€å–æ‰€æœ‰åœ–ç‰‡ä¸¦æ‰¾å‡ºæœ€å¤§å¯¬åº¦ (0-20%)
            logger.info("éšæ®µ 1/3: åˆ†æåœ–ç‰‡å°ºå¯¸...")
            pil_images = []
            max_width = 0
            
            for i, img_path in enumerate(images):
                img = Image.open(img_path)
                # è½‰æ›ç‚º RGBï¼ˆPDF ä¸æ”¯æ´ RGBA é€æ˜é€šé“ï¼‰
                if img.mode in ('RGBA', 'P', 'LA'):
                    # å»ºç«‹ç™½è‰²èƒŒæ™¯
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    if img.mode in ('RGBA', 'LA'):
                        background.paste(img, mask=img.split()[-1])  # ä½¿ç”¨ alpha é€šé“ä½œç‚ºé®ç½©
                        img = background
                    else:
                        img = img.convert('RGB')
                elif img.mode != 'RGB':
                    img = img.convert('RGB')
                
                pil_images.append(img)
                if img.width > max_width:
                    max_width = img.width
                
                self.pdf_progress = int((i + 1) / total * 20)
                if (i + 1) % 10 == 0:
                    time.sleep(0.05)
            
            logger.info(f"çµ±ä¸€å¯¬åº¦: {max_width}px")
            
            # éšæ®µ 2: èª¿æ•´æ‰€æœ‰åœ–ç‰‡ç‚ºç­‰å¯¬ (20-70%)
            logger.info("éšæ®µ 2/3: èª¿æ•´åœ–ç‰‡ç‚ºç­‰å¯¬...")
            resized_images = []
            
            for i, img in enumerate(pil_images):
                if img.width != max_width:
                    # æŒ‰æ¯”ä¾‹ç¸®æ”¾åˆ°ç›®æ¨™å¯¬åº¦
                    ratio = max_width / img.width
                    new_height = int(img.height * ratio)
                    # ä½¿ç”¨é«˜å“è³ªç¸®æ”¾
                    resized_img = img.resize((max_width, new_height), Image.Resampling.LANCZOS)
                    resized_images.append(resized_img)
                else:
                    resized_images.append(img)
                
                self.pdf_progress = 20 + int((i + 1) / total * 50)
                if (i + 1) % 10 == 0:
                    time.sleep(0.05)
            
            # éšæ®µ 3: å„²å­˜ç‚º PDF (70-100%)
            logger.info("éšæ®µ 3/3: ç”Ÿæˆ PDF...")
            self.pdf_progress = 75
            
            # ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºåŸºåº•ï¼Œå…¶é¤˜ append
            first_image = resized_images[0]
            rest_images = resized_images[1:] if len(resized_images) > 1 else []
            
            first_image.save(
                output_pdf,
                "PDF",
                save_all=True,
                append_images=rest_images,
                resolution=100.0
            )
            
            # æ¸…ç†è¨˜æ†¶é«” - ä½¿ç”¨ set è¿½è¹¤å·²é—œé–‰çš„åœ–ç‰‡ idï¼Œé¿å…æ¯”è¼ƒæ“ä½œ
            closed_ids = set()
            for img in pil_images:
                if id(img) not in closed_ids:
                    try:
                        img.close()
                    except Exception:
                        pass
                    closed_ids.add(id(img))
            for img in resized_images:
                if id(img) not in closed_ids:
                    try:
                        img.close()
                    except Exception:
                        pass
                    closed_ids.add(id(img))
            
            self.pdf_progress = 100
            self.pdf_converting = False
            
            # ç¢ºèª PDF å·²ç”Ÿæˆ
            if output_pdf.exists() and output_pdf.stat().st_size > 0:
                logger.info(f"PDF ç”ŸæˆæˆåŠŸ: {output_pdf}")
                return True
            else:
                logger.error("PDF æª”æ¡ˆæœªç”Ÿæˆæˆ–ç‚ºç©º")
                return False
                
        except Exception as e:
            logger.error(f"PDF è½‰æ›éŒ¯èª¤: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.pdf_converting = False
            return False
    
    def process(self) -> tuple[bool, str]:
        """
        åŸ·è¡Œå®Œæ•´çš„ä¸‹è¼‰è™•ç†æµç¨‹
        
        Returns:
            (æˆåŠŸç‹€æ…‹, çµæœè¨Šæ¯)
        """
        start_time = time.time()  # é–‹å§‹è¨ˆæ™‚
        
        try:
            # æ­¥é©Ÿ 1: ä¸‹è¼‰
            logger.info(f"é–‹å§‹ä¸‹è¼‰: {self.url}")
            print(f"[PROCESS] é–‹å§‹ä¸‹è¼‰: {self.url}", flush=True)
            if not self.download_with_gallery_dl():
                error_detail = self.last_error if self.last_error else "æœªçŸ¥åŸå› "
                elapsed = time.time() - start_time
                return False, f"âŒ ä¸‹è¼‰å¤±æ•—\nğŸ”— {self.url}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s\n\n{error_detail}"
            
            # å°‹æ‰¾ä¸‹è¼‰çš„å…§å®¹
            # gallery-dl å¯èƒ½æœƒå»ºç«‹å­ç›®éŒ„
            print(f"[PROCESS] æœå°‹åœ–ç‰‡ç›®éŒ„: {self.temp_path}", flush=True)
            images = find_images(self.temp_path)
            print(f"[PROCESS] æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡", flush=True)
            
            if not images:
                # åˆ—å‡ºç›®éŒ„å…§å®¹ä»¥ä¾¿é™¤éŒ¯
                try:
                    all_files = list(self.temp_path.rglob('*'))
                    print(f"[DEBUG] ç›®éŒ„å…§æ‰€æœ‰æª”æ¡ˆ: {[str(f) for f in all_files[:20]]}", flush=True)
                except Exception as e:
                    print(f"[DEBUG] ç„¡æ³•åˆ—å‡ºç›®éŒ„: {e}", flush=True)
                elapsed = time.time() - start_time
                return False, f"âŒ æ‰¾ä¸åˆ°ä¸‹è¼‰çš„åœ–ç‰‡\nğŸ”— {self.url}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s"
            
            logger.info(f"æ‰¾åˆ° {len(images)} å¼µåœ–ç‰‡")
            
            # æ­¥é©Ÿ 2: è§£æ metadata
            info_json = find_info_json(self.temp_path)
            
            if info_json:
                metadata = parse_gallery_dl_info(info_json)
            else:
                logger.warning("æ‰¾ä¸åˆ° info.jsonï¼Œä½¿ç”¨é è¨­ metadata")
                metadata = None
            
            # è¨­å®šæ¨™é¡Œ - å„ªå…ˆä½¿ç”¨æ—¥æ–‡æ¨™é¡Œ
            if metadata:
                # å„ªå…ˆé †åº: æ—¥æ–‡æ¨™é¡Œ > è‹±æ–‡æ¨™é¡Œ > URL ID
                if metadata.get('title_japanese'):
                    title = metadata['title_japanese']
                    logger.info(f"ä½¿ç”¨æ—¥æ–‡æ¨™é¡Œ: {title}")
                elif metadata.get('title'):
                    title = metadata['title']
                    logger.info(f"ä½¿ç”¨è‹±æ–‡æ¨™é¡Œ: {title}")
                else:
                    title = None
            else:
                title = None
            
            if not title:
                # å˜—è©¦å¾ URL æå– ID ä½œç‚ºæ¨™é¡Œ
                match = re.search(r'/g/(\d+)', self.url)
                if match:
                    title = f"Gallery_{match.group(1)}"
                else:
                    title = f"Download_{int(time.time())}"
            
            safe_title = sanitize_filename(title)
            logger.info(f"ä½¿ç”¨æ¨™é¡Œ: {safe_title}")
            
            # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
            self.output_path = DOWNLOAD_DIR / safe_title
            
            # å¦‚æœè³‡æ–™å¤¾å·²å­˜åœ¨ï¼Œä½¿ç”¨æ™‚é–“æˆ³å‘½åé¿å…è¦†è“‹
            if self.output_path.exists():
                self.output_path = DOWNLOAD_DIR / f"{safe_title}_{int(time.time())}"
                logger.info(f"è³‡æ–™å¤¾å·²å­˜åœ¨ï¼Œä½¿ç”¨æ–°è³‡æ–™å¤¾ {self.output_path}")
            
            self.output_path.mkdir(parents=True, exist_ok=True)
            
            # æ­¥é©Ÿ 3: è½‰æ›ç‚º PDF
            pdf_path = self.output_path / f"{safe_title}.pdf"
            if not self.convert_to_pdf(images, pdf_path):
                return False, "âŒ PDF è½‰æ›å¤±æ•—"
            
            # æ­¥é©Ÿ 3.5: è¤‡è£½ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢
            if images:
                try:
                    first_image = images[0]
                    # ç²å–å‰¯æª”å
                    ext = first_image.suffix  # ä¾‹å¦‚ .jpg, .png
                    cover_path = self.output_path / f"cover{ext}"
                    # è¤‡è£½ç¬¬ä¸€å¼µåœ–ç‰‡
                    shutil.copy2(first_image, cover_path)
                    logger.info(f"å°é¢å·²ä¿å­˜: {cover_path.name}")
                except Exception as e:
                    logger.warning(f"ä¿å­˜å°é¢å¤±æ•—: {e}")
            
            # æ­¥é©Ÿ 4: ç²å–é¡å¤–è³‡è¨Šï¼ˆæ”¶è—æ•¸ã€è©•è«–ï¼‰
            gallery_id = metadata.get('gallery_id', '') if metadata else ''
            if not gallery_id:
                # å˜—è©¦å¾ URL æå–
                match = re.search(r'/g/(\d+)', self.url)
                if match:
                    gallery_id = match.group(1)
            
            nhentai_extra = {}
            if gallery_id:
                logger.info(f"ç²å– nhentai é¡å¤–è³‡è¨Š (ID: {gallery_id})...")
                nhentai_extra = fetch_nhentai_extra_info(gallery_id)
            
            # æ­¥é©Ÿ 5: ç”Ÿæˆ Eagle metadataï¼ˆåŒ…å«æ“´å±•è³‡è¨Šï¼‰
            extra_info = None
            if metadata:
                extra_info = {
                    'title_japanese': metadata.get('title_japanese', ''),
                    'title_english': metadata.get('title', ''),  # è‹±æ–‡æ¨™é¡Œæ”¾ annotation
                    'title_pretty': metadata.get('title_pretty', ''),
                    'gallery_id': metadata.get('gallery_id', ''),
                    'pages': metadata.get('pages', 0),
                    'favorites': nhentai_extra.get('favorites', 0),  # å¾ API ç²å–
                    'category': metadata.get('category', ''),
                    'type': metadata.get('type', ''),
                    'artist': metadata.get('artist', []),
                    'group': metadata.get('group', []),
                    'parody': metadata.get('parody', []),
                    'character': metadata.get('character', []),
                    'language': metadata.get('language', ''),
                    'comments': nhentai_extra.get('comments', []),  # è©•è«–
                }
            
            eagle_metadata = create_eagle_metadata(
                title=title,  # å·²ç¶“æ˜¯æ—¥æ–‡æ¨™é¡Œå„ªå…ˆ
                url=metadata.get('url', self.url) if metadata else self.url,
                tags=metadata.get('tags', []) if metadata else [],
                annotation="",
                extra_info=extra_info
            )
            
            metadata_path = self.output_path / "metadata.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(eagle_metadata, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Eagle metadata å·²ç”Ÿæˆ: {metadata_path}")
            
            # æ­¥é©Ÿ 5: æ¸…ç†æš«å­˜æª”æ¡ˆ
            if self.temp_path and self.temp_path.exists():
                shutil.rmtree(self.temp_path)
                logger.info(f"å·²æ¸…ç†æš«å­˜ç›®éŒ„: {self.temp_path}")
            
            # è¨ˆç®—è€—æ™‚
            elapsed = time.time() - start_time
            if elapsed >= 60:
                elapsed_str = f"{int(elapsed // 60)}åˆ†{int(elapsed % 60)}ç§’"
            else:
                elapsed_str = f"{elapsed:.1f}ç§’"
            
            # ç²å–é æ•¸
            page_count = metadata.get('pages', len(images)) if metadata else len(images)
            
            # è½‰æ›è·¯å¾‘ç‚ºå­—ä¸²ï¼Œç¢ºä¿ UNC è·¯å¾‘æ­£ç¢ºé¡¯ç¤º
            output_path_str = str(self.output_path)
            if output_path_str.startswith('\\\\'):
                output_path_str = output_path_str  # å·²ç¶“æ˜¯æ­£ç¢ºçš„ UNC è·¯å¾‘
            elif output_path_str.startswith('\\') and not output_path_str.startswith('\\\\'):
                output_path_str = '\\' + output_path_str  # è£œä¸Šç¼ºå°‘çš„æ–œç·š
            
            # ç”Ÿæˆ PDF Web é€£çµ - ä½¿ç”¨å¯¦éš›è³‡æ–™å¤¾åç¨±ï¼ˆå¯èƒ½æœ‰æ™‚é–“æˆ³å¾Œç¶´ï¼‰
            from urllib.parse import quote
            folder_name = self.output_path.name  # ä½¿ç”¨å¯¦éš›è³‡æ–™å¤¾åç¨±
            pdf_filename = f"{safe_title}.pdf"
            pdf_web_url = f"{PDF_WEB_BASE_URL}/{quote(folder_name)}/{quote(pdf_filename)}"
            
            # æ¨™é¡ŒåµŒå…¥é€£çµï¼Œè®“ä½¿ç”¨è€…å¯ä»¥ç›´æ¥é»æ“Šè§€çœ‹ PDF
            return True, f"âœ… å®Œæˆ: [{safe_title}]({pdf_web_url})\nğŸ“„ {page_count}é  â±ï¸ {elapsed_str}\nğŸ“ {output_path_str}"
            
        except Exception as e:
            logger.exception(f"è™•ç†éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            
            # è¨ˆç®—è€—æ™‚
            elapsed = time.time() - start_time
            
            # æ¸…ç†æš«å­˜æª”æ¡ˆ
            if self.temp_path and self.temp_path.exists():
                try:
                    shutil.rmtree(self.temp_path)
                except Exception:
                    pass
            
            return False, f"âŒ éŒ¯èª¤: {str(e)}\nâ±ï¸ è€—æ™‚: {elapsed:.1f}s"


# ==================== Worker Thread ====================

class DownloadWorker(threading.Thread):
    """
    ä¸‹è¼‰å·¥ä½œåŸ·è¡Œç·’ï¼šå¾ä½‡åˆ—ä¸­å–å‡ºä»»å‹™ä¸¦åŸ·è¡Œ
    """
    
    def __init__(self, bot):
        super().__init__(daemon=True)
        self.bot = bot
        self.running = True
        self.current_task: Optional[str] = None  # æ­£åœ¨è™•ç†çš„ URL
    
    def run(self):
        """å·¥ä½œåŸ·è¡Œç·’ä¸»è¿´åœˆ"""
        logger.info("ä¸‹è¼‰å·¥ä½œåŸ·è¡Œç·’å·²å•Ÿå‹•")
        
        while self.running:
            try:
                # å¾ä½‡åˆ—å–å¾—ä»»å‹™ï¼ˆé˜»å¡å¼ç­‰å¾…ï¼Œ1ç§’è¶…æ™‚ï¼‰
                task = download_queue.get(timeout=1)
                
                if task is None:
                    continue
                
                # æ”¯æ´æ ¼å¼: (url, channel_id), (url, channel_id, status_msg_id), æˆ– (url, channel_id, status_msg_id, test_mode)
                if len(task) == 4:
                    url, channel_id, status_msg_id, test_mode = task
                elif len(task) == 3:
                    url, channel_id, status_msg_id = task
                    test_mode = False
                else:
                    url, channel_id = task
                    status_msg_id = None
                    test_mode = False
                
                self.current_task = url
                logger.info(f"è™•ç†ä¸‹è¼‰ä»»å‹™: {url}")
                
                # æå– gallery ID ä¸¦ç²å–é æ•¸ï¼Œç™¼é€é–‹å§‹è¨Šæ¯
                start_msg_id = None
                pages = 0
                title = ""
                media_id = ""
                match = re.search(r'/g/(\d+)', url)
                if match:
                    gallery_id = match.group(1)
                    pages, title, media_id = get_nhentai_page_count(gallery_id)
                    if pages > 0:
                        # ç™¼é€é–‹å§‹ä¸‹è¼‰è¨Šæ¯ï¼ˆåŒ…å«é æ•¸å’Œé ä¼°æ™‚é–“ï¼‰ï¼Œä¸¦è¿”å›è¨Šæ¯ ID
                        future = asyncio.run_coroutine_threadsafe(
                            self.send_start_message(channel_id, gallery_id, pages, title, media_id),
                            self.bot.loop
                        )
                        start_msg_id = future.result(timeout=10)
                
                # å‰µå»ºä¸‹è¼‰è™•ç†å™¨
                processor = DownloadProcessor(url, total_pages=pages)
                
                # å•Ÿå‹•é€²åº¦ç›£æ§åŸ·è¡Œç·’
                progress_stop_event = threading.Event()
                if start_msg_id and pages > 0:
                    progress_thread = threading.Thread(
                        target=self._monitor_progress,
                        args=(processor, channel_id, start_msg_id, pages, title, gallery_id, media_id, progress_stop_event),
                        daemon=True
                    )
                    progress_thread.start()
                
                # åŸ·è¡Œä¸‹è¼‰è™•ç†
                success, message = processor.process()
                
                # åœæ­¢é€²åº¦ç›£æ§
                progress_stop_event.set()
                
                # æ›´æ–°é–‹å§‹ä¸‹è¼‰è¨Šæ¯ï¼ˆé¡¯ç¤ºæœ€çµ‚ç‹€æ…‹ï¼‰
                if start_msg_id:
                    asyncio.run_coroutine_threadsafe(
                        self.update_final_progress(channel_id, start_msg_id, success, pages, title, media_id),
                        self.bot.loop
                    )
                
                # ç™¼é€çµæœåˆ° Discord
                asyncio.run_coroutine_threadsafe(
                    self.send_result(channel_id, message),
                    self.bot.loop
                )
                
                self.current_task = None
                download_queue.task_done()
            
            except Empty:
                # ä½‡åˆ—ç‚ºç©ºï¼Œé€™æ˜¯æ­£å¸¸çš„ï¼Œç¹¼çºŒç­‰å¾…
                continue
                
            except Exception as e:
                self.current_task = None
                logger.exception(f"å·¥ä½œåŸ·è¡Œç·’éŒ¯èª¤: {e}")
    
    def _monitor_progress(self, processor: DownloadProcessor, channel_id: int, 
                          message_id: int, total_pages: int, title: str, 
                          gallery_id: str, media_id: str, stop_event: threading.Event):
        """
        ç›£æ§ä¸‹è¼‰é€²åº¦ä¸¦æ›´æ–° Discord è¨Šæ¯
        
        åœ¨èƒŒæ™¯åŸ·è¡Œç·’ä¸­å®šæœŸæª¢æŸ¥å·²ä¸‹è¼‰çš„åœ–ç‰‡æ•¸é‡ï¼Œä¸¦ç·¨è¼¯è¨Šæ¯é¡¯ç¤ºé€²åº¦æ¢
        """
        last_count = 0
        last_pdf_progress = -1
        start_time = time.time()
        pdf_start_time = None  # PDF è½‰æ›é–‹å§‹æ™‚é–“
        first_image_sent = False  # è¿½è¹¤æ˜¯å¦å·²ç™¼é€ç¬¬ä¸€å¼µåœ–ç‰‡
        pdf_mode = False  # æ˜¯å¦é€²å…¥ PDF æ¨¡å¼
        
        while not stop_event.is_set():
            try:
                # æ ¹æ“šæ¨¡å¼èª¿æ•´æª¢æŸ¥é–“éš”
                check_interval = 1 if pdf_mode else PROGRESS_UPDATE_INTERVAL
                
                # ç­‰å¾…ä¸€æ®µæ™‚é–“
                if stop_event.wait(timeout=check_interval):
                    break  # æ”¶åˆ°åœæ­¢ä¿¡è™Ÿ
                
                # æª¢æŸ¥æ˜¯å¦åœ¨ PDF è½‰æ›éšæ®µ
                if processor.pdf_converting:
                    pdf_mode = True
                    pdf_progress = processor.pdf_progress
                    
                    # è¨˜éŒ„ PDF é–‹å§‹æ™‚é–“
                    if pdf_start_time is None:
                        pdf_start_time = time.time()
                    
                    if pdf_progress != last_pdf_progress:
                        last_pdf_progress = pdf_progress
                        
                        # è¨ˆç®— PDF é ä¼°å‰©é¤˜æ™‚é–“
                        pdf_eta_str = "è¨ˆç®—ä¸­..."
                        if pdf_progress > 0:
                            pdf_elapsed = time.time() - pdf_start_time
                            pdf_eta_seconds = (pdf_elapsed / pdf_progress) * (100 - pdf_progress)
                            if pdf_eta_seconds >= 60:
                                pdf_eta_str = f"{int(pdf_eta_seconds // 60)}åˆ†{int(pdf_eta_seconds % 60)}ç§’"
                            else:
                                pdf_eta_str = f"{int(pdf_eta_seconds)}ç§’"
                        
                        # é¡¯ç¤º PDF è½‰æ›é€²åº¦
                        pdf_bar = create_progress_bar(pdf_progress, 100)
                        # ä¸‹è¼‰é€²åº¦æ¢ä¿æŒ 100%
                        download_bar = create_progress_bar(total_pages, total_pages)
                        
                        asyncio.run_coroutine_threadsafe(
                            self.update_pdf_progress_message(
                                channel_id, message_id, 
                                pdf_progress, pdf_bar, download_bar, total_pages, title, pdf_eta_str
                            ),
                            self.bot.loop
                        )
                    continue
                
                # ç²å–å·²ä¸‹è¼‰æ•¸é‡
                current_count = processor.get_downloaded_count()
                
                # ç­‰ç¬¬ 3 å¼µåœ–ç‰‡ä¸‹è¼‰å®Œæˆå¾Œï¼Œç™¼é€ç¬¬ä¸€å¼µåœ–ç‰‡ï¼ˆç¢ºä¿ç¬¬ä¸€å¼µå·²å®Œæ•´ä¸‹è¼‰ï¼‰
                if current_count >= 3 and not first_image_sent:
                    first_image_sent = True
                    # ç­‰å¾… 1 ç§’ç¢ºä¿ NAS å¯«å…¥å®Œæˆ
                    time.sleep(1)
                    first_image = processor.get_first_image_path()
                    # ç¢ºèªæª”æ¡ˆå¤§å°å¤§æ–¼ 0
                    if first_image and first_image.exists() and first_image.stat().st_size > 0:
                        asyncio.run_coroutine_threadsafe(
                            self.send_cover_image(channel_id, first_image),
                            self.bot.loop
                        )
                
                # ä¸‹è¼‰å®Œæˆæ™‚ï¼Œåˆ‡æ›åˆ°æ›´é »ç¹çš„æª¢æŸ¥æ¨¡å¼ä»¥åµæ¸¬ PDF è½‰æ›
                if current_count >= total_pages:
                    pdf_mode = True
                
                # åªæœ‰é€²åº¦æœ‰è®ŠåŒ–æ™‚æ‰æ›´æ–°
                if current_count != last_count and current_count > 0:
                    last_count = current_count
                    
                    # è¨ˆç®—é€²åº¦å’Œé ä¼°å‰©é¤˜æ™‚é–“
                    progress_bar = create_progress_bar(current_count, total_pages)
                    elapsed = time.time() - start_time
                    
                    if current_count > 0:
                        avg_time_per_page = elapsed / current_count
                        remaining_pages = total_pages - current_count
                        eta_seconds = remaining_pages * avg_time_per_page
                        
                        if eta_seconds >= 60:
                            eta_str = f"{int(eta_seconds // 60)}åˆ†{int(eta_seconds % 60)}ç§’"
                        else:
                            eta_str = f"{int(eta_seconds)}ç§’"
                    else:
                        eta_str = "è¨ˆç®—ä¸­..."
                    
                    # æ›´æ–°è¨Šæ¯
                    asyncio.run_coroutine_threadsafe(
                        self.update_progress_message(
                            channel_id, message_id, 
                            current_count, total_pages, 
                            progress_bar, eta_str, title
                        ),
                        self.bot.loop
                    )
                    
            except Exception as e:
                logger.error(f"é€²åº¦ç›£æ§éŒ¯èª¤: {e}")
    
    async def send_cover_image(self, channel_id: int, image_path: Path):
        """ç™¼é€å°é¢åœ–ç‰‡ä½œç‚ºé™„ä»¶"""
        try:
            channel = self.bot.get_channel(channel_id)
            if channel and image_path and image_path.exists():
                await channel.send(file=discord.File(image_path))
                logger.info(f"å·²ç™¼é€å°é¢åœ–ç‰‡: {image_path.name}")
        except Exception as e:
            logger.error(f"ç™¼é€å°é¢åœ–ç‰‡å¤±æ•—: {e}")
    
    async def update_progress_message(self, channel_id: int, message_id: int,
                                       current: int, total: int,
                                       progress_bar: str, eta: str, title: str):
        """ç·¨è¼¯è¨Šæ¯æ›´æ–°ä¸‹è¼‰é€²åº¦"""
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # ç·¨è¼¯è¨Šæ¯
            new_content = (
                f"ğŸ”„ ä¸‹è¼‰ä¸­...\n"
                f"ğŸ“– {title}\n"
                f"{progress_bar}\n"
                f"({current}/{total}) â±ï¸ é ä¼°å‰©é¤˜: {eta}"
            )
            await message.edit(content=new_content)
            
        except Exception as e:
            logger.error(f"æ›´æ–°é€²åº¦è¨Šæ¯å¤±æ•—: {e}")
    
    async def update_pdf_progress_message(self, channel_id: int, message_id: int,
                                          progress: int, pdf_bar: str, download_bar: str, 
                                          total_pages: int, title: str, eta: str = ""):
        """ç·¨è¼¯è¨Šæ¯æ›´æ–° PDF è½‰æ›é€²åº¦"""
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # ç·¨è¼¯è¨Šæ¯ - é¡¯ç¤ºå…©æ¢é€²åº¦æ¢
            new_content = (
                f"ğŸ“„ è£½ä½œ PDF ä¸­...\n"
                f"ğŸ“– {title}\n"
                f"ä¸‹è¼‰: \n{download_bar}\n"
                f"({total_pages}/{total_pages})\n"
                f"PDF: \n{pdf_bar}\n"
                f"â±ï¸ é ä¼°å‰©é¤˜: {eta}"
            )
            await message.edit(content=new_content)
            
        except Exception as e:
            logger.error(f"æ›´æ–° PDF é€²åº¦è¨Šæ¯å¤±æ•—: {e}")
    
    async def update_final_progress(self, channel_id: int, message_id: int, 
                                    success: bool, total: int, title: str, media_id: str = ""):
        """æ›´æ–°æœ€çµ‚é€²åº¦ç‹€æ…‹"""
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # æ›´æ–°è¨Šæ¯å…§å®¹å’Œè¡¨æƒ…
            if success:
                progress_bar = create_progress_bar(total, total)
                await message.edit(content=f"âœ… ä¸‹è¼‰å®Œæˆ\nğŸ“– {title}\n{progress_bar}\n({total}/{total})")
                await message.add_reaction('âœ…')
            else:
                await message.add_reaction('âŒ')
            
        except Exception as e:
            logger.error(f"æ›´æ–°æœ€çµ‚é€²åº¦å¤±æ•—: {e}")
    
    async def send_start_message(self, channel_id: int, gallery_id: str, pages: int, title: str, media_id: str = "") -> int:
        """
        ç™¼é€é–‹å§‹ä¸‹è¼‰è¨Šæ¯ï¼ˆåŒ…å«é æ•¸å’Œé ä¼°æ™‚é–“ï¼‰
        
        Returns:
            è¨Šæ¯ IDï¼Œå¤±æ•—æ™‚è¿”å› None
        """
        try:
            channel = self.bot.get_channel(channel_id)
            if channel:
                # è¨ˆç®—é ä¼°æ™‚é–“
                est_seconds = pages * SECONDS_PER_PAGE
                if est_seconds >= 60:
                    est_str = f"{int(est_seconds // 60)}åˆ†{int(est_seconds % 60)}ç§’"
                else:
                    est_str = f"{int(est_seconds)}ç§’"
                
                # åˆå§‹é€²åº¦æ¢
                progress_bar = create_progress_bar(0, pages)
                
                # ç™¼é€é€²åº¦è¨Šæ¯
                msg = await channel.send(
                    f"ğŸ”„ é–‹å§‹ä¸‹è¼‰ **#{gallery_id}**\n"
                    f"ğŸ“– {title}\n"
                    f"{progress_bar}\n"
                    f"(0/{pages}) â±ï¸ é ä¼°: {est_str}"
                )
                
                return msg.id
        except Exception as e:
            logger.error(f"ç™¼é€é–‹å§‹è¨Šæ¯å¤±æ•—: {e}")
        return None
    
    async def update_status_reaction(self, channel_id: int, message_id: int, success: bool):
        """æ›´æ–°ç‹€æ…‹è¨Šæ¯çš„è¡¨æƒ…ï¼šæ·»åŠ  âœ… æˆ– âŒï¼ˆå·²ä¸å†ä½¿ç”¨ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰"""
        if not message_id:
            return
        try:
            channel = self.bot.get_channel(channel_id)
            if not channel:
                return
            
            message = await channel.fetch_message(message_id)
            if not message:
                return
            
            # æ·»åŠ çµæœè¡¨æƒ…
            result_emoji = 'âœ…' if success else 'âŒ'
            await message.add_reaction(result_emoji)
            
        except Exception as e:
            logger.error(f"æ›´æ–°ç‹€æ…‹è¡¨æƒ…å¤±æ•—: {e}")
    
    async def send_result(self, channel_id: int, message: str):
        """ç™¼é€çµæœè¨Šæ¯åˆ° Discord é »é“"""
        try:
            channel = self.bot.get_channel(channel_id)
            if channel:
                await channel.send(message)
        except Exception as e:
            logger.error(f"ç™¼é€è¨Šæ¯å¤±æ•—: {e}")
    
    def stop(self):
        """åœæ­¢å·¥ä½œåŸ·è¡Œç·’"""
        self.running = False


# ==================== Discord Bot ====================

class HentaiFetcherBot(commands.Bot):
    """
    HentaiFetcher Discord Bot (ä½¿ç”¨ Slash Commands)
    """
    
    def __init__(self):
        # è¨­å®š Intents
        intents = discord.Intents.default()
        intents.message_content = True
        
        super().__init__(
            command_prefix='!',
            intents=intents,
            help_command=None  # ä½¿ç”¨è‡ªè¨‚ help
        )
        
        self.worker: Optional[DownloadWorker] = None
    
    async def setup_hook(self):
        """Bot å•Ÿå‹•æ™‚çš„è¨­å®š"""
        # å•Ÿå‹•å·¥ä½œåŸ·è¡Œç·’
        self.worker = DownloadWorker(self)
        self.worker.start()
        logger.info("Bot setup å®Œæˆï¼Œä¸‹è¼‰åŸ·è¡Œç·’å·²å•Ÿå‹•")
    
    async def on_ready(self):
        """Bot é€£ç·šæˆåŠŸæ™‚è§¸ç™¼"""
        logger.info(f'Bot å·²ç™»å…¥: {self.user.name} (ID: {self.user.id})')
        logger.info(f'å·²é€£æ¥åˆ° {len(self.guilds)} å€‹ä¼ºæœå™¨')
        
        # è¨­å®šç‹€æ…‹
        await self.change_presence(
            activity=discord.Activity(
                type=discord.ActivityType.watching,
                name="#hentaifetcher"
            )
        )
        
        # é¡¯ç¤ºå°ˆç”¨é »é“è¨­å®š
        logger.info(f"å°ˆç”¨é »é“åç¨±: {DEDICATED_CHANNEL_NAMES}")
        logger.info("âœ… Bot å·²å°±ç·’ï¼åœ¨å°ˆç”¨é »é“ç›´æ¥è²¼ç¶²å€æˆ–æ•¸å­—å³å¯ä¸‹è¼‰")
    
    async def on_message(self, message):
        """è™•ç†è¨Šæ¯ - æ”¯æ´å°ˆç”¨é »é“ï¼ˆä¸éœ€ !dlï¼‰å’Œå‚³çµ±æŒ‡ä»¤æ¨¡å¼"""
        # å¿½ç•¥ Bot è‡ªå·±çš„è¨Šæ¯
        if message.author.bot:
            return
        
        # è¨Šæ¯å»é‡ - é¿å…é‡è¤‡è™•ç†
        if is_message_processed(message.id):
            print(f"[DEBUG] è·³éé‡è¤‡è¨Šæ¯: {message.id}", flush=True)
            return
        
        content = message.content.strip()
        
        # å¿½ç•¥ç©ºè¨Šæ¯
        if not content:
            return
        
        # æª¢æŸ¥æ˜¯å¦åœ¨å°ˆç”¨é »é“ä¸­
        is_dedicated_channel = (
            message.channel.name.lower() in [n.lower() for n in DEDICATED_CHANNEL_NAMES] or
            message.channel.id in DEDICATED_CHANNEL_IDS
        )
        
        # Debug: è¨˜éŒ„æ”¶åˆ°çš„è¨Šæ¯
        if is_dedicated_channel:
            print(f"[å°ˆç”¨é »é“] æ”¶åˆ°è¨Šæ¯ (ID:{message.id}): {repr(content[:100])}", flush=True)
        else:
            print(f"[DEBUG] æ”¶åˆ°è¨Šæ¯ (ID:{message.id}): {repr(content[:100])}", flush=True)
        
        # ===== å°ˆç”¨é »é“æ¨¡å¼ï¼šä¸éœ€è¦ !dl å‰ç¶´ =====
        if is_dedicated_channel and not content.startswith('!'):
            # åœ¨å°ˆç”¨é »é“ä¸­ï¼Œä»»ä½•çœ‹èµ·ä¾†åƒ URL æˆ–æ•¸å­—çš„è¨Šæ¯éƒ½å˜—è©¦è™•ç†
            await self.handle_direct_download(message, content)
            return
        
        # ===== å‚³çµ±æ¨¡å¼ï¼šè™•ç† !dl æŒ‡ä»¤ï¼ˆæ”¯æ´å¤šè¡Œï¼‰=====
        if content.startswith('!dl'):
            # å¼·åˆ¶è¼¸å‡º debug è¨Šæ¯
            print(f"[DEBUG] !dl æŒ‡ä»¤åµæ¸¬åˆ°!", flush=True)
            print(f"[DEBUG] å®Œæ•´å…§å®¹é•·åº¦: {len(content)}", flush=True)
            print(f"[DEBUG] å®Œæ•´å…§å®¹: {repr(content)}", flush=True)
            logger.info(f"æ”¶åˆ° !dl æŒ‡ä»¤ï¼Œå®Œæ•´å…§å®¹: {repr(content)}")
            
            # æå– !dl ä¹‹å¾Œçš„æ‰€æœ‰å…§å®¹ï¼ˆåŒ…æ‹¬æ›è¡Œï¼‰
            urls_text = content[3:].strip()  # ç§»é™¤ "!dl" å‰ç¶´
            
            print(f"[DEBUG] è§£ææ–‡å­—: {repr(urls_text)}", flush=True)
            logger.info(f"è§£ææ–‡å­—: {repr(urls_text)}")
            
            if not urls_text:
                await message.channel.send(
                    "ğŸ“– **!dl ä½¿ç”¨æ–¹å¼**\n"
                    "```\n"
                    "!dl 421633\n"
                    "!dl 421633 607769 613358\n"
                    "!dl https://nhentai.net/g/421633/\n"
                    "```\n"
                    "ä¹Ÿå¯ä»¥ç›´æ¥è²¼å¤šè¡Œï¼š\n"
                    "```\n"
                    "!dl 421633\n"
                    "607769\n"
                    "613358\n"
                    "```"
                )
                return
            
            # è§£ææ‰€æœ‰ç¶²å€
            parsed_urls = parse_input_to_urls(urls_text)
            
            print(f"[DEBUG] è§£æçµæœæ•¸é‡: {len(parsed_urls)}", flush=True)
            print(f"[DEBUG] è§£æçµæœ: {parsed_urls}", flush=True)
            logger.info(f"è§£æçµæœ: {parsed_urls}")
            
            if not parsed_urls:
                await message.channel.send("âš ï¸ ç„¡æ³•è§£æè¼¸å…¥ã€‚è«‹æä¾›æœ‰æ•ˆçš„ç¶²å€æˆ– nhentai è™Ÿç¢¼ã€‚")
                return
            
            # ç™¼é€ç‹€æ…‹è¨Šæ¯ï¼ˆç°¡åŒ–ç‰ˆï¼Œåªé¡¯ç¤ºè™Ÿç¢¼ï¼‰
            queue_size = download_queue.qsize() + len(parsed_urls)
            
            # æå–æ‰€æœ‰ gallery ID
            gallery_ids = []
            for url in parsed_urls:
                match = re.search(r'/g/(\d+)', url)
                if match:
                    gallery_ids.append(match.group(1))
            
            if len(parsed_urls) == 1 and gallery_ids:
                await message.channel.send(f"ğŸ“¥ **#{gallery_ids[0]}** å·²åŠ å…¥ä½‡åˆ—\nğŸ“Š ä½‡åˆ—: {queue_size}")
            elif len(gallery_ids) <= 15:
                id_list = ", ".join([f"`{gid}`" for gid in gallery_ids])
                await message.channel.send(f"ğŸ“¥ **{len(gallery_ids)}** å€‹å·²åŠ å…¥ä½‡åˆ—\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
            else:
                await message.channel.send(f"ğŸ“¥ **{len(parsed_urls)}** å€‹å·²åŠ å…¥ä½‡åˆ—\nğŸ“Š ä½‡åˆ—: {queue_size}")
            
            # åŠ å…¥ä½‡åˆ—ï¼ˆä¸å†å‚³é status_msg_idï¼Œå› ç‚º loading emoji æ”¹åœ¨é–‹å§‹ä¸‹è¼‰æ™‚é¡¯ç¤ºï¼‰
            for url in parsed_urls:
                download_queue.put((url, message.channel.id, None))
            
            logger.info(f"æ–°å¢ {len(parsed_urls)} å€‹ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {message.author})")
            return
        
        # ===== è™•ç† !test æŒ‡ä»¤ï¼ˆå¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼Œè·³éé‡è¤‡æª¢æŸ¥ï¼‰=====
        if content.startswith('!test'):
            print(f"[DEBUG] !test æŒ‡ä»¤åµæ¸¬åˆ°!", flush=True)
            logger.info(f"æ”¶åˆ° !test æŒ‡ä»¤ï¼Œå®Œæ•´å…§å®¹: {repr(content)}")
            
            # æå– !test ä¹‹å¾Œçš„æ‰€æœ‰å…§å®¹
            urls_text = content[5:].strip()  # ç§»é™¤ "!test" å‰ç¶´
            
            if not urls_text:
                await message.channel.send(
                    "ğŸ§ª **!test ä½¿ç”¨æ–¹å¼ï¼ˆå¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼‰**\n"
                    "```\n"
                    "!test 421633\n"
                    "!test https://nhentai.net/g/421633/\n"
                    "```\n"
                    "âš ï¸ æ­¤æ¨¡å¼æœƒè·³éé‡è¤‡æª¢æŸ¥ï¼Œå³ä½¿å·²ä¸‹è¼‰éä¹Ÿæœƒé‡æ–°ä¸‹è¼‰"
                )
                return
            
            # è§£ææ‰€æœ‰ç¶²å€
            parsed_urls = parse_input_to_urls(urls_text)
            
            if not parsed_urls:
                await message.channel.send("âš ï¸ ç„¡æ³•è§£æè¼¸å…¥ã€‚è«‹æä¾›æœ‰æ•ˆçš„ç¶²å€æˆ– nhentai è™Ÿç¢¼ã€‚")
                return
            
            # ç™¼é€ç‹€æ…‹è¨Šæ¯
            queue_size = download_queue.qsize() + len(parsed_urls)
            
            # æå–æ‰€æœ‰ gallery ID
            gallery_ids = []
            for url in parsed_urls:
                match = re.search(r'/g/(\d+)', url)
                if match:
                    gallery_ids.append(match.group(1))
            
            if len(parsed_urls) == 1 and gallery_ids:
                await message.channel.send(f"ğŸ§ª **#{gallery_ids[0]}** å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ“Š ä½‡åˆ—: {queue_size}")
            else:
                id_list = ", ".join([f"`{gid}`" for gid in gallery_ids[:10]])
                await message.channel.send(f"ğŸ§ª **{len(gallery_ids)}** å€‹å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
            
            # åŠ å…¥ä½‡åˆ—ï¼ˆç¬¬4å€‹åƒæ•¸ True è¡¨ç¤º test_modeï¼‰
            for url in parsed_urls:
                download_queue.put((url, message.channel.id, None, True))
            
            logger.info(f"æ–°å¢ {len(parsed_urls)} å€‹ TEST ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {message.author})")
            return
        
        # è™•ç†å…¶ä»–æŒ‡ä»¤
        await self.process_commands(message)
    
    async def handle_direct_download(self, message, content: str):
        """
        è™•ç†å°ˆç”¨é »é“ä¸­çš„ç›´æ¥ä¸‹è¼‰è«‹æ±‚
        ä¸éœ€è¦ ! å‰ç¶´ï¼Œç›´æ¥è²¼ç¶²å€ã€æ•¸å­—æˆ–æŒ‡ä»¤å³å¯
        """
        content_lower = content.lower().strip()
        
        # ===== è™•ç†æŒ‡ä»¤ï¼ˆä¸éœ€è¦ ! å‰ç¶´ï¼‰=====
        # help / h
        if content_lower in ['help', 'h']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('help')
            await self.invoke(ctx)
            return
        
        # queue / q
        if content_lower in ['queue', 'q']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('queue')
            await self.invoke(ctx)
            return
        
        # status
        if content_lower == 'status':
            ctx = await self.get_context(message)
            ctx.command = self.get_command('status')
            await self.invoke(ctx)
            return
        
        # ping
        if content_lower == 'ping':
            ctx = await self.get_context(message)
            ctx.command = self.get_command('ping')
            await self.invoke(ctx)
            return
        
        # version / v
        if content_lower in ['version', 'v']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('version')
            await self.invoke(ctx)
            return
        
        # list / ls / library
        if content_lower in ['list', 'ls', 'library']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('list')
            await self.invoke(ctx)
            return
        
        # cleanup / clean / dedup
        if content_lower in ['cleanup', 'clean', 'dedup']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('cleanup')
            await self.invoke(ctx)
            return
        
        # fixcover / fc / addcover
        if content_lower in ['fixcover', 'fc', 'addcover']:
            ctx = await self.get_context(message)
            ctx.command = self.get_command('fixcover')
            await self.invoke(ctx)
            return
        
        # random / rand / r [æ•°é‡]
        if content_lower.startswith('random ') or content_lower.startswith('rand ') or content_lower.startswith('r ') or content_lower in ['random', 'rand', 'r']:
            # æå–æ•°é‡å‚æ•°
            parts = content.split()
            count = 1
            if len(parts) > 1:
                try:
                    count = int(parts[1])
                except:
                    count = 1
            
            # ç›´æ¥è°ƒç”¨å‡½æ•°
            ctx = await self.get_context(message)
            await random_command(ctx, count)
            return
        
        # dl <å…§å®¹> - ä¹Ÿæ”¯æ´ä¸å¸¶ ! çš„ dl
        if content_lower.startswith('dl ') or content_lower == 'dl':
            content = content[2:].strip() if len(content) > 2 else ''
            if not content:
                await message.channel.send(
                    "ğŸ“– **ä¸‹è¼‰ä½¿ç”¨æ–¹å¼**\n"
                    "ç›´æ¥è²¼ç¶²å€æˆ–è™Ÿç¢¼å³å¯ï¼\n"
                    "```\n"
                    "421633\n"
                    "421633 607769 613358\n"
                    "https://nhentai.net/g/421633/\n"
                    "```"
                )
                return
        
        # test <å…§å®¹> - å¼·åˆ¶é‡æ–°ä¸‹è¼‰
        if content_lower.startswith('test ') or content_lower == 'test':
            test_content = content[4:].strip() if len(content) > 4 else ''
            if not test_content:
                await message.channel.send(
                    "ğŸ§ª **Test æ¨¡å¼ä½¿ç”¨æ–¹å¼ï¼ˆå¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼‰**\n"
                    "```\n"
                    "test 421633\n"
                    "test https://nhentai.net/g/421633/\n"
                    "```\n"
                    "âš ï¸ æ­¤æ¨¡å¼æœƒè·³éé‡è¤‡æª¢æŸ¥"
                )
                return
            
            # è§£æ test å…§å®¹
            test_urls = parse_input_to_urls(test_content)
            if not test_urls:
                await message.channel.send(f"âš ï¸ ç„¡æ³•è§£æ: `{test_content[:50]}`")
                return
            
            # åŠ å…¥ä½‡åˆ—ï¼ˆtest æ¨¡å¼ï¼‰
            queue_size = download_queue.qsize() + len(test_urls)
            gallery_ids = []
            for url in test_urls:
                match = re.search(r'/g/(\d+)', url)
                if match:
                    gallery_ids.append(match.group(1))
            
            if len(test_urls) == 1 and gallery_ids:
                await message.channel.send(f"ğŸ§ª **#{gallery_ids[0]}** å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ“Š ä½‡åˆ—: {queue_size}")
            else:
                id_list = ", ".join([f"`{gid}`" for gid in gallery_ids[:10]])
                await message.channel.send(f"ğŸ§ª **{len(gallery_ids)}** å€‹å·²åŠ å…¥ä½‡åˆ—ï¼ˆTest æ¨¡å¼ï¼‰\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
            
            for url in test_urls:
                download_queue.put((url, message.channel.id, None, True))
            
            logger.info(f"[å°ˆç”¨é »é“] æ–°å¢ {len(test_urls)} å€‹ TEST ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {message.author})")
            return
        
        # è§£æè¼¸å…¥
        parsed_urls = parse_input_to_urls(content)
        
        if not parsed_urls:
            # å¦‚æœç„¡æ³•è§£æï¼Œéœé»˜å¿½ç•¥ï¼ˆä¸ç™¼é€éŒ¯èª¤è¨Šæ¯ï¼Œé¿å…æ‰“æ“¾ï¼‰
            # ä½†å¦‚æœå…§å®¹çœ‹èµ·ä¾†åƒæ˜¯æƒ³è¦ä¸‹è¼‰ï¼ˆç´”æ•¸å­—æˆ–åŒ…å« nhentaiï¼‰ï¼Œçµ¦äºˆæç¤º
            if re.search(r'\d{4,7}', content) or 'nhentai' in content.lower():
                await message.channel.send(f"âš ï¸ ç„¡æ³•è§£æ: `{content[:50]}`\nè«‹ç¢ºèªæ ¼å¼æ­£ç¢ºï¼ˆä¾‹å¦‚: `607769` æˆ– `https://nhentai.net/g/607769/`ï¼‰")
            return
        
        # é©—è­‰ä¸¦åŠ å…¥ä½‡åˆ—
        valid_urls = []
        invalid_urls = []
        
        # æ·»åŠ  reaction è¡¨ç¤ºè™•ç†ä¸­
        try:
            await message.add_reaction('â³')
        except:
            pass
        
        for url in parsed_urls:
            # æå– gallery ID
            match = re.search(r'/g/(\d+)', url)
            if match:
                gallery_id = match.group(1)
                
                # é©—è­‰æ˜¯å¦å¯è¨ªå•
                is_valid, info = verify_nhentai_url(gallery_id)
                
                if is_valid:
                    valid_urls.append((url, gallery_id, info))
                else:
                    invalid_urls.append((gallery_id, info))
            else:
                invalid_urls.append((url, "ç„¡æ•ˆæ ¼å¼"))
        
        # ç§»é™¤è™•ç†ä¸­ reaction
        try:
            await message.remove_reaction('â³', self.user)
        except:
            pass
        
        # è™•ç†ç„¡æ•ˆçš„ URL
        if invalid_urls:
            error_list = "\n".join([f"â€¢ `{id}`: {reason}" for id, reason in invalid_urls[:5]])
            await message.channel.send(f"âŒ ä»¥ä¸‹ç„¡æ³•ä¸‹è¼‰:\n{error_list}")
        
        # åŠ å…¥æœ‰æ•ˆçš„ URL
        if valid_urls:
            queue_size = download_queue.qsize() + len(valid_urls)
            
            # ç™¼é€ç°¡åŒ–çš„ç‹€æ…‹è¨Šæ¯ï¼ˆåªé¡¯ç¤ºè™Ÿç¢¼ï¼‰
            if len(valid_urls) == 1:
                _, gallery_id, _ = valid_urls[0]
                await message.channel.send(f"ğŸ“¥ **#{gallery_id}** å·²åŠ å…¥ä½‡åˆ—\nğŸ“Š ä½‡åˆ—: {queue_size}")
            else:
                id_list = ", ".join([f"`{gid}`" for _, gid, _ in valid_urls[:10]])
                await message.channel.send(f"ğŸ“¥ **{len(valid_urls)}** å€‹å·²åŠ å…¥ä½‡åˆ—\nğŸ”¢ {id_list}\nğŸ“Š ä½‡åˆ—: {queue_size}")
            
            # æ·»åŠ æˆåŠŸ reaction åˆ°åŸå§‹è¨Šæ¯
            try:
                await message.add_reaction('âœ…')
            except:
                pass
            
            # åŠ å…¥ä½‡åˆ—ï¼ˆä¸å‚³é status_msg_idï¼Œloading emoji æ”¹åœ¨é–‹å§‹ä¸‹è¼‰æ™‚é¡¯ç¤ºï¼‰
            for url, gallery_id, title in valid_urls:
                download_queue.put((url, message.channel.id, None))
            
            logger.info(f"[å°ˆç”¨é »é“] æ–°å¢ {len(valid_urls)} å€‹ä¸‹è¼‰ä»»å‹™ (ä¾†è‡ª: {message.author})")
    
    async def on_command_error(self, ctx, error):
        """å…¨åŸŸéŒ¯èª¤è™•ç†"""
        if isinstance(error, commands.CommandNotFound):
            return  # å¿½ç•¥æœªçŸ¥æŒ‡ä»¤
        
        logger.error(f"æŒ‡ä»¤éŒ¯èª¤: {error}")
        await ctx.send(f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤: {str(error)}")


# å»ºç«‹ Bot å¯¦ä¾‹
bot = HentaiFetcherBot()


# ==================== å‚³çµ±æŒ‡ä»¤ ====================

@bot.command(name='queue', aliases=['q'])
async def queue_command(ctx):
    """æŸ¥çœ‹ä¸‹è¼‰ä½‡åˆ—ï¼š!queue æˆ– !q"""
    size = download_queue.qsize()
    await ctx.send(f"ğŸ“Š ä½‡åˆ—ä¸­ç­‰å¾…ä»»å‹™: {size}")


@bot.command(name='ping')
async def ping_command(ctx):
    """æ¸¬è©¦é€£ç·šï¼š!ping"""
    latency = round(bot.latency * 1000)
    await ctx.send(f"ğŸ“ Pong! å»¶é²: {latency}ms")


@bot.command(name='version', aliases=['v', 'ver'])
async def version_command(ctx):
    """é¡¯ç¤ºç‰ˆæœ¬ï¼š!version æˆ– !v"""
    await ctx.send(f"ğŸ“¦ HentaiFetcher ç‰ˆæœ¬: **{VERSION}**")


@bot.command(name='status')
async def status_command(ctx):
    """é¡¯ç¤ºç‹€æ…‹ï¼š!status"""
    embed = discord.Embed(
        title="ğŸ“Š HentaiFetcher Status",
        color=discord.Color.blue()
    )
    embed.add_field(name="ä½‡åˆ—ä»»å‹™", value=str(download_queue.qsize()), inline=True)
    embed.add_field(name="å»¶é²", value=f"{round(bot.latency * 1000)}ms", inline=True)
    embed.add_field(name="ä¼ºæœå™¨æ•¸", value=str(len(bot.guilds)), inline=True)
    
    # é¡¯ç¤ºç›®å‰ä¸‹è¼‰ç‹€æ…‹
    if bot.worker and bot.worker.current_task:
        match = re.search(r'/g/(\d+)', bot.worker.current_task)
        task_id = match.group(1) if match else "..."
        embed.add_field(name="ç›®å‰ä¸‹è¼‰", value=f"ğŸ”„ `{task_id}`", inline=True)
    else:
        embed.add_field(name="ç›®å‰ä¸‹è¼‰", value="â³ ç­‰å¾…ä¸­", inline=True)
    
    embed.set_footer(text="ä½¿ç”¨ !dl <è™Ÿç¢¼æˆ–ç¶²å€> é–‹å§‹ä¸‹è¼‰")
    
    await ctx.send(embed=embed)


@bot.command(name='list', aliases=['ls', 'library'])
async def list_command(ctx):
    """åˆ—å‡ºæ‰€æœ‰å·²ä¸‹è¼‰çš„æœ¬å­ï¼š!list"""
    try:
        from urllib.parse import quote
        
        if not DOWNLOAD_DIR.exists():
            await ctx.send("ğŸ“‚ ä¸‹è¼‰è³‡æ–™å¤¾ä¸å­˜åœ¨")
            return
        
        # ç²å–æ‰€æœ‰å­è³‡æ–™å¤¾
        folders = [f for f in DOWNLOAD_DIR.iterdir() if f.is_dir()]
        
        if not folders:
            await ctx.send("ğŸ“‚ ç›®å‰æ²’æœ‰ä»»ä½•ä¸‹è¼‰")
            return
        
        # æ§‹å»ºç´”æ–‡å­—è¨Šæ¯ï¼ˆåˆ†æ‰¹ç™¼é€ä»¥é¿å… 2000 å­—å…ƒé™åˆ¶ï¼‰
        items = []
        
        for folder in folders:
            folder_name = folder.name
            
            # å˜—è©¦å¾ metadata.json ç²å– gallery_id
            metadata_path = folder / "metadata.json"
            gallery_id = ""
            if metadata_path.exists():
                try:
                    with open(metadata_path, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                        # å„ªå…ˆå¾ gallery_id ç²å–
                        gallery_id = metadata.get('gallery_id', '')
                        # å¦‚æœæ²’æœ‰ï¼Œå¾ URL æå–
                        if not gallery_id:
                            url = metadata.get('url', '')
                            match = re.search(r'/g/(\d+)', url)
                            if match:
                                gallery_id = match.group(1)
                except:
                    pass
            
            items.append((gallery_id, folder_name))
        
        # æŒ‰è™Ÿç¢¼æ’åºï¼ˆå¾å°åˆ°å¤§ï¼‰
        items.sort(key=lambda x: int(x[0]) if x[0].isdigit() else 0)
        
        # æ§‹å»ºè¼¸å‡º
        msg_lines = []
        for gallery_id, folder_name in items:
            # æ ¼å¼ï¼š`#è™Ÿç¢¼` æ›¸åï¼ˆä¸è¦é€£çµï¼‰
            if gallery_id:
                msg_lines.append(f"`#{gallery_id}` {folder_name}")
            else:
                msg_lines.append(f"{folder_name}")
        
        # åˆ†æ‰¹ç™¼é€ï¼ˆæ¯æ‰¹æœ€å¤š 1800 å­—å…ƒï¼‰
        header = f"ğŸ“š **å·²ä¸‹è¼‰çš„æœ¬å­** (å…± {len(folders)} æœ¬)\n"
        await ctx.send(header)
        
        current_batch = []
        current_length = 0
        
        for line in msg_lines:
            line_length = len(line) + 1  # +1 for newline
            if current_length + line_length > 1800:
                # ç™¼é€ç•¶å‰æ‰¹æ¬¡
                await ctx.send("\n".join(current_batch))
                current_batch = [line]
                current_length = line_length
            else:
                current_batch.append(line)
                current_length += line_length
        
        # ç™¼é€æœ€å¾Œä¸€æ‰¹
        if current_batch:
            await ctx.send("\n".join(current_batch))
        
    except Exception as e:
        logger.error(f"åˆ—å‡ºä¸‹è¼‰å¤±æ•—: {e}")
        await ctx.send(f"âŒ åˆ—å‡ºå¤±æ•—: {e}")


@bot.command(name='random', aliases=['rand', 'r'])
async def random_command(ctx, count: int = 1):
    """éš¨æ©Ÿé¡¯ç¤ºæœ¬å­ï¼š!random [æ•¸é‡]"""
    try:
        from urllib.parse import quote
        import random
        
        if not DOWNLOAD_DIR.exists():
            await ctx.send("ğŸ“‚ ä¸‹è¼‰è³‡æ–™å¤¾ä¸å­˜åœ¨")
            return
        
        # ç²å–æ‰€æœ‰å­è³‡æ–™å¤¾
        folders = [f for f in DOWNLOAD_DIR.iterdir() if f.is_dir()]
        
        if not folders:
            await ctx.send("ğŸ“‚ ç›®å‰æ²’æœ‰ä»»ä½•ä¸‹è¼‰")
            return
        
        # é™åˆ¶æ•¸é‡
        count = max(1, min(count, 5))  # 1-5 æœ¬
        count = min(count, len(folders))  # ä¸è¶…éç¸½æ•¸
        
        # éš¨æ©Ÿé¸æ“‡
        selected = random.sample(folders, count)
        
        for folder in selected:
            folder_name = folder.name
            
            # è®€å– metadata
            metadata_path = folder / "metadata.json"
            metadata = {}
            if metadata_path.exists():
                try:
                    with open(metadata_path, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                except:
                    pass
            
            # ç²å–åŸºæœ¬è³‡æ–™
            gallery_id = metadata.get('gallery_id', '')
            # å¦‚æœæ²’æœ‰ gallery_idï¼Œå¾ URL æå–
            if not gallery_id:
                url = metadata.get('url', '')
                match = re.search(r'/g/(\d+)', url)
                if match:
                    gallery_id = match.group(1)
            if not gallery_id:
                gallery_id = 'æœªçŸ¥'
            
            # å¾ metadata ç²å–æ¨™é¡Œ
            title = metadata.get('name', metadata.get('title', folder_name))
            
            # å¾ annotation è§£æä¿¡æ¯
            annotation = metadata.get('annotation', '')
            title_japanese = ''
            pages = 'æœªçŸ¥'
            
            # è§£æ annotation
            if annotation:
                # æå–è‹±æ–‡æ¨™é¡Œ
                title_match = re.search(r'ğŸ“– è‹±æ–‡æ¨™é¡Œ: (.+?)(?:\n|$)', annotation)
                if title_match:
                    title_japanese = title_match.group(1).strip()
                
                # æå–é æ•¸
                pages_match = re.search(r'ğŸ“„ é æ•¸: (\d+)', annotation)
                if pages_match:
                    pages = pages_match.group(1)
            
            # å¾ tags è§£æä½œè€…ï¼ˆtags æ˜¯å­—ä¸²åˆ—è¡¨ï¼‰
            tags = metadata.get('tags', [])
            if not isinstance(tags, list):
                tags = []
            artists = [tag.replace('artist:', '') for tag in tags if isinstance(tag, str) and tag.startswith('artist:')]
            parodies = [tag.replace('parody:', '') for tag in tags if isinstance(tag, str) and tag.startswith('parody:')]
            groups = [tag.replace('group:', '') for tag in tags if isinstance(tag, str) and tag.startswith('group:')]
            languages = [tag.replace('language:', '') for tag in tags if isinstance(tag, str) and tag.startswith('language:')]
            
            # å…¶ä»– tagsï¼ˆä¸åŒ…å«é¡å‹å‰ç¶´çš„ï¼‰
            other_tags = [tag for tag in tags if isinstance(tag, str) and not any(tag.startswith(prefix) for prefix in ['artist:', 'parody:', 'group:', 'language:', 'type:'])]
            
            # æŸ¥æ‰¾ PDF å’Œå°é¢
            pdf_files = list(folder.glob("*.pdf"))
            
            # æŸ¥æ‰¾å°é¢ - å…ˆæ‰¾åœ–ç‰‡æª”æ¡ˆ
            cover_files = []
            # æœç´¢æ‰€æœ‰å¯èƒ½çš„å°é¢æª”æ¡ˆ
            for pattern in ["cover.*", "000.*", "001.*", "01.*", "1.*", "2.*", "3.*"]:
                found = list(folder.glob(pattern))
                if found:
                    # éæ¿¾å‡ºåœ–ç‰‡æª”æ¡ˆ
                    cover_files = [f for f in found if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.webp', '.gif']]
                    if cover_files:
                        break
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°åœ–ç‰‡ï¼Œå˜—è©¦å¾æ‰€æœ‰åœ–ç‰‡ä¸­æ‰¾ç¬¬ä¸€å¼µ
            if not cover_files:
                all_images = []
                for ext in ['.jpg', '.jpeg', '.png', '.webp', '.gif']:
                    all_images.extend(folder.glob(f"*{ext}"))
                if all_images:
                    # æŒ‰æª”åæ’åºå–ç¬¬ä¸€å¼µ
                    all_images.sort(key=lambda x: x.name)
                    cover_files = [all_images[0]]
            
            # å…ˆç™¼é€å°é¢åœ–ç‰‡ï¼ˆå–®ç¨ä¸€å‰‡è¨Šæ¯ï¼‰
            if cover_files:
                cover_file = cover_files[0]
                try:
                    file = discord.File(str(cover_file), filename=cover_file.name)
                    await ctx.send(file=file)
                    logger.info(f"æˆåŠŸç™¼é€å°é¢: {cover_file.name}")
                except Exception as e:
                    logger.error(f"ç™¼é€å°é¢å¤±æ•— ({cover_file}): {e}")
            else:
                # æ²’æœ‰å°é¢æ™‚ç™¼é€æç¤º
                logger.warning(f"æ‰¾ä¸åˆ°å°é¢åœ–ç‰‡: {folder_name}")
            
            # æ§‹å»ºç´”æ–‡å­—è³‡æ–™è¨Šæ¯
            msg_lines = []
            
            # PDF é€£çµæ¨™é¡Œ - ä½¿ç”¨åˆ†éš”ç·šç¾åŒ–
            msg_lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            if pdf_files:
                pdf_name = pdf_files[0].name
                pdf_url = f"{PDF_WEB_BASE_URL}/{quote(folder_name)}/{quote(pdf_name)}"
                # é€£çµæ–‡å­—ç°¡æ½”é¡¯ç¤ºï¼ŒURL éš±è—åœ¨ markdown é€£çµä¸­
                msg_lines.append(f"ğŸ“– **#{gallery_id}** â”‚ [ğŸ“¥ é»æ“Šé–±è®€ PDF](<{pdf_url}>)")
            else:
                msg_lines.append(f"ğŸ“– **#{gallery_id}**")
            msg_lines.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
            
            # æ¨™é¡Œ
            if title:
                msg_lines.append(f"**{title}**")
            if title_japanese and title_japanese != title:
                msg_lines.append(f"_{title_japanese}_\n")
            else:
                msg_lines.append("")
            
            # åŸºæœ¬ä¿¡æ¯ - åˆ†è¡Œé¡¯ç¤ºæ›´æ¸…æ¥š
            msg_lines.append("**ğŸ“Š åŸºæœ¬è³‡æ–™**")
            if pages != 'æœªçŸ¥':
                msg_lines.append(f"â”œ ğŸ“„ é æ•¸: **{pages}**")
            if artists:
                msg_lines.append(f"â”œ âœï¸ ä½œè€…: {', '.join(artists[:3])}")
            if groups:
                msg_lines.append(f"â”œ ğŸ‘¥ ç¤¾åœ˜: {', '.join(groups[:2])}")
            if parodies:
                msg_lines.append(f"â”œ ğŸ¬ åŸä½œ: {', '.join(parodies[:3])}")
            if languages:
                msg_lines.append(f"â”” ğŸŒ èªè¨€: {', '.join(languages)}")
            
            # Tags
            if other_tags:
                msg_lines.append(f"\n**ğŸ·ï¸ æ¨™ç±¤**")
                tags_text = ", ".join([f"`{tag}`" for tag in other_tags[:12]])
                if len(other_tags) > 12:
                    tags_text += f" `+{len(other_tags)-12}`"
                msg_lines.append(tags_text)
            
            msg_lines.append("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            
            # ç™¼é€è³‡æ–™è¨Šæ¯
            final_msg = "\n".join(msg_lines)
            if len(final_msg) > 1900:
                final_msg = final_msg[:1900] + "..."
            await ctx.send(final_msg)
        
    except Exception as e:
        logger.error(f"éš¨æ©Ÿé¡¯ç¤ºå¤±æ•—: {e}")
        await ctx.send(f"âŒ éš¨æ©Ÿé¡¯ç¤ºå¤±æ•—: {e}")


@bot.command(name='fixcover', aliases=['fc', 'addcover'])
async def fixcover_command(ctx):
    """ç‚ºå·²æœ‰çš„æœ¬å­è£œå……å°é¢ï¼ˆå¾ nhentai ä¸‹è¼‰æˆ–ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ï¼‰ï¼š!fixcover"""
    try:
        if not DOWNLOAD_DIR.exists():
            await ctx.send("ğŸ“‚ ä¸‹è¼‰è³‡æ–™å¤¾ä¸å­˜åœ¨")
            return
        
        await ctx.send("ğŸ” é–‹å§‹æƒæä¸¦è£œå……å°é¢...")
        
        folders = [f for f in DOWNLOAD_DIR.iterdir() if f.is_dir()]
        fixed_count = 0
        skipped_count = 0
        fallback_count = 0  # ä½¿ç”¨ç¬¬ä¸€å¼µåœ–ç‰‡ä½œç‚ºå°é¢çš„æ•¸é‡
        failed_count = 0
        
        for folder in folders:
            # æª¢æŸ¥æ˜¯å¦å·²æœ‰å°é¢
            has_cover = any(list(folder.glob(f"cover.{ext}")) for ext in ['jpg', 'jpeg', 'png', 'gif', 'webp'])
            
            if has_cover:
                skipped_count += 1
                continue
            
            # å¾ metadata.json ç²å– gallery_id
            metadata_path = folder / "metadata.json"
            gallery_id = ""
            
            if metadata_path.exists():
                try:
                    with open(metadata_path, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                        # å¾ url æå– gallery_id
                        url = metadata.get('url', '')
                        match = re.search(r'/g/(\d+)', url)
                        if match:
                            gallery_id = match.group(1)
                except Exception as e:
                    logger.error(f"è®€å– metadata å¤±æ•— ({folder.name}): {e}")
            
            cover_success = False
            
            if gallery_id:
                # å˜—è©¦å¾ nhentai ä¸‹è¼‰å°é¢
                if download_nhentai_cover(gallery_id, folder):
                    fixed_count += 1
                    cover_success = True
                    logger.info(f"è£œå……å°é¢æˆåŠŸ (nhentai å°é¢): {folder.name}")
                else:
                    # å°é¢ä¸‹è¼‰å¤±æ•—ï¼Œå˜—è©¦ä¸‹è¼‰ç¬¬ä¸€é ä½œç‚ºå°é¢
                    await asyncio.sleep(0.3)  # çŸ­æš«å»¶é²é¿å…è«‹æ±‚å¤ªå¿«
                    if download_nhentai_first_page(gallery_id, folder):
                        fallback_count += 1
                        cover_success = True
                        logger.info(f"è£œå……å°é¢æˆåŠŸ (nhentai ç¬¬ä¸€é ): {folder.name}")
                # é¿å…è«‹æ±‚å¤ªé »ç¹
                await asyncio.sleep(0.5)
            
            # å¦‚æœå¾ nhentai éƒ½å¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨è³‡æ–™å¤¾å…§çš„ç¬¬ä¸€å¼µåœ–ç‰‡
            if not cover_success:
                first_image = get_first_image_as_cover(folder)
                if first_image:
                    fallback_count += 1
                    cover_success = True
                    logger.info(f"è£œå……å°é¢æˆåŠŸ (æœ¬åœ°åœ–ç‰‡): {folder.name}")
                else:
                    failed_count += 1
                    logger.warning(f"è£œå……å°é¢å¤±æ•— (æ‰€æœ‰æ–¹æ³•éƒ½å¤±æ•—): {folder.name}")
        
        msg = f"âœ… å®Œæˆï¼\n"
        msg += f"ğŸ“¥ å¾ nhentai å°é¢ä¸‹è¼‰äº† {fixed_count} å€‹\n"
        if fallback_count > 0:
            msg += f"ğŸ–¼ï¸ ä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ {fallback_count} å€‹\n"
        msg += f"â­ï¸ è·³é {skipped_count} å€‹å·²æœ‰å°é¢\n"
        if failed_count > 0:
            msg += f"âŒ å¤±æ•— {failed_count} å€‹"
        await ctx.send(msg)
        
    except Exception as e:
        logger.error(f"è£œå……å°é¢å¤±æ•—: {e}")
        await ctx.send(f"âŒ è£œå……å°é¢å¤±æ•—: {e}")


@bot.command(name='cleanup', aliases=['clean', 'dedup'])
async def cleanup_command(ctx):
    """æ¸…é™¤é‡è¤‡çš„è³‡æ–™å¤¾ï¼ˆæœ‰æ™‚é–“æˆ³å¾Œç¶´çš„ï¼‰ï¼š!cleanup"""
    try:
        if not DOWNLOAD_DIR.exists():
            await ctx.send("ğŸ“‚ ä¸‹è¼‰è³‡æ–™å¤¾ä¸å­˜åœ¨")
            return
        
        # æ‰¾å‡ºæœ‰æ™‚é–“æˆ³å¾Œç¶´çš„è³‡æ–™å¤¾ï¼ˆæ ¼å¼ï¼šæ¨™é¡Œ_æ™‚é–“æˆ³ï¼‰
        import re
        timestamp_pattern = re.compile(r'^(.+)_(\d{10})$')  # 10 ä½æ•¸æ™‚é–“æˆ³
        
        folders = [f for f in DOWNLOAD_DIR.iterdir() if f.is_dir()]
        duplicates = []
        
        for folder in folders:
            match = timestamp_pattern.match(folder.name)
            if match:
                original_name = match.group(1)
                original_path = DOWNLOAD_DIR / original_name
                
                # å¦‚æœåŸå§‹è³‡æ–™å¤¾ä¹Ÿå­˜åœ¨ï¼Œé€™å€‹å°±æ˜¯é‡è¤‡çš„
                if original_path.exists() and original_path.is_dir():
                    duplicates.append(folder)
        
        if not duplicates:
            await ctx.send("âœ… æ²’æœ‰ç™¼ç¾é‡è¤‡çš„è³‡æ–™å¤¾")
            return
        
        # é¡¯ç¤ºå°‡è¦åˆªé™¤çš„è³‡æ–™å¤¾
        msg = f"ğŸ” ç™¼ç¾ {len(duplicates)} å€‹é‡è¤‡è³‡æ–™å¤¾ï¼š\n"
        for dup in duplicates[:10]:
            msg += f"â€¢ `{dup.name}`\n"
        if len(duplicates) > 10:
            msg += f"... é‚„æœ‰ {len(duplicates) - 10} å€‹\n"
        msg += "\nâš ï¸ ç¢ºå®šè¦åˆªé™¤å—ï¼Ÿå›è¦† `ç¢ºèª` æˆ– `yes` ä¾†åŸ·è¡Œåˆªé™¤"
        
        await ctx.send(msg)
        
        # ç­‰å¾…ç¢ºèª
        def check(m):
            return m.author == ctx.author and m.channel == ctx.channel and m.content.lower() in ['ç¢ºèª', 'yes', 'y']
        
        try:
            confirm_msg = await bot.wait_for('message', timeout=30.0, check=check)
        except:
            await ctx.send("â° è¶…æ™‚ï¼Œå–æ¶ˆæ“ä½œ")
            return
        
        # åŸ·è¡Œåˆªé™¤
        deleted = 0
        for dup in duplicates:
            try:
                shutil.rmtree(dup)
                deleted += 1
                logger.info(f"å·²åˆªé™¤é‡è¤‡è³‡æ–™å¤¾: {dup.name}")
            except Exception as e:
                logger.error(f"åˆªé™¤å¤±æ•— {dup.name}: {e}")
        
        await ctx.send(f"âœ… å·²åˆªé™¤ {deleted}/{len(duplicates)} å€‹é‡è¤‡è³‡æ–™å¤¾")
        
    except Exception as e:
        logger.error(f"æ¸…é™¤é‡è¤‡å¤±æ•—: {e}")
        await ctx.send(f"âŒ æ¸…é™¤å¤±æ•—: {e}")


@bot.command(name='help', aliases=['h'])
async def help_command(ctx):
    """é¡¯ç¤ºèªªæ˜ï¼š!help"""
    embed = discord.Embed(
        title="ğŸ“– HentaiFetcher ä½¿ç”¨èªªæ˜",
        description="è‡ªå‹•ä¸‹è¼‰æ¼«ç•«ä¸¦è½‰æ›ç‚º PDFï¼Œç”Ÿæˆ Eagle ç›¸å®¹ metadata",
        color=discord.Color.green()
    )
    
    # æª¢æŸ¥æ˜¯å¦åœ¨å°ˆç”¨é »é“
    is_dedicated = (
        ctx.channel.name.lower() in [n.lower() for n in DEDICATED_CHANNEL_NAMES] or
        ctx.channel.id in DEDICATED_CHANNEL_IDS
    )
    
    if is_dedicated:
        embed.add_field(
            name="ğŸ¯ å°ˆç”¨é »é“æ¨¡å¼ï¼ˆæ­¤é »é“ï¼‰",
            value="**æ‰€æœ‰æŒ‡ä»¤éƒ½ä¸éœ€è¦ `!` å‰ç¶´ï¼**\n"
                  "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                  "**ğŸ“¥ ä¸‹è¼‰** - ç›´æ¥è²¼ç¶²å€æˆ–è™Ÿç¢¼ï¼š\n"
                  "```\n"
                  "421633\n"
                  "https://nhentai.net/g/607769/\n"
                  "421633 607769 613358\n"
                  "```\n"
                  "**ğŸ§ª å¼·åˆ¶é‡æ–°ä¸‹è¼‰**ï¼š`test <è™Ÿç¢¼>`\n"
                  "**ğŸ“Š å…¶ä»–æŒ‡ä»¤ï¼š**\n"
                  "`queue` `q` - æŸ¥çœ‹ä½‡åˆ—\n"
                  "`status` - Bot ç‹€æ…‹\n"
                  "`list` `ls` - åˆ—å‡ºå·²ä¸‹è¼‰\n"
                  "`random` `r [n]` - éš¨æ©Ÿé¡¯ç¤º\n"
                  "`fixcover` `fc` - è£œå……å°é¢\n"
                  "`cleanup` `clean` - æ¸…é™¤é‡è¤‡\n"
                  "`ping` - æ¸¬è©¦é€£ç·š\n"
                  "`version` `v` - ç‰ˆæœ¬è™Ÿ\n"
                  "`help` `h` - é¡¯ç¤ºæ­¤èªªæ˜",
            inline=False
        )
    else:
        embed.add_field(
            name="ğŸ“¥ !dl <ç¶²å€æˆ–è™Ÿç¢¼>",
            value="**ä¸‹è¼‰æ¼«ç•«**\n"
                  "```\n"
                  "!dl 421633\n"
                  "!dl 421633 607769 613358\n"
                  "!dl https://nhentai.net/g/421633/\n"
                  "```\n"
                  "æ”¯æ´å¤šè¡Œè¼¸å…¥ï¼š\n"
                  "```\n"
                  "!dl 421633\n"
                  "607769\n"
                  "https://nhentai.net/g/613358/\n"
                  "```",
            inline=False
        )
        
        embed.add_field(
            name="ğŸ§ª !test <ç¶²å€æˆ–è™Ÿç¢¼>",
            value="å¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼ˆè·³éé‡è¤‡æª¢æŸ¥ï¼‰",
            inline=True
        )
        
        embed.add_field(
            name="ğŸ“Š !queue æˆ– !q",
            value="æŸ¥çœ‹ä¸‹è¼‰ä½‡åˆ—ä»»å‹™æ•¸",
            inline=True
        )
        
        embed.add_field(
            name="ğŸ“ˆ !status",
            value="é¡¯ç¤º Bot ç‹€æ…‹",
            inline=True
        )
        
        embed.add_field(
            name="ğŸ“š !list æˆ– !ls",
            value="åˆ—å‡ºå·²ä¸‹è¼‰é …ç›®",
            inline=True
        )
        
        embed.add_field(
            name="ğŸ² !random [n]",
            value="éš¨æ©Ÿé¡¯ç¤º n æœ¬",
            inline=True
        )
        
        embed.add_field(
            name="ğŸ–¼ï¸ !fixcover",
            value="è£œå……å°é¢åœ–ç‰‡",
            inline=True
        )
        
        embed.add_field(
            name="ğŸ§¹ !cleanup æˆ– !clean",
            value="æ¸…é™¤é‡è¤‡è³‡æ–™å¤¾",
            inline=True
        )
        
        embed.add_field(
            name="ğŸ“ !ping",
            value="æ¸¬è©¦ Bot é€£ç·š",
            inline=True
        )
        
        embed.add_field(
            name="ğŸ“¦ !version æˆ– !v",
            value="é¡¯ç¤º Bot ç‰ˆæœ¬è™Ÿ",
            inline=True
        )
    
    embed.add_field(
        name="ğŸ“ è¼¸å‡ºçµæœ",
        value="ä¸‹è¼‰å®Œæˆå¾Œæœƒç”Ÿæˆï¼š\n"
              "```\n"
              "downloads/[æ¼«ç•«æ¨™é¡Œ]/\n"
              "â”œâ”€â”€ [æ¼«ç•«æ¨™é¡Œ].pdf\n"
              "â””â”€â”€ metadata.json (Eagle ç”¨)\n"
              "```",
        inline=False
    )
    
    if is_dedicated:
        embed.set_footer(text="ğŸ¯ å°ˆç”¨é »é“ï¼šæ‰€æœ‰æŒ‡ä»¤éƒ½ä¸éœ€è¦ ! å‰ç¶´ï¼")
    else:
        embed.set_footer(text="ğŸ’¡ å¯ä¸€æ¬¡è²¼å¤šå€‹è™Ÿç¢¼æˆ–ç¶²å€ï¼Œç”¨ç©ºç™½/é€—è™Ÿ/æ›è¡Œåˆ†éš”")
    
    await ctx.send(embed=embed)


# ==================== ä¸»ç¨‹å¼å…¥å£ ====================

def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    # å–å¾— Discord Token
    token = os.environ.get('DISCORD_TOKEN')
    
    if not token:
        logger.error("éŒ¯èª¤: æœªè¨­å®š DISCORD_TOKEN ç’°å¢ƒè®Šæ•¸")
        logger.error("è«‹åœ¨ docker-compose.yml ä¸­è¨­å®š DISCORD_TOKEN")
        sys.exit(1)
    
    try:
        logger.info("æ­£åœ¨å•Ÿå‹• HentaiFetcher Bot...")
        bot.run(token)
    except discord.LoginFailure:
        logger.error("Discord ç™»å…¥å¤±æ•—: Token ç„¡æ•ˆ")
        sys.exit(1)
    except Exception as e:
        logger.exception(f"Bot åŸ·è¡ŒéŒ¯èª¤: {e}")
        sys.exit(1)
    finally:
        # åœæ­¢å·¥ä½œåŸ·è¡Œç·’
        if bot.worker:
            bot.worker.stop()


if __name__ == '__main__':
    main()
